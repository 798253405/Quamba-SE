import math
import copy
from functools import partial
from typing import Optional, Dict

import torch

# ===== DEBUG: å±‚è®¡æ•°å™¨ =====
_DEBUG_LAYER_COUNTER = {'count': 0, 'total': None}
# ===== END DEBUG =====

# ===== Mode 6-4: Î±=1.0 scale ç¼“å­˜ =====
import os as _os
_PA1_SCALES_CACHE = {}  # {model_size: {layer_idx: output_scale}}
_PA1_MODEL_PATHS = {
    '130m': '/workspace/Quamba/pretrained/130mpercentile1125/130mpercentile1125/pa-1/quamba-130m-w8a8',
    '1.4b': '/workspace/Quamba/pretrained/percentile1125/1p4b/pa-1/quamba-1.4b-w8a8',
    '2.8b': '/workspace/Quamba/pretrained/percentile1125/2p8b/pa-1/quamba-2.8b-w8a8',
}
# ===== END Mode 6-4 =====
import torch.nn as nn
import torch.nn.functional as F
from torch import Tensor

from einops import rearrange, repeat

try:
    from causal_conv1d import causal_conv1d_fn, causal_conv1d_update
except ImportError:
    causal_conv1d_fn, causal_conv1d_update = None, None

from mamba_ssm.ops.selective_scan_interface import selective_scan_fn
from mamba_ssm.ops.triton.selective_state_update import selective_state_update
from mamba_ssm.modules.mamba_simple import Mamba

from .qActLayer import QAct, ActIdentity
from .qLinearLayer import W4A16B16O16Linear
from .qLinearLayer import W4A8B8O8Linear, W4A8B16O16Linear
from .qLinearLayer import W8A8B8O8Linear, W8A8B16O16Linear
from .qLinearLayer import HadLinear
from .qConvLayer import QCausalConv1D
from .qSelectiveScan import QSScan
from .qHadamard import Hadamard, QHadamard


class MambaSimple(nn.Module):
    def __init__(
        self,
        originalLayer: Mamba,
        use_had_transform: bool = True
    ):
        super().__init__()
        self.d_model = originalLayer.d_model
        self.d_state = originalLayer.d_state
        self.d_conv = originalLayer.d_conv
        self.expand = originalLayer.expand
        self.d_inner = originalLayer.d_inner
        self.dt_rank = originalLayer.dt_rank
        # self.use_fast_path = originalLayer.use_fast_path
        self.use_fast_path = False # DO NOT USE FAST PATH for quantization experiments
        self.layer_idx = originalLayer.layer_idx
        self.use_had_transform = use_had_transform
        
        # input proj
        if use_had_transform:
            self.in_proj = HadLinear(originalLayer.in_proj, input_transform=True, output_transform=False)
        else:
            self.in_proj = copy.deepcopy(originalLayer.in_proj)
        # causal conv
        self.conv1d = copy.deepcopy(originalLayer.conv1d)
        self.activation = "silu"
        self.act = nn.SiLU()
        # B, C, dt
        self.x_proj = copy.deepcopy(originalLayer.x_proj)
        self.dt_proj = copy.deepcopy(originalLayer.dt_proj)
        self.dt_proj.bias = None
        self.dt_proj_bias = originalLayer.dt_proj.bias.clone().float()
        # ascan
        self.A_log = copy.deepcopy(originalLayer.A_log)
        self.D = copy.deepcopy(originalLayer.D)
        self.ssm_state_act = ActIdentity(tensor_name="ssm_state_act")
        # output proj
        if use_had_transform:
            self.had = Hadamard(originalLayer.out_proj.in_features)
            self.out_proj = HadLinear(originalLayer.out_proj, input_transform=True, output_transform=True)
        else:
            self.had = nn.Identity()
            self.out_proj = copy.deepcopy(originalLayer.out_proj)

    def forward(self, hidden_states, inference_params=None):
        """
        hidden_states: (B, L, D)
        Returns: same shape as hidden_states
        """
        
        #assert hidden_states.shape[0] == 1, "Current only support bsz=1"
        batch, seqlen, dim = hidden_states.shape

        conv_state, ssm_state = None, None
        if inference_params is not None:
            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)
            if inference_params.seqlen_offset > 0:
                # The states are updated inplace
                out, _, _ = self.step(hidden_states, conv_state, ssm_state)
                return out
            
        #NOTE(brian1009): Simplified of original implementation 
        # https://github.com/state-spaces/mamba/blob/main/mamba_ssm/modules/mamba_simple.py#L134
        xz = self.in_proj(hidden_states) #(B, L, 2*D)
        xz = rearrange(xz, "b l d -> b d l") 
        x, z = xz.chunk(2, dim=1) #(B, D, L), #(B, D, L)
        
        # Compute short convolution
        if conv_state is not None:
            # If we just take x[:, :, -self.d_conv :], it will error if seqlen < self.d_conv
            # Instead F.pad will pad with zeros if seqlen < self.d_conv, and truncate otherwise.
            conv_state.copy_(F.pad(x, (self.d_conv - x.shape[-1], 0)))  # Update state (B D W)

        x = self.conv1d(x)
        x = self.act(x[...,:seqlen])
        #NOTE(brian1009): 2024/03/27 Do not squeeze the dimension of (b l), to make sure that QAct will always take the input dimension of (b, l, d)
        x_reshape = rearrange(x, "b d l -> b l d")
        x_dbl = self.x_proj(x_reshape)  # (bl d)
        dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        
        #NOTE(brian1009): Comment this line and do the inference directly with the forward in the module
        dt = self.dt_proj(dt)

        #NOTE(brian1009): 2024/03/27 Do not squeeze the dimension of (b l), to make sure that QAct will always take the input dimension of (b, l, d)
        dt = rearrange(dt, "b l d -> b d l", l=seqlen)
        B = rearrange(B, "b l dstate -> b dstate l", l=seqlen).contiguous()
        C = rearrange(C, "b l dstate -> b dstate l", l=seqlen).contiguous()
        
        assert self.activation in ["silu", "swish"]
        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)
        y = selective_scan_fn(
                x,
                dt,
                A,
                B,
                C,
                self.D.float(),
                z=z,
                delta_bias=self.dt_proj_bias,
                # delta_bias=None,  # delta_bias has been added in dt_proj
                delta_softplus=True,
                return_last_state=ssm_state is not None,
            )

        if ssm_state is not None:
            y, last_state = y
            ssm_state.copy_(last_state)
            ssm_state = self.ssm_state_act(ssm_state)
        y = rearrange(y, "b d l -> b l d") 
        y = self.had(y)
        out = self.out_proj(y)
        return out

    def step(self, hidden_states, conv_state, ssm_state):
        dtype = hidden_states.dtype
        assert hidden_states.shape[1] == 1, "Only support decoding with 1 token at a time for now"

        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)
        x, z = xz.chunk(2, dim=-1)  # (B D)

        # Conv step
        if causal_conv1d_update is None:
            conv_state.copy_(torch.roll(conv_state, shifts=-1, dims=-1))  # Update state (B D W)
            conv_state[:, :, -1] = x
            w_quant, w_scales = self.conv1d.quant_weight
            x = torch.sum(conv_state * rearrange(w_quant, "d 1 w -> d w"), dim=-1)  # (B D)
            if self.conv1d.bias is not None:
                x = x + self.conv1d.bias
            x = self.act(x).to(dtype=dtype)
        else:
            x = causal_conv1d_update(
                x,
                conv_state,
                rearrange(self.conv1d.weight, "d 1 w -> d w"),
                self.conv1d.bias,
                self.activation,
            )

        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)
        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        dt = self.dt_proj(dt)
        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)

        # SSM step
        # Discretize A and B
        dt = F.softplus(dt+self.dt_proj_bias)
        dA = torch.exp(torch.einsum("bd,dn->bdn", dt, A))
        dB = torch.einsum("bd,bn->bdn", dt, B)
        ssm_state.copy_(ssm_state * dA + rearrange(x, "b d -> b d 1") * dB)
        y = torch.einsum("bdn,bn->bd", ssm_state.to(dtype), C)
        y = y + self.D.to(dtype) * x
        y = y * self.act(z)  # (B D)

        y = self.had(y)
        out = self.out_proj(y)
        return out.unsqueeze(1), conv_state, ssm_state

    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):
        device = self.out_proj.weight.device
        conv_dtype = self.conv1d.weight.dtype if dtype is None else dtype
        conv_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype
        )
        ssm_dtype = self.dt_proj.weight.dtype if dtype is None else dtype
        ssm_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype
        )
        return conv_state, ssm_state

    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):
        assert self.layer_idx is not None
        if self.layer_idx not in inference_params.key_value_memory_dict:
            batch_shape = (batch_size,)
            conv_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_conv,
                device=self.conv1d.weight.device,
                dtype=self.conv1d.weight.dtype,
            )
            ssm_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_state,
                device=self.dt_proj.weight.device,
                dtype=self.dt_proj.weight.dtype,
            )
            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)
        else:
            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]
            # TODO: What if batch size changes between generation, and we reuse the same states?
            if initialize_states:
                conv_state.zero_()
                ssm_state.zero_()
        return conv_state, ssm_state


class W4A16QMamba(nn.Module):

    def __init__(
        self,
        d_model,
        d_state=16,
        d_conv=4,
        expand=2,
        dt_rank="auto",
        dt_min=0.001,
        dt_max=0.1,
        dt_init="random",
        dt_scale=1.0,
        dt_init_floor=1e-4,
        conv_bias=True,
        bias=False,
        use_had_transform=True,
        use_fast_path=True,  # Fused kernel options
        layer_idx=None,
        device=None,
        dtype=None,
    ):
        factory_kwargs = {"device": device, "dtype": torch.float16}
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.d_conv = d_conv
        self.expand = expand
        self.d_inner = int(self.expand * self.d_model)
        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == "auto" else dt_rank
        self.use_fast_path = use_fast_path
        self.layer_idx = layer_idx
        assert bias is False, "Only support bias=False for now"

        self.in_proj = W4A16B16O16Linear(self.d_model, self.d_inner * 2, group_size=128)

        self.conv1d = nn.Conv1d(
            in_channels=self.d_inner,
            out_channels=self.d_inner,
            bias=conv_bias,
            kernel_size=d_conv,
            groups=self.d_inner,
            padding=d_conv - 1,
            **factory_kwargs,
        )

        self.activation = "silu"
        self.act = nn.SiLU()

        self.x_proj = W4A16B16O16Linear(
            self.d_inner, self.dt_rank + self.d_state * 2, group_size=128
        )
        # we seperate the bias, so we set bias=False here
        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=False, **factory_kwargs)
        self.register_buffer("dt_proj_bias", torch.empty(
            self.d_inner, device=factory_kwargs["device"], dtype=torch.float32))

        # Initialize special dt projection to preserve variance at initialization
        dt_init_std = self.dt_rank**-0.5 * dt_scale
        if dt_init == "constant":
            nn.init.constant_(self.dt_proj.weight, dt_init_std)
        elif dt_init == "random":
            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)
        else:
            raise NotImplementedError

        # Initialize dt bias so that F.softplus(dt_bias) is between dt_min and dt_max
        dt = torch.exp(
            torch.rand(self.d_inner, **factory_kwargs) * (math.log(dt_max) - math.log(dt_min))
            + math.log(dt_min)
        ).clamp(min=dt_init_floor)
        # Inverse of softplus: https://github.com/pytorch/pytorch/issues/72759
        inv_dt = dt + torch.log(-torch.expm1(-dt))
        with torch.no_grad():
            self.dt_proj_bias.copy_(inv_dt)
        # Our initialization would set all Linear.bias to zero, need to mark this one as _no_reinit
        self.dt_proj_bias._no_reinit = True

        # S4D real initialization
        A = repeat(
            torch.arange(1, self.d_state + 1, dtype=torch.float32, device=device),
            "n -> d n",
            d=self.d_inner,
        ).contiguous()
        A_log = torch.log(A)  # Keep A_log in fp32
        self.A_log = nn.Parameter(A_log)
        self.A_log._no_weight_decay = True

        # D "skip" parameter
        self.D = nn.Parameter(torch.ones(self.d_inner, device=device))  # Keep in fp32
        self.D._no_weight_decay = True
        # output proj
        if use_had_transform:
            self.had = Hadamard(self.d_inner)
        else:
            self.had = nn.Identity()
        self.out_proj = W4A16B16O16Linear(self.d_inner, self.d_model, group_size=128)

    @classmethod
    def from_fp16(cls, originalLayer: Mamba, use_had_transform: bool = True):
        
        qmixer = cls(
            d_model=originalLayer.d_model,
            d_state=originalLayer.d_state,
            d_conv=originalLayer.d_conv,
            expand=originalLayer.expand,
            dt_rank=originalLayer.dt_rank,
            use_had_transform = use_had_transform,
            use_fast_path=False,  # Fused kernel options
            layer_idx=originalLayer.layer_idx,
            device=torch.device("cuda"),
            dtype=torch.float16,
        )
        
        # input proj, weight group_size=128
        qmixer.in_proj = W4A16B16O16Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.in_proj),
        )
        # causal conv
        qmixer.conv1d = copy.deepcopy(originalLayer.conv1d)
        qmixer.activation = "silu"
        qmixer.act = nn.SiLU()
        # B, C, dt
        qmixer.x_proj = W4A16B16O16Linear.from_fp16(copy.deepcopy(originalLayer.x_proj))
        # We use FP16 dt_proj, becuase w4a16o16 does not support M=bsize, K=48, N=1536
        qmixer.dt_proj = copy.deepcopy(originalLayer.dt_proj)
        qmixer.dt_proj_bias = originalLayer.dt_proj_bias.clone() # MambaSimple has separated bias 
        # ascan
        qmixer.A_log = copy.deepcopy(originalLayer.A_log)
        qmixer.D = copy.deepcopy(originalLayer.D)
        # output proj
        if use_had_transform:
            qmixer.had = Hadamard(originalLayer.out_proj.in_features)
        else:
            qmixer.had = nn.Identity()
        qmixer.out_proj = W4A16B16O16Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.out_proj),
        )
        return qmixer

    def forward(self, hidden_states, inference_params=None):
        """
        hidden_states: (B, L, D)
        Returns: same shape as hidden_states
        """
        
        #assert hidden_states.shape[0] == 1, "Current only support bsz=1"
        batch, seqlen, dim = hidden_states.shape

        conv_state, ssm_state = None, None
        if inference_params is not None:
            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)
            if inference_params.seqlen_offset > 0:
                # The states are updated inplace
                out, _, _ = self.step(hidden_states, conv_state, ssm_state)
                return out
            
        # xz = self.in_proj(hidden_states) #(B, 2*D, L)
        # xz = rearrange(xz, "b l d -> b d l")
        xz = self.in_proj.to_seqlen_last(hidden_states) #(B, 2*D, L)
        x, z = xz.chunk(2, dim=1) #(B, D, L), #(B, D, L)
        
        # Compute short convolution
        if conv_state is not None:
            # If we just take x[:, :, -self.d_conv :], it will error if seqlen < self.d_conv
            # Instead F.pad will pad with zeros if seqlen < self.d_conv, and truncate otherwise.
            conv_state.copy_(F.pad(x, (self.d_conv - x.shape[-1], 0)))  # Update state (B D W)

        assert self.activation in ["silu", "swish"]
        x = causal_conv1d_fn(
            x=x,
            weight=rearrange(self.conv1d.weight, "d 1 w -> d w"),
            bias=self.conv1d.bias,
            activation=self.activation,
        )

        # we need a contiguous here for W4A16B16O16
        x_reshape = rearrange(x, "b d l -> (b l) d").contiguous()
        x_dbl = self.x_proj(x_reshape)  # (bl d)
        dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        
        dt = self.dt_proj.weight @ dt.t()
        dt = rearrange(dt, "d (b l) -> b d l", l=seqlen)
        B = rearrange(B, "(b l) dstate -> b dstate l", l=seqlen).contiguous()
        C = rearrange(C, "(b l) dstate -> b dstate l", l=seqlen).contiguous()
        
        assert self.activation in ["silu", "swish"]
        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)
        y = selective_scan_fn(
                x,
                dt,
                A,
                B,
                C,
                self.D.float(),
                z=z,
                delta_bias=self.dt_proj_bias,
                # delta_bias=None,  # delta_bias has been added in dt_proj
                delta_softplus=True,
                return_last_state=ssm_state is not None,
            )

        if ssm_state is not None:
            y, last_state = y
            ssm_state.copy_(last_state)
        y = rearrange(y, "b d l -> b l d") 
        y = self.had(y)
        out = self.out_proj(y)
        return out

    def step(self, hidden_states, conv_state, ssm_state):
        dtype = hidden_states.dtype
        assert hidden_states.shape[1] == 1, "Only support decoding with 1 token at a time for now"
        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)
        x, z = xz.chunk(2, dim=-1)  # (B D)

        # Conv step
        x = causal_conv1d_update(
            x,
            conv_state,
            rearrange(self.conv1d.weight, "d 1 w -> d w"),
            self.conv1d.bias,
            self.activation,
        )

        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)
        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt = self.dt_proj(dt) # (B d_inner)
        A = -torch.exp(self.A_log.float())  # (d_inner, d_state)

        # SSM step
        y = selective_state_update(
            ssm_state, x, dt, A, B, C, self.D, z=z, dt_bias=self.dt_proj_bias, dt_softplus=True
        )
        y = self.had(y)
        out = self.out_proj(y)
        return out.unsqueeze(1), conv_state, ssm_state

    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):
        device = self.out_proj.weight.device
        conv_dtype = torch.float16
        conv_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype
        )
        ssm_dtype = torch.float16
        ssm_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype
        )
        return conv_state, ssm_state

    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):
        assert self.layer_idx is not None
        # conv_dtype is torch.float16
        conv_dtype = torch.float16
        # ssm_dtype is torch.float16
        ssm_dtype = torch.float16
        if self.layer_idx not in inference_params.key_value_memory_dict:
            batch_shape = (batch_size,)
            conv_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_conv,
                device=self.conv1d.weight.device,
                dtype=conv_dtype,
            )
            ssm_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_state,
                device=self.dt_proj.weight.device,
                dtype=ssm_dtype,
            )
            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)
        else:
            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]
            # TODO: What if batch size changes between generation, and we reuse the same states?
            if initialize_states:
                conv_state.zero_()
                ssm_state.zero_()
        return conv_state, ssm_state


class W4A8QMamba(nn.Module):

    def __init__(
        self,
        d_model,
        d_state=16,
        d_conv=4,
        expand=2,
        dt_rank="auto",
        dt_min=0.001,
        dt_max=0.1,
        dt_init="random",
        dt_scale=1.0,
        dt_init_floor=1e-4,
        conv_bias=True,
        bias=False,
        use_had_transform=True,
        use_fast_path=True,  # Fused kernel options
        layer_idx=None,
        device=None,
        dtype=None,
    ):
        factory_kwargs = {"device": device, "dtype": torch.float16}
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.d_conv = d_conv
        self.expand = expand
        self.d_inner = int(self.expand * self.d_model)
        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == "auto" else dt_rank
        self.use_fast_path = use_fast_path
        self.layer_idx = layer_idx
        assert bias is False, "Only support bias=False for now"

        self.in_proj = W4A8B8O8Linear(self.d_model, self.d_inner * 2, group_size=128)

        self.conv1d = QCausalConv1D(
            in_channels=self.d_inner,
            out_channels=self.d_inner,
            bias=conv_bias,
            kernel_size=d_conv,
            groups=self.d_inner,
            padding=d_conv - 1,
        )

        self.activation = "silu"
        self.act = nn.SiLU()

        self.x_proj = W4A8B8O8Linear(
            self.d_inner, self.dt_rank + self.d_state * 2, group_size=128
        )
        # we seperate the bias and put the bias in the QSScan
        self.dt_proj = W8A8B8O8Linear(self.dt_rank, self.d_inner)

        # Quantized selective scan
        self.selective_scan = QSScan(d_state=self.d_state, d_inner=self.d_inner, delta_softplus=True)

        # output proj
        if use_had_transform:
            self.had = QHadamard(self.d_inner, x_H_scale=1.0)
        else:
            self.had = QAct(scale=1.0)
        self.out_proj = W4A8B16O16Linear(self.d_inner, self.d_model, group_size=128)

    @classmethod
    def from_fp16(cls, originalLayer: MambaSimple, act_scales: Dict, use_had_transform: bool = True):

        qmixer = cls(
            d_model=originalLayer.d_model,
            d_state=originalLayer.d_state,
            d_conv=originalLayer.d_conv,
            expand=originalLayer.expand,
            dt_rank=originalLayer.dt_rank,
            use_had_transform = use_had_transform,
            use_fast_path=False,  # Fused kernel options
            layer_idx=originalLayer.layer_idx,
            device=torch.device("cuda"),
            dtype=torch.float16,
        )

        # input proj, weight group_size=128
        qmixer.in_proj = W4A8B8O8Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.in_proj),
            input_scale=act_scales["in_proj:input"],
            output_scale=act_scales["in_proj:output"],
        )

        # causal conv
        # no used, silu is fused in causal_conv1d
        qmixer.activation = "silu"
        assert qmixer.activation == "silu"
        qmixer.conv1d = QCausalConv1D.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.conv1d),
            input_scale=act_scales["in_proj:output"].item(),
            output_scale=act_scales["x_proj:input"].item(),            
        )

        # x_proj
        qmixer.x_proj = W4A8B8O8Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.x_proj),
            input_scale=act_scales["x_proj:input"],
            output_scale=act_scales["x_proj:output"],
        )

        # We use W8A8B8O8 dt_proj, becuase W4A8B8O8 does not support M=bsize, K=48, N=1536
        qmixer.dt_proj = W8A8B8O8Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.dt_proj),
            input_scale=act_scales["x_proj:output"].item(), # use x_proj_scale to avoid additional quantization operations
            output_scale=act_scales["dt_proj:output"].item(),
        )

        # ascan
        qmixer.selective_scan = QSScan.from_fp16(
            originalLayer.d_state, originalLayer.d_inner,
            originalLayer.A_log.clone(), D=originalLayer.D.clone(),
            dt_bias=originalLayer.dt_proj_bias.clone(), delta_softplus=True,
            ssm_state_scale=act_scales["ssm_state_act:input"],
            u_scale=act_scales["x_proj:input"],
            dt_scale=act_scales["dt_proj:output"],
            B_scale=act_scales["x_proj:output"],
            C_scale=act_scales["x_proj:output"],
            z_scale=act_scales["in_proj:output"],
        )

        # output proj
        if use_had_transform:
            qmixer.had.x_H_scale = act_scales["out_proj:input"].item()
        else:
            qmixer.had.scale = act_scales["out_proj:input"].item()
        qmixer.out_proj = W4A8B16O16Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.out_proj),
            input_scale=act_scales["out_proj:input"],
        )
        return qmixer

    def forward(self, hidden_states, inference_params=None):
        """
        hidden_states: (B, L, D)
        Returns: same shape as hidden_states
        """
        #assert hidden_states.shape[0] == 1, "Current only support bsz=1"
        batch, seqlen, dim = hidden_states.shape

        conv_state, ssm_state = None, None
        if inference_params is not None:
            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)
            if inference_params.seqlen_offset > 0:
                # The states are updated inplace
                out, _, _ = self.step(hidden_states, conv_state, ssm_state)
                return out

        xz = self.in_proj.to_seqlen_last(hidden_states) # (B, D, L) 
        x, z = xz.chunk(2, dim=1) #(B, D, L), #(B, D, L)
        
        # Perform causal conv1d and return conv_state
        if conv_state is not None:
            # store quantized x into conv_state
            # If we just take x[:, :, -self.d_conv :], it will error if seqlen < self.d_conv
            # Instead F.pad will pad with zeros if seqlen < self.d_conv, and truncate otherwise.
            conv_state.copy_(F.pad(x, (self.d_conv - x.shape[-1], 0)))  # Update state (B D W)
        x = self.conv1d.forward(x)

        # Check if FP32 SSM mode is enabled (requires requantization for x_proj)
        import os
        fp32_mode_enabled = (
            os.environ.get('FLOAT_SIM_ASIC_INT8', 'false').lower() == 'true' or
            os.environ.get('CONV1D_MODE24_FP32', 'false').lower() == 'true' or
            os.environ.get('CONV1D_MODE3_FP32', 'false').lower() == 'true'
        )

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # # Only debug last layer (layer_idx == 23 for 24-layer model)
        # DEBUG_ENABLED = self.layer_idx is not None and self.layer_idx == 23
        # if DEBUG_ENABLED:
        #     if not hasattr(self, '_debug_step_count'):
        #         self._debug_step_count = 0
        #     self._debug_step_count += 1
        #     # Only print first 3 calls for this layer
        #     if self._debug_step_count <= 3:
        #         print(f"\n{'='*80}")
        #         print(f"[Layer {self.layer_idx} Call #{self._debug_step_count}] After Conv1D")
        #         print(f"  x dtype: {x.dtype}, shape: {x.shape}")
        #         x_vals = x.flatten()[:10]
        #         print(f"  First 10 values (high precision):")
        #         for i in range(min(10, x_vals.numel())):
        #             print(f"    x[{i}] = {x_vals[i]:.12f}" if x.dtype == torch.float32 else f"    x[{i}] = {x_vals[i]}")
        #         if hasattr(x, '_dual_scale_overflow_mask'):
        #             print(f"  x has dual-scale metadata (outliers: {x._dual_scale_overflow_mask.sum().item()})")

        #         # Print all scales for this layer (first call only)
        #         if self._debug_step_count == 1:
        #             print(f"\n  === Layer {self.layer_idx} All Scales ===")
        #             print(f"  in_proj scales:")
        #             if hasattr(self.in_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.in_proj.input_scale:.10f}")
        #             if hasattr(self.in_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.in_proj.weight_scale:.10f}")
        #             if hasattr(self.in_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.in_proj.output_scale:.10f}")

        #             print(f"  conv1d scales:")
        #             print(f"    input_scale: {self.conv1d.input_scale:.10f}")
        #             print(f"    weight_scale: {self.conv1d.weight_scale:.10f}")
        #             if hasattr(self.conv1d, 'bias_scale') and self.conv1d.bias_scale is not None:
        #                 print(f"    bias_scale: {self.conv1d.bias_scale:.10f}")
        #             print(f"    output_scale: {self.conv1d.output_scale:.10f}")

        #             print(f"  x_proj scales:")
        #             if hasattr(self.x_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.x_proj.input_scale:.10f}")
        #             if hasattr(self.x_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.x_proj.weight_scale:.10f}")
        #             if hasattr(self.x_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.x_proj.output_scale:.10f}")

        #             print(f"  selective_scan scales:")
        #             if hasattr(self.selective_scan, 'u_scale'):
        #                 print(f"    u_scale: {self.selective_scan.u_scale:.10f}")
        #             if hasattr(self.selective_scan, 'dt_scale'):
        #                 print(f"    dt_scale: {self.selective_scan.dt_scale:.10f}")

        #             print(f"  out_proj scales:")
        #             if hasattr(self.out_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.out_proj.input_scale:.10f}")
        #             if hasattr(self.out_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.out_proj.weight_scale:.10f}")
        #             if hasattr(self.out_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.out_proj.output_scale:.10f}")
        # # ===== END TEMPORARY DEBUG CODE =====

        # Convert Conv1D output for use in SSM
        # Different modes have different requirements for SSM input dtype
        if fp32_mode_enabled:
            # Check mode-specific environment variables
            ssm_use_pytorch_int8 = os.environ.get('SSM_USE_PYTORCH_INT8', 'false').lower() == 'true'
            conv1d_mode23_fp32 = os.environ.get('CONV1D_MODE23_FP32', 'false').lower() == 'true'

            if x.dtype == torch.int8:
                # x is INT8 from Conv1D (Mode 2-0, 2-1, 2-2, 2-3 when FLOAT_SIM_ASIC_INT8=true)
                x_for_xproj = x  # INT8 for x_proj

                # Mode 2-1: Keep INT8 for PyTorch INT8 SSM (direct pass, no dequant)
                # Mode 2-0, 2-2: Dequantize to FP32 for SSM
                if ssm_use_pytorch_int8 and not conv1d_mode23_fp32:
                    # Mode 2-1: PyTorch INT8 SSM expects INT8 input directly
                    x_for_ssm = x  # Keep INT8
                else:
                    # Mode 2-0 (CUDA INT8 SSM with requant), Mode 2-2 (FP32 SSM)
                    x_for_ssm = x.float() * self.conv1d.output_scale  # Dequantize to FP32
            elif x.dtype == torch.float32:
                # x is FP32 from Conv1D (Mode 2-3, 2-4)
                # Requantize to INT8 for x_proj, keep FP32 for SSM
                x_for_xproj = torch.round(x / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
                x_for_ssm = x  # Keep FP32 for SSM
            else:
                raise ValueError(f"Unexpected dtype in fp32_mode_enabled: {x.dtype}")

            # Compute dt, B, C using INT8
            x_reshape = rearrange(x_for_xproj, "b d l -> b l d").contiguous()
            x_dbl = self.x_proj(x_reshape)  # (bl d)
            dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)

            # Compute dt proj with x_proj_scale
            dt = self.dt_proj.to_seqlen_last(dt.contiguous())
            B = rearrange(B, "b l dstate -> b dstate l", l=seqlen).contiguous()
            C = rearrange(C, "b l dstate -> b dstate l", l=seqlen).contiguous()

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After dt_proj: dt dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            #     print(f"  B dtype: {B.dtype}, first 3: {B.flatten()[:3].tolist()}")
            #     print(f"  C dtype: {C.dtype}, first 3: {C.flatten()[:3].tolist()}")
            #     print(f"  z dtype: {z.dtype if z is not None else 'None'}, first 3: {z.flatten()[:3].tolist() if z is not None else 'N/A'}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # Print Layer 24 SSM scales (before SSM forward) - only once
            if self.layer_idx == 23:
                if not hasattr(self, '_ssm_scales_printed'):
                    self._ssm_scales_printed = False

                if not self._ssm_scales_printed:
                    print(f"\n{'='*80}")
                    print(f"[Layer 24 / layer_idx {self.layer_idx}] SSM Scales")
                    print(f"{'='*80}")
                    print(f"  Location: qMambaLayer.py forward() - fp32_mode_enabled branch")
                    print(f"  ")
                    print(f"  SSM Input Data (before SSM.forward):")
                    print(f"    u dtype: {x_for_ssm.dtype}")
                    print(f"    u first 5 values [0,0,:5]: {x_for_ssm[0, 0, :5].tolist()}")
                    print(f"    dt first 5 values [0,0,:5]: {dt[0, 0, :5].tolist()}")
                    print(f"    B first 5 values [0,0,:5]: {B[0, 0, :5].tolist()}")
                    print(f"    C first 5 values [0,0,:5]: {C[0, 0, :5].tolist()}")
                    print(f"    dt/B/C dtype: {dt.dtype}")
                    print(f"  ")
                    print(f"  SSM Scales (from self.selective_scan / QSScan):")
                    print(f"    u_scale          = {self.selective_scan.u_scale.item():.10f}  (for SSM input u)")
                    print(f"    dt_scale         = {self.selective_scan.dt_scale.item():.10f}  (for dt)")
                    print(f"    B_scale          = {self.selective_scan.B_scale.item():.10f}  (for B)")
                    print(f"    C_scale          = {self.selective_scan.C_scale.item():.10f}  (for C)")
                    print(f"    A_scale          = {self.selective_scan.A_scale.item():.10f}  (for A)")
                    print(f"    D_scale          = {self.selective_scan.D_scale.item():.10f}  (for D)")
                    print(f"    z_scale          = {self.selective_scan.z_scale.item():.10f}  (for z)")
                    print(f"    ssm_state_scale  = {self.selective_scan.ssm_state_scale.item():.10f}  (for state)")
                    print(f"    dt_bias_scale    = {self.selective_scan.dt_bias_scale.item():.10f}  (for dt_bias)")
                    print(f"  ")
                    print(f"  âš ï¸  Important: Conv1D output_scale should match SSM u_scale")
                    print(f"    (Conv1D output_scale printed above)")
                    print(f"    SSM u_scale = {self.selective_scan.u_scale.item():.10f}")
                    print(f"{'='*80}\n")
                    self._ssm_scales_printed = True

                    # Quick verification mode: exit after printing Layer 24 SSM scales
                    if os.environ.get('QUICK_VERIFY', 'false').lower() == 'true':
                        print("ðŸ” QUICK_VERIFY mode: Exiting after Layer 24 SSM input data print")
                        import sys
                        sys.exit(0)

            # ===== DUAL MODE DEBUG: Compare Mode 2-0 vs 2-1 =====
            # Run for ALL samples (remove the hasattr check)
            if self.layer_idx == 23 and os.environ.get('DUAL_MODE_DEBUG', 'false').lower() == 'true':
                dual_mode_compare_ssm(self, x, dt, B, C, z, self.conv1d.output_scale)

            # SSM with FP32 input (ONLY u is FP32, dt/B/C are INT8)
            y = self.selective_scan.forward(x_for_ssm, dt, B, C, z=z, return_last_state=ssm_state is not None)
        else:
            # Original INT8 path (completely unchanged)
            x_reshape = rearrange(x, "b d l -> b l d").contiguous()
            x_dbl = self.x_proj(x_reshape)  # (bl d)
            dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After x_proj: x_dbl dtype: {x_dbl.dtype}, first 3: {x_dbl.flatten()[:3].tolist()}")
            #     print(f"  dt (before dt_proj) dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # Compute dt proj with x_proj_scale
            dt = self.dt_proj.to_seqlen_last(dt.contiguous())
            B = rearrange(B, "b l dstate -> b dstate l", l=seqlen).contiguous()
            C = rearrange(C, "b l dstate -> b dstate l", l=seqlen).contiguous()

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After dt_proj: dt dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            #     print(f"  B dtype: {B.dtype}, first 3: {B.flatten()[:3].tolist()}")
            #     print(f"  C dtype: {C.dtype}, first 3: {C.flatten()[:3].tolist()}")
            #     print(f"  z dtype: {z.dtype if z is not None else 'None'}, first 3: {z.flatten()[:3].tolist() if z is not None else 'N/A'}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # ===== DEBUG: Mode 0 Scaleå’Œè¾“å‡º =====
            if os.environ.get('DEBUG_MODE0_VS_MODE50', 'false').lower() == 'true':
                if self.layer_idx == 23:
                    if not hasattr(self, '_mode0_debug_count'):
                        self._mode0_debug_count = 0
                    self._mode0_debug_count += 1
                    if self._mode0_debug_count == 1:
                        print(f"\n{'='*80}")
                        print(f"[Mode 0 - Layer 24] Scaleå’Œè¾“å‡ºå¯¹æ¯”")
                        print(f"{'='*80}")
                        print(f"  conv1d.output_scale: {self.conv1d.output_scale:.10f}")
                        print(f"  x_proj.a (input/output scale): {self.x_proj.a.item():.10f}")
                        print(f"  selective_scan.u_scale: {self.selective_scan.u_scale.item():.10f}")
                        print(f"  x (INT8) [0,0,:5]: {x[0,0,:5].tolist()}")
                        print(f"  x (dequant) [0,0,:5]: {(x.float()*self.conv1d.output_scale)[0,0,:5].tolist()}")
                        print(f"  dt (INT8) [0,0,:5]: {dt[0,0,:5].tolist()}")
                        print(f"  B (INT8) [0,0,:5]: {B[0,0,:5].tolist()}")
                        print(f"  C (INT8) [0,0,:5]: {C[0,0,:5].tolist()}")
                        print(f"{'='*80}\n")
            # ===== END DEBUG =====

            # SSM step and return ssm_state
            y = self.selective_scan.forward(x, dt, B, C, z=z, return_last_state=ssm_state is not None)

            # ===== DEBUG: Mode 0 SSMè¾“å‡º =====
            if os.environ.get('DEBUG_MODE0_VS_MODE50', 'false').lower() == 'true':
                if self.layer_idx == 23 and self._mode0_debug_count == 1:
                    print(f"[Mode 0] SSM output y[0,0,:5]: {y[0,0,:5].tolist()}")
            # ===== END DEBUG =====

        if ssm_state is not None:
            y, last_state = y # y: fp16, last_state: fp32
            ssm_state.copy_(last_state) # last_state: fp32 copy to ssm_state: fp16

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After SSM: y dtype: {y.dtype}, first 3: {y.flatten()[:3].tolist()}")
        # # ===== END TEMPORARY DEBUG CODE =====

        # Output projection
        y = self.had(y) # input fp16, output is int8

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After had: y dtype: {y.dtype}, first 3: {y.flatten()[:3].tolist()}")
        # # ===== END TEMPORARY DEBUG CODE =====

        out = self.out_proj(y) # HadW8A8BF16OF16Linear: input int8, output is fp16

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After out_proj: out dtype: {out.dtype}, first 3: {out.flatten()[:3].tolist()}")
        #     print(f"{'='*80}\n")
        # # ===== END TEMPORARY DEBUG CODE =====

        return out

    def step(self, hidden_states, conv_state, ssm_state):
        dtype = hidden_states.dtype
        assert hidden_states.shape[1] == 1, "Only support decoding with 1 token at a time for now"

        # Input projection for x, z
        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)
        x, z = xz.chunk(2, dim=-1)  # (B D)

        # Perform causal conv1d and update conv_state in-place
        x = self.conv1d.update(x, conv_state)

        # Compute dt, B, C 
        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)
        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt = self.dt_proj(dt.contiguous())

        # SSM step and update ssm_state in-place
        y, ssm_state = self.selective_scan.update(ssm_state, x.contiguous(), dt, B, C, z=z)

        # Output projection
        y = self.had(y) # input fp16, output is int8
        out = self.out_proj(y)
        return out.unsqueeze(1), conv_state, ssm_state

    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):
        device = self.out_proj.weight.device
        conv_dtype = torch.int8
        conv_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype
        )
        ssm_dtype = torch.int8
        ssm_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype
        )
        return conv_state, ssm_state

    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):
        assert self.layer_idx is not None
        if self.layer_idx not in inference_params.key_value_memory_dict:
            batch_shape = (batch_size,)
            conv_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_conv,
                device=self.conv1d.weight.device,
                dtype=torch.int8,
            )
            ssm_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_state,
                device=self.dt_proj.weight.device,
                dtype=torch.int8,
            )
            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)
        else:
            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]
            # TODO: What if batch size changes between generation, and we reuse the same states?
            if initialize_states:
                conv_state.zero_()
                ssm_state.zero_()
        return conv_state, ssm_state


class W8A8QMamba(nn.Module):

    def __init__(
        self,
        d_model,
        d_state=16,
        d_conv=4,
        expand=2,
        dt_rank="auto",
        dt_min=0.001,
        dt_max=0.1,
        dt_init="random",
        dt_scale=1.0,
        dt_init_floor=1e-4,
        conv_bias=True,
        bias=False,
        use_had_transform=True,
        use_fast_path=True,  # Fused kernel options
        layer_idx=None,
        device=None,
        dtype=None,
    ):
        factory_kwargs = {"device": device, "dtype": torch.float16}
        super().__init__()
        self.d_model = d_model
        self.d_state = d_state
        self.d_conv = d_conv
        self.expand = expand
        self.d_inner = int(self.expand * self.d_model)
        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == "auto" else dt_rank
        self.use_fast_path = use_fast_path
        self.layer_idx = layer_idx
        assert bias is False, "Only support bias=False for now"

        self.in_proj = W8A8B8O8Linear(self.d_model, self.d_inner * 2)

        self.conv1d = QCausalConv1D(
            in_channels=self.d_inner,
            out_channels=self.d_inner,
            bias=conv_bias,
            kernel_size=d_conv,
            groups=self.d_inner,
            padding=d_conv - 1,
        )

        self.activation = "silu"
        self.act = nn.SiLU()

        self.x_proj = W8A8B8O8Linear(self.d_inner, self.dt_rank + self.d_state * 2)
        # we seperate the bias and put the bias in the QSScan
        self.dt_proj = W8A8B8O8Linear(self.dt_rank, self.d_inner)

        # Quantized selective scan
        self.selective_scan = QSScan(d_state=self.d_state, d_inner=self.d_inner, delta_softplus=True)

        # output proj
        if use_had_transform:
            self.had = QHadamard(self.d_inner, x_H_scale=1.0)
        else:
            self.had = QAct(scale=1.0)
        self.out_proj = W8A8B16O16Linear(self.d_inner, self.d_model)

    @classmethod
    def from_fp16(cls, originalLayer: MambaSimple, act_scales: Dict, use_had_transform: bool = True):

        qmixer = cls(
            d_model=originalLayer.d_model,
            d_state=originalLayer.d_state,
            d_conv=originalLayer.d_conv,
            expand=originalLayer.expand,
            dt_rank=originalLayer.dt_rank,
            use_had_transform = use_had_transform,
            use_fast_path=False,  # Fused kernel options
            layer_idx=originalLayer.layer_idx,
            device=torch.device("cuda"),
            dtype=torch.float16,
        )

        # input proj
        qmixer.in_proj = W8A8B8O8Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.in_proj),
            input_scale=act_scales["in_proj:input"].item(),
            output_scale=act_scales["in_proj:output"].item(),
        )

        # causal conv
        # no used, silu is fused in causal_conv1d
        qmixer.activation = "silu"
        assert qmixer.activation == "silu"
        qmixer.conv1d = QCausalConv1D.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.conv1d),
            input_scale=act_scales["in_proj:output"].item(),
            output_scale=act_scales["x_proj:input"].item(),            
        )

        # x_proj
        qmixer.x_proj = W8A8B8O8Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.x_proj),
            input_scale=act_scales["x_proj:input"].item(),
            output_scale=act_scales["x_proj:output"].item(),
        )

        # dt_proj
        original_dt_proj = copy.deepcopy(originalLayer.dt_proj)
        dt_proj_bias = originalLayer.dt_proj_bias.clone() # MambaSimple has separated bias 
        # original_dt_proj.bias = None
        qmixer.dt_proj = W8A8B8O8Linear.from_fp16(
            originalLayer=original_dt_proj,
            input_scale=act_scales["x_proj:output"].item(), # use x_proj_scale to avoid additional quantization operations
            output_scale=act_scales["dt_proj:output"].item(),
        )

        # ascan
        qmixer.selective_scan = QSScan.from_fp16(
            originalLayer.d_state, originalLayer.d_inner,
            originalLayer.A_log.clone(), D=originalLayer.D.clone(),
            dt_bias=dt_proj_bias, delta_softplus=True,
            ssm_state_scale=act_scales["ssm_state_act:input"],
            u_scale=act_scales["x_proj:input"],
            dt_scale=act_scales["dt_proj:output"],
            B_scale=act_scales["x_proj:output"],
            C_scale=act_scales["x_proj:output"],
            z_scale=act_scales["in_proj:output"],
        )

        # output proj
        if use_had_transform:
            qmixer.had.x_H_scale = act_scales["out_proj:input"].item()
        else:
            qmixer.had.scale = act_scales["out_proj:input"].item()
        qmixer.out_proj = W8A8B16O16Linear.from_fp16(
            originalLayer=copy.deepcopy(originalLayer.out_proj),
            input_scale=act_scales["out_proj:input"].item(),
        )
        return qmixer

    def forward(self, hidden_states, inference_params=None):
        """
        hidden_states: (B, L, D)
        Returns: same shape as hidden_states
        """
        #assert hidden_states.shape[0] == 1, "Current only support bsz=1"
        batch, seqlen, dim = hidden_states.shape

        conv_state, ssm_state = None, None
        if inference_params is not None:
            conv_state, ssm_state = self._get_states_from_cache(inference_params, batch)
            if inference_params.seqlen_offset > 0:
                # The states are updated inplace
                out, _, _ = self.step(hidden_states, conv_state, ssm_state)
                return out

        xz = self.in_proj.to_seqlen_last(hidden_states) #(B, D, L)
        x, z = xz.chunk(2, dim=1) #(B, D, L), #(B, D, L)
        
        # Perform causal conv1d and return conv_state
        if conv_state is not None:
            # store quantized x into conv_state
            # If we just take x[:, :, -self.d_conv :], it will error if seqlen < self.d_conv
            # Instead F.pad will pad with zeros if seqlen < self.d_conv, and truncate otherwise.
            conv_state.copy_(F.pad(x, (self.d_conv - x.shape[-1], 0)))  # Update state (B D W)
        x = self.conv1d.forward(x)

        # Check if FP32 SSM mode is enabled (requires requantization for x_proj)
        import os
        fp32_mode_enabled = (
            os.environ.get('FLOAT_SIM_ASIC_INT8', 'false').lower() == 'true' or
            os.environ.get('CONV1D_MODE24_FP32', 'false').lower() == 'true' or
            os.environ.get('CONV1D_MODE3_FP32', 'false').lower() == 'true'
        )

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # # Only debug last layer (layer_idx == 23 for 24-layer model)
        # DEBUG_ENABLED = self.layer_idx is not None and self.layer_idx == 23
        # if DEBUG_ENABLED:
        #     if not hasattr(self, '_debug_step_count'):
        #         self._debug_step_count = 0
        #     self._debug_step_count += 1
        #     # Only print first 3 calls for this layer
        #     if self._debug_step_count <= 3:
        #         print(f"\n{'='*80}")
        #         print(f"[Layer {self.layer_idx} Call #{self._debug_step_count}] After Conv1D")
        #         print(f"  x dtype: {x.dtype}, shape: {x.shape}")
        #         x_vals = x.flatten()[:10]
        #         print(f"  First 10 values (high precision):")
        #         for i in range(min(10, x_vals.numel())):
        #             print(f"    x[{i}] = {x_vals[i]:.12f}" if x.dtype == torch.float32 else f"    x[{i}] = {x_vals[i]}")
        #         if hasattr(x, '_dual_scale_overflow_mask'):
        #             print(f"  x has dual-scale metadata (outliers: {x._dual_scale_overflow_mask.sum().item()})")

        #         # Print all scales for this layer (first call only)
        #         if self._debug_step_count == 1:
        #             print(f"\n  === Layer {self.layer_idx} All Scales ===")
        #             print(f"  in_proj scales:")
        #             if hasattr(self.in_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.in_proj.input_scale:.10f}")
        #             if hasattr(self.in_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.in_proj.weight_scale:.10f}")
        #             if hasattr(self.in_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.in_proj.output_scale:.10f}")

        #             print(f"  conv1d scales:")
        #             print(f"    input_scale: {self.conv1d.input_scale:.10f}")
        #             print(f"    weight_scale: {self.conv1d.weight_scale:.10f}")
        #             if hasattr(self.conv1d, 'bias_scale') and self.conv1d.bias_scale is not None:
        #                 print(f"    bias_scale: {self.conv1d.bias_scale:.10f}")
        #             print(f"    output_scale: {self.conv1d.output_scale:.10f}")

        #             print(f"  x_proj scales:")
        #             if hasattr(self.x_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.x_proj.input_scale:.10f}")
        #             if hasattr(self.x_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.x_proj.weight_scale:.10f}")
        #             if hasattr(self.x_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.x_proj.output_scale:.10f}")

        #             print(f"  selective_scan scales:")
        #             if hasattr(self.selective_scan, 'u_scale'):
        #                 print(f"    u_scale: {self.selective_scan.u_scale:.10f}")
        #             if hasattr(self.selective_scan, 'dt_scale'):
        #                 print(f"    dt_scale: {self.selective_scan.dt_scale:.10f}")

        #             print(f"  out_proj scales:")
        #             if hasattr(self.out_proj, 'input_scale'):
        #                 print(f"    input_scale: {self.out_proj.input_scale:.10f}")
        #             if hasattr(self.out_proj, 'weight_scale'):
        #                 print(f"    weight_scale: {self.out_proj.weight_scale:.10f}")
        #             if hasattr(self.out_proj, 'output_scale'):
        #                 print(f"    output_scale: {self.out_proj.output_scale:.10f}")
        # # ===== END TEMPORARY DEBUG CODE =====

        # Convert Conv1D output for use in SSM
        # Different modes have different requirements for SSM input dtype
        if fp32_mode_enabled:
            # Check mode-specific environment variables
            ssm_use_pytorch_int8 = os.environ.get('SSM_USE_PYTORCH_INT8', 'false').lower() == 'true'
            conv1d_mode23_fp32 = os.environ.get('CONV1D_MODE23_FP32', 'false').lower() == 'true'

            if x.dtype == torch.int8:
                # x is INT8 from Conv1D (Mode 2-0, 2-1, 2-2, 2-3 when FLOAT_SIM_ASIC_INT8=true)
                x_for_xproj = x  # INT8 for x_proj

                # Mode 2-1: Keep INT8 for PyTorch INT8 SSM (direct pass, no dequant)
                # Mode 2-0, 2-2: Dequantize to FP32 for SSM
                if ssm_use_pytorch_int8 and not conv1d_mode23_fp32:
                    # Mode 2-1: PyTorch INT8 SSM expects INT8 input directly
                    x_for_ssm = x  # Keep INT8
                else:
                    # Mode 2-0 (CUDA INT8 SSM with requant), Mode 2-2 (FP32 SSM)
                    x_for_ssm = x.float() * self.conv1d.output_scale  # Dequantize to FP32
            elif x.dtype == torch.float32:
                # x is FP32 from Conv1D (Mode 2-3, 2-4)
                # Requantize to INT8 for x_proj, keep FP32 for SSM
                x_for_xproj = torch.round(x / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
                x_for_ssm = x  # Keep FP32 for SSM
            else:
                raise ValueError(f"Unexpected dtype in fp32_mode_enabled: {x.dtype}")

            # Compute dt, B, C using INT8
            x_reshape = rearrange(x_for_xproj, "b d l -> b l d").contiguous()
            x_dbl = self.x_proj(x_reshape)  # (bl d)
            dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)

            # Compute dt proj with x_proj_scale
            dt = self.dt_proj.to_seqlen_last(dt.contiguous())
            B = rearrange(B, "b l dstate -> b dstate l", l=seqlen).contiguous()
            C = rearrange(C, "b l dstate -> b dstate l", l=seqlen).contiguous()

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After dt_proj: dt dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            #     print(f"  B dtype: {B.dtype}, first 3: {B.flatten()[:3].tolist()}")
            #     print(f"  C dtype: {C.dtype}, first 3: {C.flatten()[:3].tolist()}")
            #     print(f"  z dtype: {z.dtype if z is not None else 'None'}, first 3: {z.flatten()[:3].tolist() if z is not None else 'N/A'}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # Print Layer 24 SSM scales (before SSM forward) - only once
            if self.layer_idx == 23:
                if not hasattr(self, '_ssm_scales_printed'):
                    self._ssm_scales_printed = False

                if not self._ssm_scales_printed:
                    print(f"\n{'='*80}")
                    print(f"[Layer 24 / layer_idx {self.layer_idx}] SSM Scales")
                    print(f"{'='*80}")
                    print(f"  Location: qMambaLayer.py forward() - fp32_mode_enabled branch")
                    print(f"  ")
                    print(f"  SSM Input Data (before SSM.forward):")
                    print(f"    u dtype: {x_for_ssm.dtype}")
                    print(f"    u first 5 values [0,0,:5]: {x_for_ssm[0, 0, :5].tolist()}")
                    print(f"    dt first 5 values [0,0,:5]: {dt[0, 0, :5].tolist()}")
                    print(f"    B first 5 values [0,0,:5]: {B[0, 0, :5].tolist()}")
                    print(f"    C first 5 values [0,0,:5]: {C[0, 0, :5].tolist()}")
                    print(f"    dt/B/C dtype: {dt.dtype}")
                    print(f"  ")
                    print(f"  SSM Scales (from self.selective_scan / QSScan):")
                    print(f"    u_scale          = {self.selective_scan.u_scale.item():.10f}  (for SSM input u)")
                    print(f"    dt_scale         = {self.selective_scan.dt_scale.item():.10f}  (for dt)")
                    print(f"    B_scale          = {self.selective_scan.B_scale.item():.10f}  (for B)")
                    print(f"    C_scale          = {self.selective_scan.C_scale.item():.10f}  (for C)")
                    print(f"    A_scale          = {self.selective_scan.A_scale.item():.10f}  (for A)")
                    print(f"    D_scale          = {self.selective_scan.D_scale.item():.10f}  (for D)")
                    print(f"    z_scale          = {self.selective_scan.z_scale.item():.10f}  (for z)")
                    print(f"    ssm_state_scale  = {self.selective_scan.ssm_state_scale.item():.10f}  (for state)")
                    print(f"    dt_bias_scale    = {self.selective_scan.dt_bias_scale.item():.10f}  (for dt_bias)")
                    print(f"  ")
                    print(f"  âš ï¸  Important: Conv1D output_scale should match SSM u_scale")
                    print(f"    (Conv1D output_scale printed above)")
                    print(f"    SSM u_scale = {self.selective_scan.u_scale.item():.10f}")
                    print(f"{'='*80}\n")
                    self._ssm_scales_printed = True

                    # Quick verification mode: exit after printing Layer 24 SSM scales
                    if os.environ.get('QUICK_VERIFY', 'false').lower() == 'true':
                        print("ðŸ” QUICK_VERIFY mode: Exiting after Layer 24 SSM input data print")
                        import sys
                        sys.exit(0)

            # ===== DUAL MODE DEBUG: Compare Mode 2-0 vs 2-1 =====
            # Run for ALL samples (remove the hasattr check)
            if self.layer_idx == 23 and os.environ.get('DUAL_MODE_DEBUG', 'false').lower() == 'true':
                dual_mode_compare_ssm(self, x, dt, B, C, z, self.conv1d.output_scale)

            # SSM with FP32 input (ONLY u is FP32, dt/B/C are INT8)
            y = self.selective_scan.forward(x_for_ssm, dt, B, C, z=z, return_last_state=ssm_state is not None)
        else:
            # Original INT8 path (completely unchanged)
            x_reshape = rearrange(x, "b d l -> b l d").contiguous()
            x_dbl = self.x_proj(x_reshape)  # (bl d)
            dt, B, C = torch.split(x_dbl, [self.dt_rank, self.d_state, self.d_state], dim=-1)

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After x_proj: x_dbl dtype: {x_dbl.dtype}, first 3: {x_dbl.flatten()[:3].tolist()}")
            #     print(f"  dt (before dt_proj) dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # Compute dt proj with x_proj_scale
            dt = self.dt_proj.to_seqlen_last(dt.contiguous())
            B = rearrange(B, "b l dstate -> b dstate l", l=seqlen).contiguous()
            C = rearrange(C, "b l dstate -> b dstate l", l=seqlen).contiguous()

            # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
            # if DEBUG_ENABLED and self._debug_step_count <= 3:
            #     print(f"  After dt_proj: dt dtype: {dt.dtype}, first 3: {dt.flatten()[:3].tolist()}")
            #     print(f"  B dtype: {B.dtype}, first 3: {B.flatten()[:3].tolist()}")
            #     print(f"  C dtype: {C.dtype}, first 3: {C.flatten()[:3].tolist()}")
            #     print(f"  z dtype: {z.dtype if z is not None else 'None'}, first 3: {z.flatten()[:3].tolist() if z is not None else 'N/A'}")
            # # ===== END TEMPORARY DEBUG CODE =====

            # ===== DEBUG: Mode 0 Scaleå’Œè¾“å‡º =====
            if os.environ.get('DEBUG_MODE0_VS_MODE50', 'false').lower() == 'true':
                if self.layer_idx == 23:
                    if not hasattr(self, '_mode0_debug_count'):
                        self._mode0_debug_count = 0
                    self._mode0_debug_count += 1
                    if self._mode0_debug_count == 1:
                        print(f"\n{'='*80}")
                        print(f"[Mode 0 - Layer 24] Scaleå’Œè¾“å‡ºå¯¹æ¯”")
                        print(f"{'='*80}")
                        print(f"  conv1d.output_scale: {self.conv1d.output_scale:.10f}")
                        print(f"  x_proj.a (input/output scale): {self.x_proj.a.item():.10f}")
                        print(f"  selective_scan.u_scale: {self.selective_scan.u_scale.item():.10f}")
                        print(f"  x (INT8) [0,0,:5]: {x[0,0,:5].tolist()}")
                        print(f"  x (dequant) [0,0,:5]: {(x.float()*self.conv1d.output_scale)[0,0,:5].tolist()}")
                        print(f"  dt (INT8) [0,0,:5]: {dt[0,0,:5].tolist()}")
                        print(f"  B (INT8) [0,0,:5]: {B[0,0,:5].tolist()}")
                        print(f"  C (INT8) [0,0,:5]: {C[0,0,:5].tolist()}")
                        print(f"{'='*80}\n")
            # ===== END DEBUG =====

            # SSM step and return ssm_state
            y = self.selective_scan.forward(x, dt, B, C, z=z, return_last_state=ssm_state is not None)

            # ===== DEBUG: Mode 0 SSMè¾“å‡º =====
            if os.environ.get('DEBUG_MODE0_VS_MODE50', 'false').lower() == 'true':
                if self.layer_idx == 23 and self._mode0_debug_count == 1:
                    print(f"[Mode 0] SSM output y[0,0,:5]: {y[0,0,:5].tolist()}")
            # ===== END DEBUG =====

        if ssm_state is not None:
            y, last_state = y # y: fp16, last_state: fp32
            ssm_state.copy_(last_state) # last_state: fp32 copy to ssm_state: fp16

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After SSM: y dtype: {y.dtype}, first 3: {y.flatten()[:3].tolist()}")
        # # ===== END TEMPORARY DEBUG CODE =====

        # Output projection
        y = self.had(y) # input fp16, output is int8

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After had: y dtype: {y.dtype}, first 3: {y.flatten()[:3].tolist()}")
        # # ===== END TEMPORARY DEBUG CODE =====

        out = self.out_proj(y) # HadW8A8BF16OF16Linear: input int8, output is fp16

        # # ===== TEMPORARY DEBUG CODE - TO BE DELETED =====
        # if DEBUG_ENABLED and self._debug_step_count <= 3:
        #     print(f"  After out_proj: out dtype: {out.dtype}, first 3: {out.flatten()[:3].tolist()}")
        #     print(f"{'='*80}\n")
        # # ===== END TEMPORARY DEBUG CODE =====

        return out

    def step(self, hidden_states, conv_state, ssm_state):
        dtype = hidden_states.dtype
        assert hidden_states.shape[1] == 1, "Only support decoding with 1 token at a time for now"

        # Input projection for x, z
        xz = self.in_proj(hidden_states.squeeze(1))  # (B 2D)
        x, z = xz.chunk(2, dim=-1)  # (B D)

        # Perform causal conv1d and update conv_state in-place
        x = self.conv1d.update(x, conv_state)

        # Compute dt, B, C 
        x_db = self.x_proj(x)  # (B dt_rank+2*d_state)
        dt, B, C = torch.split(x_db, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt = self.dt_proj(dt.contiguous())

        # SSM step and update ssm_state in-place
        y, ssm_state = self.selective_scan.update(ssm_state, x.contiguous(), dt, B, C, z=z)

        # Output projection
        y = self.had(y) # input fp16, output is int8
        out = self.out_proj(y)
        return out.unsqueeze(1), conv_state, ssm_state

    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):
        device = self.out_proj.weight.device
        conv_dtype = torch.int8
        conv_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_conv, device=device, dtype=conv_dtype
        )
        ssm_dtype = torch.int8
        ssm_state = torch.zeros(
            batch_size, self.d_model * self.expand, self.d_state, device=device, dtype=ssm_dtype
        )
        return conv_state, ssm_state

    def _get_states_from_cache(self, inference_params, batch_size, initialize_states=False):
        assert self.layer_idx is not None
        if self.layer_idx not in inference_params.key_value_memory_dict:
            batch_shape = (batch_size,)
            conv_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_conv,
                device=self.conv1d.weight.device,
                dtype=torch.int8,
            )
            ssm_state = torch.zeros(
                batch_size,
                self.d_model * self.expand,
                self.d_state,
                device=self.dt_proj.weight.device,
                dtype=torch.int8,
            )
            inference_params.key_value_memory_dict[self.layer_idx] = (conv_state, ssm_state)
        else:
            conv_state, ssm_state = inference_params.key_value_memory_dict[self.layer_idx]
            # TODO: What if batch size changes between generation, and we reuse the same states?
            if initialize_states:
                conv_state.zero_()
                ssm_state.zero_()
        return conv_state, ssm_state

    def forward_mode5_0(self, hidden_states, inference_params=None):
        """
        Mode 5-0: Real FP32 + Virtual INT8 è·¯å¾„
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º â†’ Virtual INT8 (é‡åŒ–åˆ° INT8 grid çš„ FP32 å€¼)
        - x_proj: INT8 è¾“å…¥ (ä»Ž Virtual INT8 è½¬æ¢)
        - SSM: FP32 è¾“å…¥ (Virtual INT8 å€¼) via quant_sscan_cuda.fwd_mode5
        - ç›®æ ‡ï¼šéªŒè¯ Virtual INT8 é‡åŒ–æ˜¯å¦èƒ½è¾¾åˆ°ä¸ŽçœŸå®ž INT8 (Mode 0) ç›¸åŒçš„ç²¾åº¦
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_5_0, z_5_0 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32 â†’ Virtual INT8) ===
        # ä½¿ç”¨ fwd_mode5 èŽ·å– FP32 è¾“å‡º
        x_5_0_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_5_0, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º

        # Virtual INT8: å°† FP32 å€¼é‡åŒ–åˆ° INT8 grid (ä½†ä¿æŒ FP32 dtype)
        # é‡è¦ï¼šä½¿ç”¨ roundf_like æ¨¡æ‹Ÿ C++ roundf()ï¼Œè€Œä¸æ˜¯ torch.round()
        # torch.round() ä½¿ç”¨ "round half to even" (banker's rounding): 0.5 â†’ 0, 1.5 â†’ 2
        # C++ roundf() ä½¿ç”¨ "round half away from zero": 0.5 â†’ 1, -0.5 â†’ -1
        def roundf_like(x):
            """æ¨¡æ‹Ÿ C++ roundf() - round half away from zero"""
            return torch.where(x >= 0, torch.floor(x + 0.5), torch.ceil(x - 0.5))

        x_5_0_scaled = x_5_0_fp32 / self.conv1d.output_scale
        x_5_0_int8_values = roundf_like(x_5_0_scaled).clamp(-128, 127)
        x_5_0_virtual_int8 = x_5_0_int8_values * self.conv1d.output_scale  # FP32 on INT8 grid

        # === Step 3: x_proj, dt_proj (éœ€è¦çœŸå®ž INT8 è¾“å…¥) ===
        # å¤ç”¨å·²è®¡ç®—çš„ int8 å€¼ï¼Œé¿å…é‡å¤è®¡ç®—
        x_5_0_int8_for_xproj = x_5_0_int8_values.to(torch.int8)
        x_5_0_reshape = rearrange(x_5_0_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_5_0 = self.x_proj(x_5_0_reshape)
        dt_5_0, B_5_0, C_5_0 = torch.split(x_dbl_5_0, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_5_0 = self.dt_proj.to_seqlen_last(dt_5_0.contiguous())
        B_5_0 = rearrange(B_5_0, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_5_0 = rearrange(C_5_0, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 4: SSM (FP32 Virtual INT8 è¾“å…¥) via fwd_mode5 ===
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_5_0, _ = quant_sscan_cuda.fwd_mode5(
            x_5_0_virtual_int8,  # FP32 Virtual INT8 è¾“å…¥
            dt_5_0, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_5_0, ensure_shape_1(self.selective_scan.B_scale),
            C_5_0, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_5_0, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # ===== DEBUG: Mode 5-0 vs Mode 0 å¯¹æ¯” =====
        import os
        if os.environ.get('DEBUG_MODE0_VS_MODE50', 'false').lower() == 'true':
            if self.layer_idx == 23:  # åªæ‰“å°æœ€åŽä¸€å±‚
                if not hasattr(self, '_mode50_debug_count'):
                    self._mode50_debug_count = 0
                self._mode50_debug_count += 1
                if self._mode50_debug_count == 1:  # åªæ‰“å°ç¬¬ä¸€æ¬¡
                    print(f"\n{'='*80}")
                    print(f"[Mode 5-0 - Layer 24 - W8A8QMamba] Debug Output")
                    print(f"{'='*80}")
                    # Conv1D è¾“å‡º
                    print(f"\n--- Conv1D Output ---")
                    print(f"  x_5_0_fp32 (FP32 raw): shape={x_5_0_fp32.shape}, dtype={x_5_0_fp32.dtype}")
                    print(f"  x_5_0_fp32 first 5: {x_5_0_fp32[0, 0, :5].tolist()}")
                    print(f"  x_5_0_virtual_int8 (FP32 on grid): {x_5_0_virtual_int8[0, 0, :5].tolist()}")
                    print(f"  x_5_0_int8_for_xproj (INT8): {x_5_0_int8_for_xproj[0, 0, :5].tolist()}")
                    # Scales
                    print(f"\n--- Scales ---")
                    print(f"  conv1d.input_scale:  {self.conv1d.input_scale:.10f}")
                    print(f"  conv1d.output_scale: {self.conv1d.output_scale:.10f}")
                    print(f"  x_proj.a (input_scale): {self.x_proj.a.item():.10f}")
                    print(f"  u_scale (for SSM):   {self.selective_scan.u_scale.item():.10f}")
                    # x_proj è¾“å‡º
                    print(f"\n--- x_proj Output ---")
                    print(f"  x_dbl_5_0 (INT8): shape={x_dbl_5_0.shape}, dtype={x_dbl_5_0.dtype}")
                    print(f"  x_dbl_5_0 first 5: {x_dbl_5_0[0, 0, :5].tolist()}")
                    # dt/B/C
                    print(f"\n--- dt/B/C ---")
                    print(f"  dt_5_0 (INT8): shape={dt_5_0.shape}, first 5: {dt_5_0[0, 0, :5].tolist()}")
                    print(f"  B_5_0 (INT8): shape={B_5_0.shape}, first 5: {B_5_0[0, 0, 0, :5].tolist()}")
                    print(f"  C_5_0 (INT8): shape={C_5_0.shape}, first 5: {C_5_0[0, 0, 0, :5].tolist()}")
                    print(f"  z_5_0 (INT8): shape={z_5_0.shape}, first 5: {z_5_0[0, 0, :5].tolist()}")
                    # SSM è¾“å‡º
                    print(f"\n--- SSM Output ---")
                    print(f"  y_5_0: shape={y_5_0.shape}, dtype={y_5_0.dtype}")
                    print(f"  y_5_0 first 5: {y_5_0[0, 0, :5].tolist()}")
                    print(f"{'='*80}\n")
        # ===== END DEBUG =====

        # === Step 5: had + out_proj ===
        y_5_0_fp16 = y_5_0.half() if y_5_0.dtype != torch.float16 else y_5_0
        y_5_0 = self.had(y_5_0_fp16)
        out_5_0 = self.out_proj(y_5_0)

        return out_5_0

    def forward_mode5_1(self, hidden_states, inference_params=None):
        """
        Mode 5-1: FP32 è·¯å¾„ (é«˜ç²¾åº¦è·¯å¾„)
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º
        - SSM: FP32 è¾“å…¥
        - ç”¨äºŽè¯¯å·®ç´¯ç§¯æ¯”è¾ƒçš„ FP32 åŸºå‡†è·¯å¾„
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_5_1, z_5_1 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        # [Scaleå¯¹æ¯”] fwd_mode5 ä½¿ç”¨å’Œ Mode 0 ç›¸åŒçš„ scales:
        #   - input_scale: self.conv1d.input_scale (åŒ Mode 0, qConvLayer.py:174)
        #   - weight_scale: self.conv1d.weight_scale (åŒ Mode 0, qConvLayer.py:175)
        #   - bias_scale: self.conv1d.bias_scale (åŒ Mode 0, qConvLayer.py:177)
        #   åŒºåˆ«: fwd_mode5 è¿”å›ž FP32, Mode 0 çš„ fwd è¿”å›ž INT8 (å†…éƒ¨ç”¨ output_scale é‡åŒ–)
        x_5_1_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_5_1, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º

        # === Step 3: x_proj, dt_proj (éœ€è¦ INT8 è¾“å…¥ï¼Œé‡æ–°é‡åŒ–) ===
        # [Scaleå¯¹æ¯”] Mode 5-1 ä½¿ç”¨ self.conv1d.output_scale åšæˆªæ–­
        #   - Mode 0: qConvLayer.py:171-179 CUDA kernel å†…éƒ¨ç”¨ output_scale åšé‡åŒ–+æˆªæ–­
        #             quant_causal_conv1d_cuda.fwd(..., self.output_scale, ...) â†’ è¿”å›ž INT8
        #   - Mode 5-1: Python ç«¯ç”¨åŒæ ·çš„ output_scale åš re-quantize
        #   - ä¸¤è€…ç”¨çš„æ˜¯åŒä¸€ä¸ª scale å€¼: self.conv1d.output_scale
        #   - ä¸¤è€…éƒ½ä¼šæŠŠè¶…å‡º [-128, 127] çš„ outlier clamp æˆªæ–­
        # ä½¿ç”¨ roundf_like æ¨¡æ‹Ÿ C++ roundf()
        def roundf_like(x):
            return torch.where(x >= 0, torch.floor(x + 0.5), torch.ceil(x - 0.5))
        x_5_1_int8_for_xproj = roundf_like(x_5_1_fp32 / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
        x_5_1_reshape = rearrange(x_5_1_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_5_1 = self.x_proj(x_5_1_reshape)
        dt_5_1, B_5_1, C_5_1 = torch.split(x_dbl_5_1, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_5_1 = self.dt_proj.to_seqlen_last(dt_5_1.contiguous())
        B_5_1 = rearrange(B_5_1, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_5_1 = rearrange(C_5_1, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 4: SSM (FP32 è¾“å…¥) ===
        # [Scaleå¯¹æ¯”] fwd_mode5 ä½¿ç”¨ç›¸åŒçš„ selective_scan scales:
        #   - Mode 0: self.selective_scan.forward(x, dt, B, C, z=z) ä½¿ç”¨ quant_sscan_cuda.fwd
        #             å†…éƒ¨ä½¿ç”¨åŒæ ·çš„ dt_scale, A_scale, B_scale, C_scale, etc.
        #   - Mode 5-1: ç›´æŽ¥è°ƒç”¨ quant_sscan_cuda.fwd_mode5, ä¼ å…¥ç›¸åŒçš„ scales
        #   - åŒºåˆ«: fwd_mode5 æŽ¥å— FP32 è¾“å…¥ x_5_1_fp32 (ä¿ç•™äº† outlier ç²¾åº¦)
        #           Mode 0 çš„ fwd æŽ¥å— INT8 è¾“å…¥ (outlier å·²è¢«æˆªæ–­)
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_5_1, _ = quant_sscan_cuda.fwd_mode5(
            x_5_1_fp32,  # FP32 è¾“å…¥ (ä¿ç•™ outlier ç²¾åº¦, ä¸Ž Mode 0 ä¸åŒ)
            dt_5_1, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_5_1, ensure_shape_1(self.selective_scan.B_scale),
            C_5_1, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_5_1, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 5: had + out_proj ===
        y_5_1_fp16 = y_5_1.half() if y_5_1.dtype != torch.float16 else y_5_1
        y_5_1 = self.had(y_5_1_fp16)
        out_5_1 = self.out_proj(y_5_1)

        # ===== DEBUG: Mode 5-1 æ•°å€¼æ‰“å° =====
        _DEBUG_LAYER_COUNTER['count'] += 1
        if _DEBUG_LAYER_COUNTER['total'] is None:
            _DEBUG_LAYER_COUNTER['total'] = 24  # 130M=24, 1.4B=48, 2.8B=64
        if _DEBUG_LAYER_COUNTER['count'] == _DEBUG_LAYER_COUNTER['total']:
            def _get_val(x):
                return x.item() if hasattr(x, 'item') else x
            print(f"\n===== Mode 5-1 æœ€åŽä¸€å±‚ =====")
            print(f"conv1d.input_scale: {_get_val(self.conv1d.input_scale):.6f}")
            print(f"conv1d.output_scale: {_get_val(self.conv1d.output_scale):.6f}")
            print(f"x_proj.a: {_get_val(self.x_proj.a):.6f}")
            print(f"Conv1D out (FP32): {x_5_1_fp32.flatten()[:3].tolist()}")
            print(f"x_proj input (re-quant INT8): {x_5_1_int8_for_xproj.flatten()[:3].tolist()}")
            print(f"dt: {dt_5_1.flatten()[:3].tolist()}")
            print(f"B: {B_5_1.flatten()[:3].tolist()}")
            print(f"C: {C_5_1.flatten()[:3].tolist()}")
            # import sys; sys.exit(0)  # æ–¹ä¾¿æ³¨é‡Š - DISABLED for eval
        # ===== END DEBUG =====

        return out_5_1

    def forward_mode5_2(self, hidden_states, inference_params=None):
        """
        Mode 5-2: è™šæ‹Ÿé‡åŒ– + Outlier è·¯å¾„
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º â†’ è™šæ‹Ÿé‡åŒ– + outlier
        - SSM: FP32 è¾“å…¥ï¼ˆæ··åˆï¼šç½‘æ ¼å€¼ + outlier ä¿æŒåŽŸ FP32ï¼‰
        - ç”¨äºŽç ”ç©¶ outlier ä¿æŠ¤å¯¹ç²¾åº¦çš„å½±å“
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_5_2, z_5_2 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_5_2_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_5_2, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º

        # === Step 3: è™šæ‹Ÿé‡åŒ– + Outlier (5-2 ç‹¬æœ‰) ===
        # ä½¿ç”¨ roundf_like æ¨¡æ‹Ÿ C++ roundf()
        def roundf_like(x):
            return torch.where(x >= 0, torch.floor(x + 0.5), torch.ceil(x - 0.5))
        # é‡åŒ–åˆ°æ•´æ•°ç½‘æ ¼
        x_quantized = roundf_like(x_5_2_fp32 / self.conv1d.output_scale)
        # æ£€æµ‹ outlierï¼ˆè¶…å‡º INT8 èŒƒå›´ï¼‰
        overflow_mask_5_2 = torch.abs(x_quantized) > 127
        # ç½‘æ ¼å€¼ = clamp + åé‡åŒ–
        x_grid = torch.clamp(x_quantized, -128, 127) * self.conv1d.output_scale
        # æ··åˆè¾“å‡º - outlier ä¿æŒ FP32ï¼Œæ­£å¸¸å€¼ç”¨ç½‘æ ¼
        x_5_2_mixed = torch.where(overflow_mask_5_2, x_5_2_fp32, x_grid)

        # ä¿å­˜ outlier ç»Ÿè®¡ä¾›æ‰“å°
        self._mode5_2_overflow_count = overflow_mask_5_2.sum().item()
        self._mode5_2_total_count = overflow_mask_5_2.numel()

        # === Step 4: x_proj, dt_proj (é‡æ–°é‡åŒ–ä¸º INT8) ===
        x_5_2_int8_for_xproj = roundf_like(x_5_2_mixed / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
        x_5_2_reshape = rearrange(x_5_2_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_5_2 = self.x_proj(x_5_2_reshape)
        dt_5_2, B_5_2, C_5_2 = torch.split(x_dbl_5_2, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_5_2 = self.dt_proj.to_seqlen_last(dt_5_2.contiguous())
        B_5_2 = rearrange(B_5_2, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_5_2 = rearrange(C_5_2, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 5: SSM (FP32 è¾“å…¥ï¼Œç”¨æ··åˆå€¼) ===
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_5_2, _ = quant_sscan_cuda.fwd_mode5(
            x_5_2_mixed,  # FP32 æ··åˆè¾“å…¥ï¼ˆç½‘æ ¼å€¼ + outlier FP32ï¼‰
            dt_5_2, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_5_2, ensure_shape_1(self.selective_scan.B_scale),
            C_5_2, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_5_2, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 6: had + out_proj ===
        y_5_2_fp16 = y_5_2.half() if y_5_2.dtype != torch.float16 else y_5_2
        y_5_2 = self.had(y_5_2_fp16)
        out_5_2 = self.out_proj(y_5_2)

        return out_5_2

    def forward_mode5_3(self, hidden_states, inference_params=None):
        """
        Mode 5-3: åŒç²¾åº¦ INT8 è™šæ‹Ÿé‡åŒ–è·¯å¾„ï¼ˆåŠ¨æ€ outlier scaleï¼‰
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º â†’ åŒç²¾åº¦è™šæ‹Ÿé‡åŒ–
        - SSM: FP32 è¾“å…¥ï¼ˆæ‰€æœ‰å€¼éƒ½åœ¨ INT8 ç½‘æ ¼ä¸Šï¼Œä½†ç”¨ä¸åŒ scaleï¼‰
        - ä¸Ž Mode 0 CUDA kernel ä¿æŒä¸€è‡´ï¼šround + clamp
        - åŠ¨æ€è®¡ç®— outlier scaleï¼šæ ¹æ® outlier æœ€å¤§å€¼ï¼Œè®©å…¶åˆšå¥½å¡«æ»¡ [-127, 127]
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_5_3, z_5_3 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_5_3_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_5_3, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º

        # === Step 3: åŒç²¾åº¦ INT8 è™šæ‹Ÿé‡åŒ– (5-3 ç‹¬æœ‰ï¼ŒåŠ¨æ€ scale) ===
        # ä½¿ç”¨ roundf_like æ¨¡æ‹Ÿ C++ roundf()
        def roundf_like(x):
            return torch.where(x >= 0, torch.floor(x + 0.5), torch.ceil(x - 0.5))

        # Step 3.1: ä½¿ç”¨åŽŸå§‹ scale é‡åŒ–
        x_quantized = roundf_like(x_5_3_fp32 / self.conv1d.output_scale)

        # Step 3.2: æ£€æµ‹ outlierï¼ˆè¶…å‡º INT8 èŒƒå›´ï¼‰
        overflow_mask_1x = torch.abs(x_quantized) > 127

        # Step 3.3: æ­£å¸¸å€¼ â†’ åŽŸå§‹ scale çš„ INT8 ç½‘æ ¼
        x_normal = torch.clamp(x_quantized, -128, 127) * self.conv1d.output_scale

        # Step 3.4: åŠ¨æ€è®¡ç®— outlier scaleï¼ˆå…³é”®æ”¹è¿›ï¼‰
        # ç›®æ ‡ï¼šè®© outlier åˆšå¥½å¡«æ»¡ [-127, 127] èŒƒå›´ï¼Œæœ€å¤§åŒ–ç²¾åº¦
        outlier_values = x_5_3_fp32[overflow_mask_1x]
        if outlier_values.numel() > 0:
            outlier_max = outlier_values.abs().max()
            # è®© outlier åˆšå¥½å¡«æ»¡ [-127, 127] èŒƒå›´
            outlier_scale = (outlier_max / 127.0).clamp(min=self.conv1d.output_scale)
            scale_factor = (outlier_scale / self.conv1d.output_scale).item()
        else:
            outlier_scale = self.conv1d.output_scale  # æ—  outlierï¼Œfallback
            scale_factor = 1.0

        # Step 3.5: Outlier â†’ åŠ¨æ€ scale çš„ INT8 ç½‘æ ¼
        x_outlier_quantized = roundf_like(x_5_3_fp32 / outlier_scale)

        # Step 3.6: æ£€æµ‹äºŒæ¬¡æº¢å‡ºï¼ˆç†è®ºä¸Šä¸åº”è¯¥æœ‰ï¼Œå› ä¸º scale æ˜¯åŠ¨æ€è®¡ç®—çš„ï¼‰
        overflow_mask_2x = torch.abs(x_outlier_quantized) > 127

        # Step 3.7: Outlier å€¼ â†’ åŠ¨æ€ scale çš„ INT8 ç½‘æ ¼
        x_outlier = torch.clamp(x_outlier_quantized, -128, 127) * outlier_scale

        # Step 3.8: æ··åˆè¾“å‡ºï¼ˆå…¨éƒ¨æ˜¯ FP32 dtypeï¼Œä½†å€¼åœ¨ä¸åŒç²¾åº¦çš„ INT8 ç½‘æ ¼ä¸Šï¼‰
        x_5_3_mixed = torch.where(overflow_mask_1x, x_outlier, x_normal)

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯ä¾›æ‰“å°
        self._mode5_3_overflow_1x_count = overflow_mask_1x.sum().item()
        self._mode5_3_overflow_2x_count = (overflow_mask_1x & overflow_mask_2x).sum().item()
        self._mode5_3_total_count = overflow_mask_1x.numel()
        self._mode5_3_scale_factor = scale_factor

        # === Step 4: x_proj, dt_proj (é‡æ–°é‡åŒ–ä¸º INT8) ===
        x_5_3_int8_for_xproj = roundf_like(x_5_3_mixed / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
        x_5_3_reshape = rearrange(x_5_3_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_5_3 = self.x_proj(x_5_3_reshape)
        dt_5_3, B_5_3, C_5_3 = torch.split(x_dbl_5_3, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_5_3 = self.dt_proj.to_seqlen_last(dt_5_3.contiguous())
        B_5_3 = rearrange(B_5_3, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_5_3 = rearrange(C_5_3, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 5: SSM (FP32 è¾“å…¥ï¼Œç”¨æ··åˆå€¼) ===
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_5_3, _ = quant_sscan_cuda.fwd_mode5(
            x_5_3_mixed,  # FP32 æ··åˆè¾“å…¥ï¼ˆå…¨éƒ¨åœ¨ INT8 ç½‘æ ¼ä¸Šï¼Œä½†ä¸åŒ scaleï¼‰
            dt_5_3, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_5_3, ensure_shape_1(self.selective_scan.B_scale),
            C_5_3, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_5_3, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 6: had + out_proj ===
        y_5_3_fp16 = y_5_3.half() if y_5_3.dtype != torch.float16 else y_5_3
        y_5_3 = self.had(y_5_3_fp16)
        out_5_3 = self.out_proj(y_5_3)

        return out_5_3

    def forward_mode5_4(self, hidden_states, inference_params=None):
        """
        Mode 5-4: QuarterScale 4Ã— Precision for Small Values
        - Conv1D: INT8 â†’ FP32 è¾“å‡º
        - QuarterScale: å°å€¼ (|q| < 32) ç”¨ scale/4 (4Ã— ç²¾åº¦), å¤§å€¼ç”¨æ­£å¸¸ scale
        - x_proj: é‡æ–°é‡åŒ–å›ž INT8 (ä¸Ž Mode 5-0 ä¸€è‡´)
        - SSM: FP32 mixed è¾“å…¥ (ä¿ç•™å°å€¼ 4Ã— ç²¾åº¦)

        å…³é”®è®¾è®¡:
        - å°å€¼å  INT8 èŒƒå›´çš„ 1/4 (|q| < 32)
        - å°å€¼ç”¨ quarter_scale = scale/4ï¼ŒèŽ·å¾— 4Ã— ç²¾åº¦
        - x_proj ç²¾åº¦ä¸Ž Mode 5-0 å®Œå…¨ä¸€è‡´ï¼ˆé€€åŒ–å›žåŽŸå§‹ç²¾åº¦ï¼‰
        - åªæœ‰ SSM è¾“å…¥èŽ·å¾—å°å€¼çš„ 4Ã— ç²¾åº¦
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x_5_4, z_5_4 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_5_4_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_5_4, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )

        # === Step 3: QuarterScale Virtual Quantization ===
        # ä½¿ç”¨ roundf_like æ¨¡æ‹Ÿ C++ roundf()
        def roundf_like(x):
            return torch.where(x >= 0, torch.floor(x + 0.5), torch.ceil(x - 0.5))

        scale = self.conv1d.output_scale
        quarter_scale = scale / 4.0

        # ç”¨åŽŸå§‹ scale åˆ¤æ–­å€¼çš„å¤§å°
        x_quantized = roundf_like(x_5_4_fp32 / scale)

        # å°å€¼: |q| < 32 (èŒƒå›´çš„ 1/4)
        is_small = (x_quantized.abs() < 32)

        # å°å€¼ç”¨ quarter_scale (4Ã— ç²¾åº¦)
        x_small = roundf_like(x_5_4_fp32 / quarter_scale).clamp(-127, 127) * quarter_scale

        # å¤§å€¼ç”¨åŽŸå§‹ scale
        x_normal = x_quantized.clamp(-128, 127) * scale

        # ç»„åˆ
        x_5_4_mixed = torch.where(is_small, x_small, x_normal)

        # === Step 4: x_proj (é‡æ–°é‡åŒ–å›ž INT8ï¼Œä¸Ž Mode 5-0 ä¸€è‡´) ===
        x_5_4_int8 = roundf_like(x_5_4_mixed / scale).clamp(-128, 127).to(torch.int8)
        x_5_4_reshape = rearrange(x_5_4_int8, "b d l -> b l d").contiguous()
        x_dbl_5_4 = self.x_proj(x_5_4_reshape)
        dt_5_4, B_5_4, C_5_4 = torch.split(x_dbl_5_4, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_5_4 = self.dt_proj.to_seqlen_last(dt_5_4.contiguous())
        B_5_4 = rearrange(B_5_4, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_5_4 = rearrange(C_5_4, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 5: SSM (FP32 mixed è¾“å…¥ï¼Œä¿ç•™å°å€¼ 4Ã— ç²¾åº¦) ===
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_5_4, _ = quant_sscan_cuda.fwd_mode5(
            x_5_4_mixed,  # FP32 è¾“å…¥ (å°å€¼ 4Ã— ç²¾åº¦)
            dt_5_4, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_5_4, ensure_shape_1(self.selective_scan.B_scale),
            C_5_4, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_5_4, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 6: had + out_proj ===
        y_5_4_fp16 = y_5_4.half() if y_5_4.dtype != torch.float16 else y_5_4
        y_5_4 = self.had(y_5_4_fp16)
        out_5_4 = self.out_proj(y_5_4)

        return out_5_4

    def forward_mode6_0_eval(self, hidden_states, inference_params=None):
        """
        Mode 6-0: Virtual INT8 (æ¨¡æ‹Ÿ Mode 0 çš„é‡åŒ–è¯¯å·®)
        æ‰€æœ‰ FP32 å€¼éƒ½æ¨¡æ‹Ÿ INT8 gridï¼šround(x/scale).clamp(-128,127)*scale
        - Conv1D: INT8 kernel â†’ FP32 è¾“å‡º â†’ Virtual INT8
        - x_proj: FP32 F.linear â†’ Virtual INT8
        - dt_proj: FP32 F.linear â†’ Virtual INT8
        - SSM: mamba_ssm selective_scan_fn (FP32 kernel with Virtual INT8 values)

        æ³¨æ„ï¼šç”±äºŽ SSM ä½¿ç”¨ FP32 kernelï¼ˆmamba_ssmï¼‰ï¼Œå†…éƒ¨ç´¯åŠ ç²¾åº¦ä¸Ž Mode 0 çš„ INT8 kernel ä¸åŒï¼Œ
        å› æ­¤ç»“æžœä¸ä¼šå®Œå…¨ä¸€è‡´ã€‚6-0 åªæ¨¡æ‹Ÿäº†è¾“å…¥çš„é‡åŒ–è¯¯å·®ï¼Œä¸æ¨¡æ‹Ÿ kernel å†…éƒ¨çš„ç²¾åº¦å·®å¼‚ã€‚
        é¢„æœŸï¼š6-0 çš„ perplexity åº”ä»‹äºŽ Mode 0 å’Œ 6-1 ä¹‹é—´ã€‚
        """
        import quant_causal_conv1d_cuda
        from mamba_ssm.ops.selective_scan_interface import selective_scan_fn

        batch, seqlen, dim = hidden_states.shape

        # === èŽ·å–æ‰€æœ‰éœ€è¦çš„ scale ===
        conv1d_output_scale = self.conv1d.output_scale
        x_proj_output_scale = self.selective_scan.B_scale  # = C_scale = x_proj:output
        dt_proj_output_scale = self.selective_scan.dt_scale
        z_scale = self.selective_scan.z_scale
        D_scale = self.selective_scan.D_scale
        dt_bias_scale = self.selective_scan.dt_bias_scale
        A_scale = self.selective_scan.A_scale

        # === Step 1: in_proj (ä¿æŒ INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x, z = xz.chunk(2, dim=1)  # x, z éƒ½æ˜¯ INT8

        # === Step 2: Conv1D â†’ FP32ï¼Œç„¶åŽ Virtual INT8 ===
        x_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º
        x_vq = torch.round(x_fp32 / conv1d_output_scale).clamp(-128, 127) * conv1d_output_scale  # Virtual INT8

        # Debug: éªŒè¯ Virtual INT8 (å‰ 5 æ¬¡)
        if self.layer_idx == 0:
            if not hasattr(self, '_vq_debug_count'):
                self._vq_debug_count = 0
            if self._vq_debug_count < 5:
                residual = (x_vq / conv1d_output_scale) - torch.round(x_vq / conv1d_output_scale)
                print(f"[6-0 VQ Check] Layer 0, Call {self._vq_debug_count}: max_residual = {residual.abs().max().item():.10f}")
                self._vq_debug_count += 1

        # === Step 3: x_proj (FP32 F.linear) ===
        x_reshape = rearrange(x_vq, "b d l -> (b l) d")
        x_dbl_fp32 = self.x_proj.forward_mode6(x_reshape)  # FP32 è¾“å‡º

        # Virtual INT8 for x_proj output
        x_dbl_vq = torch.round(x_dbl_fp32 / x_proj_output_scale).clamp(-128, 127) * x_proj_output_scale
        x_dbl_vq = x_dbl_vq.view(batch, seqlen, -1)

        # === Step 4: split dt, B, C (éƒ½æ˜¯ Virtual INT8) ===
        dt_raw, B_raw, C_raw = torch.split(x_dbl_vq, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        # === Step 5: dt_proj (FP32 F.linear) + Virtual INT8 ===
        dt_fp32 = self.dt_proj.to_seqlen_last_mode6(dt_raw.contiguous())
        dt_vq = torch.round(dt_fp32 / dt_proj_output_scale).clamp(-128, 127) * dt_proj_output_scale

        # === Step 6: B, C reshape (ä¿æŒ Virtual INT8ï¼Œå·²ç»åœ¨ split æ—¶åšè¿‡ VQ) ===
        B_vq = rearrange(B_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_vq = rearrange(C_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 7: z Virtual INT8 ===
        # z ä»Ž in_proj å‡ºæ¥æ˜¯ INT8ï¼Œdequant åŽ (z.float() * z_scale) å·²ç»åœ¨ INT8 grid ä¸Š
        z_fp32 = z.float() * z_scale  # è¿™å°±æ˜¯ Virtual INT8

        # === Step 8: A, D, dt_bias dequant ===
        # A_log æ˜¯ INT8 å­˜çš„ log å€¼ï¼Œdequant åŽå† exp
        A_fp32 = -torch.exp(self.selective_scan.A_log.float() * A_scale)

        # D å’Œ dt_bias æ˜¯ INT8 weight buffersï¼Œdequant åŽå·²ç»åœ¨ INT8 grid ä¸Š
        D_fp32 = None
        if self.selective_scan.D is not None:
            D_fp32 = self.selective_scan.D.float() * D_scale  # å·²ç»æ˜¯ Virtual INT8

        dt_bias_fp32 = None
        if self.selective_scan.dt_bias is not None:
            dt_bias_fp32 = self.selective_scan.dt_bias.float() * dt_bias_scale  # å·²ç»æ˜¯ Virtual INT8

        # === Step 9: SSM (FP32 kernel with Virtual INT8 values) ===
        y = selective_scan_fn(
            x_vq, dt_vq, A_fp32, B_vq, C_vq,
            D=D_fp32, z=z_fp32, delta_bias=dt_bias_fp32,
            delta_softplus=True, return_last_state=False
        )

        # === Step 10: had + out_proj ===
        y = rearrange(y, "b d l -> b l d")
        y_fp16 = y.half() if y.dtype != torch.float16 else y
        y = self.had(y_fp16)
        out = self.out_proj(y)

        return out

    def forward_mode6_1_eval(self, hidden_states, inference_params=None):
        """
        Mode 6-1: INT8 Kernel + FP32 è¾“å‡º (æ—  Virtual INT8)
        - Conv1D: INT8 kernel â†’ FP32 è¾“å‡º (ä¸åš Virtual INT8!)
        - x_proj: FP32 F.linear â†’ FP32 è¾“å‡º (ä¸ clamp!)
        - dt_proj: FP32 F.linear â†’ FP32 è¾“å‡º (ä¸ clamp!)
        - SSM: mamba_ssm selective_scan_fn (FP32 kernel)
        ä¸Ž 6-0 çš„åŒºåˆ«ï¼š6-0 æ¯æ­¥è¾“å‡ºéƒ½åš VQ åˆ° INT8 gridï¼Œ6-1 ç›´æŽ¥ç”¨ FP32 å€¼
        é¢„æœŸï¼š6-1 çš„ Acc åº”è¯¥æ¯” 6-0 é«˜ï¼ˆ6-1 æ˜¯ upper boundï¼‰
        """
        import quant_causal_conv1d_cuda
        from mamba_ssm.ops.selective_scan_interface import selective_scan_fn

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x_6_1, z_6_1 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_6_1_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_6_1, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 è¾“å‡º

        # === Step 3: x_proj (FP32) - ç”¨ä¸Ž SSM å®Œå…¨ç›¸åŒçš„å€¼ï¼===
        x_6_1_reshape = rearrange(x_6_1_fp32, "b d l -> (b l) d")
        x_dbl_6_1 = self.x_proj.forward_mode6(x_6_1_reshape)
        x_dbl_6_1 = x_dbl_6_1.view(batch, seqlen, -1)
        dt_6_1_raw, B_6_1_raw, C_6_1_raw = torch.split(x_dbl_6_1, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        # dt_proj: FP32 è¾“å‡º, shape (batch, dim, seqlen)
        dt_6_1 = self.dt_proj.to_seqlen_last_mode6(dt_6_1_raw.contiguous())

        # B, C: selective_scan_fn æœŸæœ› shape (batch, n_groups, dstate, seqlen)
        # åŽŸå§‹ shape: (batch, seqlen, dstate), éœ€è¦è½¬æ¢
        B_6_1 = rearrange(B_6_1_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_6_1 = rearrange(C_6_1_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 4: SSM (FP32 è¾“å…¥) - ä½¿ç”¨ mamba_ssm åŽŸå§‹ FP32 kernel ===
        # èŽ·å– A (dequantize A_log: INT8 -> FP32, ç„¶åŽ exp)
        A_fp32 = -torch.exp(self.selective_scan.A_log.float() * self.selective_scan.A_scale)  # (dim, dstate)

        # z éœ€è¦ dequantize: INT8 -> FP32
        z_6_1_fp32 = z_6_1.float() * self.selective_scan.z_scale

        # D: dequantize if needed
        D_fp32 = None
        if self.selective_scan.D is not None:
            D_fp32 = self.selective_scan.D.float() * self.selective_scan.D_scale

        # dt_bias: dequantize
        dt_bias_fp32 = None
        if self.selective_scan.dt_bias is not None:
            dt_bias_fp32 = self.selective_scan.dt_bias.float() * self.selective_scan.dt_bias_scale

        # selective_scan_fn expects:
        #   u: (batch, dim, seqlen), delta: (batch, dim, seqlen)
        #   A: (dim, dstate), B: (batch, n_groups, dstate, seqlen), C: (batch, n_groups, dstate, seqlen)
        #   D: (dim,), z: (batch, dim, seqlen)
        y_6_1 = selective_scan_fn(
            x_6_1_fp32,      # u: (batch, dim, seqlen) FP32
            dt_6_1,          # delta: (batch, dim, seqlen) FP32
            A_fp32,          # A: (dim, dstate) FP32
            B_6_1,           # B: (batch, 1, dstate, seqlen) FP32
            C_6_1,           # C: (batch, 1, dstate, seqlen) FP32
            D=D_fp32,        # D: (dim,) FP32 or None
            z=z_6_1_fp32,    # z: (batch, dim, seqlen) FP32
            delta_bias=dt_bias_fp32,
            delta_softplus=True,
            return_last_state=False
        )

        # === Step 5: had + out_proj ===
        # selective_scan_fn è¿”å›ž (batch, dim, seqlen), éœ€è¦è½¬æ¢ä¸º (batch, seqlen, dim)
        y_6_1 = rearrange(y_6_1, "b d l -> b l d")
        y_6_1_fp16 = y_6_1.half() if y_6_1.dtype != torch.float16 else y_6_1
        y_6_1 = self.had(y_6_1_fp16)
        out_6_1 = self.out_proj(y_6_1)

        return out_6_1

    def forward_mode6_2_eval(self, hidden_states, inference_params=None):
        """
        Mode 6-2: FP32 + Outlier ä¿æŠ¤ (è™šæ‹Ÿé‡åŒ– + outlier ä¿ç•™åŽŸå€¼)
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º
        - Virtual Quant: æ­£å¸¸å€¼æ˜ å°„åˆ° INT8 ç½‘æ ¼ï¼Œoutlier ä¿ç•™ FP32 åŽŸå€¼
        - x_proj & SSM: ç”¨ç›¸åŒçš„ mixed å€¼ï¼(ä½¿ç”¨åŽŸå§‹ mamba_ssm selective_scan_fn)
        å…³é”®æ”¹è¿›ï¼šè§£å†³ Mode 5-2 çš„ä¸ä¸€è‡´é—®é¢˜
        """
        import quant_causal_conv1d_cuda
        from mamba_ssm.ops.selective_scan_interface import selective_scan_fn

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x_6_2, z_6_2 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_6_2_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_6_2, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )

        # === Step 3: Virtual quantization + Outlier ä¿æŠ¤ ===
        x_quantized = torch.round(x_6_2_fp32 / self.conv1d.output_scale)
        is_outlier = (x_quantized.abs() > 127)
        x_normal = x_quantized.clamp(-128, 127) * self.conv1d.output_scale
        x_6_2_mixed = torch.where(is_outlier, x_6_2_fp32, x_normal)

        # === Step 4: x_proj (FP32) - ç”¨ä¸Ž SSM ç›¸åŒçš„ mixed å€¼ï¼===
        x_6_2_reshape = rearrange(x_6_2_mixed, "b d l -> (b l) d")
        x_dbl_6_2 = self.x_proj.forward_mode6(x_6_2_reshape)
        x_dbl_6_2 = x_dbl_6_2.view(batch, seqlen, -1)
        dt_6_2_raw, B_6_2_raw, C_6_2_raw = torch.split(x_dbl_6_2, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        # dt_proj: FP32 è¾“å‡º, shape (batch, dim, seqlen)
        dt_6_2 = self.dt_proj.to_seqlen_last_mode6(dt_6_2_raw.contiguous())

        # B, C: selective_scan_fn æœŸæœ› shape (batch, n_groups, dstate, seqlen)
        B_6_2 = rearrange(B_6_2_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_6_2 = rearrange(C_6_2_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 5: SSM (FP32 è¾“å…¥) - ä½¿ç”¨ mamba_ssm åŽŸå§‹ FP32 kernel ===
        # èŽ·å– A (dequantize A_log)
        A_fp32 = -torch.exp(self.selective_scan.A_log.float())  # (dim, dstate)

        # z éœ€è¦ dequantize: INT8 -> FP32
        z_6_2_fp32 = z_6_2.float() * self.selective_scan.z_scale

        # D: dequantize if needed
        D_fp32 = None
        if self.selective_scan.D is not None:
            D_fp32 = self.selective_scan.D.float() * self.selective_scan.D_scale

        # dt_bias: dequantize
        dt_bias_fp32 = None
        if self.selective_scan.dt_bias is not None:
            dt_bias_fp32 = self.selective_scan.dt_bias.float() * self.selective_scan.dt_bias_scale

        y_6_2 = selective_scan_fn(
            x_6_2_mixed,     # u: (batch, dim, seqlen) FP32
            dt_6_2,          # delta: (batch, dim, seqlen) FP32
            A_fp32,          # A: (dim, dstate) FP32
            B_6_2,           # B: (batch, 1, dstate, seqlen) FP32
            C_6_2,           # C: (batch, 1, dstate, seqlen) FP32
            D=D_fp32,        # D: (dim,) FP32 or None
            z=z_6_2_fp32,    # z: (batch, dim, seqlen) FP32
            delta_bias=dt_bias_fp32,
            delta_softplus=True,
            return_last_state=False
        )

        # === Step 6: had + out_proj ===
        # selective_scan_fn è¿”å›ž (batch, dim, seqlen), éœ€è¦è½¬æ¢ä¸º (batch, seqlen, dim)
        y_6_2 = rearrange(y_6_2, "b d l -> b l d")
        y_6_2_fp16 = y_6_2.half() if y_6_2.dtype != torch.float16 else y_6_2
        y_6_2 = self.had(y_6_2_fp16)
        out_6_2 = self.out_proj(y_6_2)

        return out_6_2

    def forward_mode6_3_eval(self, hidden_states, inference_params=None):
        """
        Mode 6-3: HalfScale 2x Precision for Small Values
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º
        - HalfScale Virtual Quant: å°å€¼ (|q| < 64) ç”¨ half scale (2x ç²¾åº¦), å¤§å€¼ç”¨æ­£å¸¸ scale
        - x_proj & SSM: ç”¨ç›¸åŒçš„ HalfScale å€¼
        å…³é”®: å°å€¼ä½¿ç”¨ scale/2ï¼Œé‡åŒ–æ­¥é•¿å‡åŠï¼Œç²¾åº¦ç¿»å€
        """
        import quant_causal_conv1d_cuda
        from mamba_ssm.ops.selective_scan_interface import selective_scan_fn

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x_6_3, z_6_3 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_6_3_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_6_3, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )

        # === Step 3: HalfScale Virtual Quantization ===
        scale = self.conv1d.output_scale
        half_scale = scale / 2.0

        # ç”¨æ­£å¸¸ scale åˆ¤æ–­å€¼çš„å¤§å°
        x_quantized = torch.round(x_6_3_fp32 / scale)

        # åˆ¤æ–­å°å€¼ vs å¤§å€¼ vs outlier
        is_small = (x_quantized.abs() < 64)      # å°å€¼: ç”¨ half scale (2x ç²¾åº¦)
        # is_outlier = (x_quantized.abs() > 127)   # outlier: ç”¨æ­£å¸¸ scale VQ (clamp)
        # is_normal = ~is_small & ~is_outlier    # å¤§å€¼: ç”¨æ­£å¸¸ scale

        # å°å€¼ç”¨ half scale (æ›´ç²¾ç¡®)
        x_small_quantized = torch.round(x_6_3_fp32 / half_scale).clamp(-127, 127)
        x_small = x_small_quantized * half_scale

        # å¤§å€¼å’Œ outlier ç”¨æ­£å¸¸ scale
        x_normal_vq = x_quantized.clamp(-128, 127) * scale

        # ç»„åˆ: å°å€¼ç”¨ half scale, å…¶ä½™ç”¨æ­£å¸¸ scale
        x_6_3_mixed = torch.where(is_small, x_small, x_normal_vq)

        # === Step 4: x_proj (FP32) - ç”¨ä¸Ž SSM ç›¸åŒçš„ HalfScale å€¼ï¼===
        x_6_3_reshape = rearrange(x_6_3_mixed, "b d l -> (b l) d")
        x_dbl_6_3 = self.x_proj.forward_mode6(x_6_3_reshape)  # FP32 output
        x_dbl_6_3 = x_dbl_6_3.view(batch, seqlen, -1)
        dt_6_3_raw, B_6_3_raw, C_6_3_raw = torch.split(x_dbl_6_3, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        # dt_proj: FP32 è¾“å‡º
        dt_6_3 = self.dt_proj.to_seqlen_last_mode6(dt_6_3_raw.contiguous())

        # B, C: reshape for selective_scan_fn
        B_6_3 = rearrange(B_6_3_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_6_3 = rearrange(C_6_3_raw, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # === Step 5: SSM (FP32) - ä½¿ç”¨ mamba_ssm åŽŸå§‹ FP32 kernel ===
        A_fp32 = -torch.exp(self.selective_scan.A_log.float() * self.selective_scan.A_scale)

        z_6_3_fp32 = z_6_3.float() * self.selective_scan.z_scale

        D_fp32 = None
        if self.selective_scan.D is not None:
            D_fp32 = self.selective_scan.D.float() * self.selective_scan.D_scale

        dt_bias_fp32 = None
        if self.selective_scan.dt_bias is not None:
            dt_bias_fp32 = self.selective_scan.dt_bias.float() * self.selective_scan.dt_bias_scale

        y_6_3 = selective_scan_fn(
            x_6_3_mixed,     # u: (batch, dim, seqlen) FP32 HalfScale mixed
            dt_6_3,          # delta: (batch, dim, seqlen) FP32
            A_fp32,          # A: (dim, dstate) FP32
            B_6_3,           # B: (batch, 1, dstate, seqlen) FP32
            C_6_3,           # C: (batch, 1, dstate, seqlen) FP32
            D=D_fp32,
            z=z_6_3_fp32,
            delta_bias=dt_bias_fp32,
            delta_softplus=True,
            return_last_state=False
        )

        # === Step 6: had + out_proj ===
        y_6_3 = rearrange(y_6_3, "b d l -> b l d")
        y_6_3_fp16 = y_6_3.half() if y_6_3.dtype != torch.float16 else y_6_3
        y_6_3 = self.had(y_6_3_fp16)
        out_6_3 = self.out_proj(y_6_3)

        return out_6_3

    def _get_pa1_output_scale(self, layer_idx):
        """
        èŽ·å–å½“å‰å±‚å¯¹åº”çš„ Î±=1.0 æ¨¡åž‹çš„ output_scale
        ä½¿ç”¨æ¨¡å—çº§å˜é‡ç¼“å­˜ï¼ŒåªåŠ è½½ä¸€æ¬¡
        """
        global _PA1_SCALES_CACHE, _PA1_MODEL_PATHS

        # æ ¹æ®æ¨¡åž‹ d_model åˆ¤æ–­æ¨¡åž‹å¤§å°
        if self.d_model == 768:
            model_size = '130m'
        elif self.d_model == 2048:
            model_size = '1.4b'
        elif self.d_model == 2560:
            model_size = '2.8b'
        else:
            raise ValueError(f"Unknown model size for d_model={self.d_model}")

        # æ£€æŸ¥ç¼“å­˜
        if model_size not in _PA1_SCALES_CACHE:
            # åŠ è½½ Î±=1.0 æ¨¡åž‹
            pa1_path = _PA1_MODEL_PATHS[model_size]
            model_file = _os.path.join(pa1_path, 'pytorch_model.bin')

            if not _os.path.exists(model_file):
                print(f"[Mode 6-4] Warning: Î±=1.0 model not found at {model_file}, using current scale")
                return self.conv1d.output_scale

            pa1_state = torch.load(model_file, map_location='cpu')

            # æå–æ‰€æœ‰å±‚çš„ output_scale
            _PA1_SCALES_CACHE[model_size] = {}
            for key, value in pa1_state.items():
                if 'conv1d.output_scale' in key:
                    # key æ ¼å¼: backbone.layers.{idx}.mixer.conv1d.output_scale
                    parts = key.split('.')
                    idx = int(parts[2])  # æå– layer index
                    # Handle both tensor and scalar values
                    if hasattr(value, 'item'):
                        _PA1_SCALES_CACHE[model_size][idx] = value.item()
                    else:
                        _PA1_SCALES_CACHE[model_size][idx] = float(value)

            print(f"[Mode 6-4] Loaded Î±=1.0 scales for {model_size} from {pa1_path}")

        return _PA1_SCALES_CACHE[model_size].get(layer_idx, self.conv1d.output_scale)

    def forward_mode6_4_eval(self, hidden_states, inference_params=None):
        """
        Mode 6-4: Calibrated DualScale INT8 è™šæ‹Ÿé‡åŒ– + x_proj ä¸€è‡´
        - Conv1D: INT8 è¾“å…¥ â†’ FP32 è¾“å‡º
        - DualScale Virtual Quant:
            - æ­£å¸¸å€¼ç”¨å½“å‰æ ¡å‡† scale (Î±=0.9995/0.9999)
            - Outlier ç”¨é¢„æ ¡å‡† scale (Î±=1.0)
        - Outlier åˆ¤å®š: ç”¨å½“å‰ scale
        - x_proj & SSM: ç”¨ç›¸åŒçš„ DualScale å€¼ï¼

        ä¸Ž Mode 6-3 çš„åŒºåˆ«:
        - 6-3: outlier_scale = max(outlier)/127 (åŠ¨æ€è®¡ç®—)
        - 6-4: outlier_scale = Î±=1.0 æ¨¡åž‹çš„ output_scale (é¢„æ ¡å‡†)
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (INT8) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)
        x_6_4, z_6_4 = xz.chunk(2, dim=1)

        # === Step 2: Conv1D (INT8 â†’ FP32) ===
        x_6_4_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_6_4, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )

        # === Step 3: Calibrated DualScale Virtual Quantization ===
        output_scale = self.conv1d.output_scale

        # èŽ·å– Î±=1.0 é¢„æ ¡å‡†çš„ outlier scale
        outlier_scale = self._get_pa1_output_scale(self.layer_idx)

        # Step 3.1: ç”¨å½“å‰ scale åˆ¤å®š outlier
        x_quantized = torch.round(x_6_4_fp32 / output_scale)
        is_outlier = (x_quantized.abs() > 127)

        # Step 3.2: æ­£å¸¸å€¼ç”¨å½“å‰ scale
        x_normal = x_quantized.clamp(-128, 127) * output_scale

        # Step 3.3: Outlier ç”¨é¢„æ ¡å‡†çš„ Î±=1.0 scale
        outlier_values = x_6_4_fp32[is_outlier]
        if outlier_values.numel() > 0:
            x_outlier_quantized = torch.round(outlier_values / outlier_scale)
            x_outlier = x_outlier_quantized.clamp(-128, 127) * outlier_scale
            x_6_4_mixed = x_normal.clone()
            x_6_4_mixed[is_outlier] = x_outlier
        else:
            x_6_4_mixed = x_normal

        # === Step 4: x_proj (FP32) - ç”¨ä¸Ž SSM ç›¸åŒçš„ DualScale å€¼ï¼===
        x_6_4_reshape = rearrange(x_6_4_mixed, "b d l -> (b l) d")
        x_dbl_6_4 = self.x_proj.forward_mode6(x_6_4_reshape)  # FP32 output
        x_dbl_6_4 = x_dbl_6_4.view(batch, seqlen, -1)
        dt_6_4_fp32, B_6_4_fp32, C_6_4_fp32 = torch.split(x_dbl_6_4, [self.dt_rank, self.d_state, self.d_state], dim=-1)

        # dt_proj: FP32 -> FP32 (via forward_mode6), then requantize to INT8 for SSM kernel
        dt_6_4_proj = self.dt_proj.to_seqlen_last_mode6(dt_6_4_fp32.contiguous())  # (B, D, L) FP32
        # Requantize dt to INT8 for SSM kernel - need contiguous for CUDA kernel
        dt_6_4 = torch.round(dt_6_4_proj / self.selective_scan.dt_scale).clamp(-128, 127).to(torch.int8).contiguous()

        # Requantize B, C to INT8 for SSM kernel
        B_6_4_rearranged = rearrange(B_6_4_fp32, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        B_6_4 = torch.round(B_6_4_rearranged / self.selective_scan.B_scale).clamp(-128, 127).to(torch.int8).contiguous()

        C_6_4_rearranged = rearrange(C_6_4_fp32, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_6_4 = torch.round(C_6_4_rearranged / self.selective_scan.C_scale).clamp(-128, 127).to(torch.int8).contiguous()

        # === Step 5: SSM (FP32 è¾“å…¥) - ç”¨ä¸Ž x_proj ç›¸åŒçš„ DualScale å€¼ï¼===
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_6_4, _ = quant_sscan_cuda.fwd_mode5(
            x_6_4_mixed,  # ä¸Ž x_proj ç›¸åŒçš„ DualScale å€¼
            dt_6_4, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_6_4, ensure_shape_1(self.selective_scan.B_scale),
            C_6_4, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z_6_4, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True
        )

        # === Step 6: had + out_proj ===
        y_6_4_fp16 = y_6_4.half() if y_6_4.dtype != torch.float16 else y_6_4
        y_6_4 = self.had(y_6_4_fp16)
        out_6_4 = self.out_proj(y_6_4)

        return out_6_4

    def forward_mode5(self, hidden_states, inference_params=None):
        """
        Mode 5: Dual-path forward (æ—§å®žçŽ°ï¼Œä¿ç•™å…¼å®¹æ€§)
        - Mode 0 path: Normal INT8 quantization
        - Mode 5 path: Conv1D outputs FP32, SSM receives FP32
        - Both paths start from the SAME initial quantized input
        - Compare outputs at each layer (layers 0, 1, 2, 23)
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (shared by both paths) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_int8, z = xz.chunk(2, dim=1)

        # === Step 2a: Mode 0 Conv1D (INT8 â†’ INT8) ===
        x_mode0 = quant_causal_conv1d_cuda.fwd(
            x_int8, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.output_scale, self.conv1d.bias_scale,
            self.conv1d.bias, None, None, None, True
        )  # INT8

        # === Step 2b: Mode 5 Conv1D (INT8 â†’ FP32) ===
        x_mode5_fp32 = quant_causal_conv1d_cuda.fwd_mode5(
            x_int8, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32

        # === Step 3a: Mode 0 SSM (INT8 input) ===
        x_mode0_reshape = rearrange(x_mode0, "b d l -> b l d").contiguous()
        x_dbl_mode0 = self.x_proj(x_mode0_reshape)
        dt_mode0, B_mode0, C_mode0 = torch.split(x_dbl_mode0, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_mode0 = self.dt_proj.to_seqlen_last(dt_mode0.contiguous())
        B_mode0 = rearrange(B_mode0, "b l dstate -> b dstate l", l=seqlen).contiguous()
        C_mode0 = rearrange(C_mode0, "b l dstate -> b dstate l", l=seqlen).contiguous()

        y_mode0 = self.selective_scan.forward(x_mode0, dt_mode0, B_mode0, C_mode0, z=z, return_last_state=False)

        # === Step 3b: Mode 5 SSM (FP32 input) ===
        # Requantize FP32 to INT8 for x_proj
        x_mode5_int8_for_xproj = torch.round(x_mode5_fp32 / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
        x_mode5_reshape = rearrange(x_mode5_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_mode5 = self.x_proj(x_mode5_reshape)
        dt_mode5, B_mode5, C_mode5 = torch.split(x_dbl_mode5, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_mode5 = self.dt_proj.to_seqlen_last(dt_mode5.contiguous())
        B_mode5 = rearrange(B_mode5, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_mode5 = rearrange(C_mode5, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # Call Mode 5 SSM kernel (FP32 input)
        # Helper to ensure scale tensors have shape (1,) instead of scalar
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_mode5, _ = quant_sscan_cuda.fwd_mode5(
            x_mode5_fp32,  # FP32 input
            dt_mode5, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_mode5, ensure_shape_1(self.selective_scan.B_scale),
            C_mode5, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 4: Compare outputs (for layers 0, 1, 2, 23) ===
        if self.layer_idx in [0, 1, 2, 23]:
            y_mode0_fp16 = y_mode0.half() if y_mode0.dtype != torch.float16 else y_mode0
            y_mode5_fp16 = y_mode5.half() if y_mode5.dtype != torch.float16 else y_mode5

            # Sample 3 values
            sample_indices = [0, y_mode0_fp16.numel() // 2, y_mode0_fp16.numel() - 1]
            y_mode0_flat = y_mode0_fp16.flatten()
            y_mode5_flat = y_mode5_fp16.flatten()

            # Statistics
            diff = (y_mode0_flat.float() - y_mode5_flat.float()).abs()

            print(f"\n{'='*80}")
            print(f"[Mode 5 Dual-Path] Layer {self.layer_idx}")
            print(f"{'='*80}")

            # === Input Statistics ===
            hs_flat = hidden_states.flatten().float()
            print(f"INPUT (hidden_states):")
            print(f"  Shape: {hidden_states.shape}, Dtype: {hidden_states.dtype}")
            print(f"  Mean: {hs_flat.mean().item():.6f}, Std: {hs_flat.std().item():.6f}")
            print(f"  Min: {hs_flat.min().item():.6f}, Max: {hs_flat.max().item():.6f}")

            # === Scale Values ===
            def get_scale_val(s):
                return s.item() if hasattr(s, 'item') else float(s)
            print(f"\nSCALE VALUES:")
            print(f"  Conv1D: input={get_scale_val(self.conv1d.input_scale):.8f}, output={get_scale_val(self.conv1d.output_scale):.8f}")
            print(f"  Conv1D: weight={get_scale_val(self.conv1d.weight_scale):.8f}, bias={get_scale_val(self.conv1d.bias_scale):.8f}")
            print(f"  SSM: dt={get_scale_val(self.selective_scan.dt_scale):.8f}, A={get_scale_val(self.selective_scan.A_scale):.8f}")
            print(f"  SSM: B={get_scale_val(self.selective_scan.B_scale):.8f}, C={get_scale_val(self.selective_scan.C_scale):.8f}")
            print(f"  SSM: D={get_scale_val(self.selective_scan.D_scale):.8f}, z={get_scale_val(self.selective_scan.z_scale):.8f}")

            # === Output Comparison ===
            print(f"\nOUTPUT COMPARISON:")
            print(f"Sample values (3 positions):")
            for idx in sample_indices:
                print(f"  [{idx}] Mode 0: {y_mode0_flat[idx].item():.6f}, Mode 5: {y_mode5_flat[idx].item():.6f}, Diff: {diff[idx].item():.6f}")
            print(f"Statistics:")
            print(f"  Mean: Mode 0={y_mode0_flat.float().mean().item():.6f}, Mode 5={y_mode5_flat.float().mean().item():.6f}")
            print(f"  Std:  Mode 0={y_mode0_flat.float().std().item():.6f}, Mode 5={y_mode5_flat.float().std().item():.6f}")
            print(f"  Min:  Mode 0={y_mode0_flat.min().item():.6f}, Mode 5={y_mode5_flat.min().item():.6f}")
            print(f"  Max:  Mode 0={y_mode0_flat.max().item():.6f}, Mode 5={y_mode5_flat.max().item():.6f}")
            print(f"Difference Statistics:")
            print(f"  Mean Abs Diff: {diff.mean().item():.6f}")
            print(f"  Max Abs Diff:  {diff.max().item():.6f}")
            print(f"{'='*80}\n")

        # === Step 5: Continue with Mode 5 output ===
        y_mode5_for_output = y_mode5.half() if y_mode5.dtype != torch.float16 else y_mode5
        y = self.had(y_mode5_for_output)
        out = self.out_proj(y)

        return out

    def forward_mode6(self, hidden_states, inference_params=None):
        """
        Mode 6: Dual-path forward
        - Mode 0 path: Takes quantized Mode 6 Conv FP32 output as input
        - Mode 6 path: Conv1D outputs FP32, SSM receives FP32
        - Mode 6 output feeds BOTH paths (quantized for Mode 0, FP32 for Mode 6)
        - Compare outputs at each layer (layers 0, 1, 2, 23)
        """
        import quant_causal_conv1d_cuda
        import quant_sscan_cuda

        batch, seqlen, dim = hidden_states.shape

        # === Step 1: in_proj (shared by both paths) ===
        xz = self.in_proj.to_seqlen_last(hidden_states)  # (B, D, L) INT8
        x_int8, z = xz.chunk(2, dim=1)

        # === Step 2: Mode 6 Conv1D (INT8 â†’ FP32) - å…±äº«èµ·ç‚¹ ===
        x_mode6_fp32 = quant_causal_conv1d_cuda.fwd_mode6(
            x_int8, self.conv1d.input_scale,
            self.conv1d.weight, self.conv1d.weight_scale,
            self.conv1d.bias_scale, self.conv1d.bias, True
        )  # FP32 - è¿™æ˜¯ä¸¤æ¡è·¯å¾„çš„å…±äº«èµ·ç‚¹

        # === Step 3: ä»Žå…±äº«çš„ x_mode6_fp32 åˆ†å‰ ===
        # Mode 0: é‡åŒ– FP32 Conv è¾“å‡ºä¸º INT8ï¼Œç›´æŽ¥ç”¨äºŽ x_proj å’Œ SSM (ä¸å†åšç¬¬äºŒæ¬¡ Conv1D!)
        x_mode0_int8 = torch.round(x_mode6_fp32 / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)

        # === Step 4a: Mode 0 SSM (ç”¨é‡åŒ–åŽçš„ x_mode0_int8) ===
        x_mode0_reshape = rearrange(x_mode0_int8, "b d l -> b l d").contiguous()
        x_dbl_mode0 = self.x_proj(x_mode0_reshape)
        dt_mode0, B_mode0, C_mode0 = torch.split(x_dbl_mode0, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_mode0 = self.dt_proj.to_seqlen_last(dt_mode0.contiguous())
        B_mode0 = rearrange(B_mode0, "b l dstate -> b dstate l", l=seqlen).contiguous()
        C_mode0 = rearrange(C_mode0, "b l dstate -> b dstate l", l=seqlen).contiguous()

        y_mode0 = self.selective_scan.forward(x_mode0_int8, dt_mode0, B_mode0, C_mode0, z=z, return_last_state=False)

        # === Step 4b: Mode 6 SSM (FP32 input) ===
        # Requantize FP32 to INT8 for x_proj
        x_mode6_int8_for_xproj = torch.round(x_mode6_fp32 / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
        x_mode6_reshape = rearrange(x_mode6_int8_for_xproj, "b d l -> b l d").contiguous()
        x_dbl_mode6 = self.x_proj(x_mode6_reshape)
        dt_mode6, B_mode6, C_mode6 = torch.split(x_dbl_mode6, [self.dt_rank, self.d_state, self.d_state], dim=-1)
        dt_mode6 = self.dt_proj.to_seqlen_last(dt_mode6.contiguous())
        B_mode6 = rearrange(B_mode6, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()
        C_mode6 = rearrange(C_mode6, "b l dstate -> b 1 dstate l", l=seqlen).contiguous()

        # Call Mode 6 SSM kernel (FP32 input)
        # Helper to ensure scale tensors have shape (1,) instead of scalar
        def ensure_shape_1(t):
            return t.view(1) if t.dim() == 0 else t

        y_mode6, _ = quant_sscan_cuda.fwd_mode6(
            x_mode6_fp32,  # FP32 input
            dt_mode6, ensure_shape_1(self.selective_scan.dt_scale),
            self.selective_scan.A_log, ensure_shape_1(self.selective_scan.A_scale),
            B_mode6, ensure_shape_1(self.selective_scan.B_scale),
            C_mode6, ensure_shape_1(self.selective_scan.C_scale),
            ensure_shape_1(self.selective_scan.ssm_state_scale),
            self.selective_scan.D, ensure_shape_1(self.selective_scan.D_scale),
            z, ensure_shape_1(self.selective_scan.z_scale),
            self.selective_scan.dt_bias, ensure_shape_1(self.selective_scan.dt_bias_scale),
            True  # delta_softplus
        )

        # === Step 5: Compare outputs (for layers 0, 1, 2, 23) ===
        if self.layer_idx in [0, 1, 2, 23]:
            y_mode0_fp16 = y_mode0.half() if y_mode0.dtype != torch.float16 else y_mode0
            y_mode6_fp16 = y_mode6.half() if y_mode6.dtype != torch.float16 else y_mode6

            # Sample 3 values
            sample_indices = [0, y_mode0_fp16.numel() // 2, y_mode0_fp16.numel() - 1]
            y_mode0_flat = y_mode0_fp16.flatten()
            y_mode6_flat = y_mode6_fp16.flatten()

            # Statistics
            diff = (y_mode0_flat.float() - y_mode6_flat.float()).abs()

            print(f"\n{'='*80}")
            print(f"[Mode 6 Dual-Path] Layer {self.layer_idx}")
            print(f"{'='*80}")

            # === Input Statistics ===
            hs_flat = hidden_states.flatten().float()
            print(f"INPUT (hidden_states):")
            print(f"  Shape: {hidden_states.shape}, Dtype: {hidden_states.dtype}")
            print(f"  Mean: {hs_flat.mean().item():.6f}, Std: {hs_flat.std().item():.6f}")
            print(f"  Min: {hs_flat.min().item():.6f}, Max: {hs_flat.max().item():.6f}")

            # === Shared Starting Point (x_mode6_fp32) ===
            fp32_flat = x_mode6_fp32.flatten()
            print(f"\nSHARED STARTING POINT (x_mode6_fp32 - Conv1D FP32 output):")
            print(f"  Shape: {x_mode6_fp32.shape}, Dtype: {x_mode6_fp32.dtype}")
            print(f"  Mean: {fp32_flat.mean().item():.6f}, Std: {fp32_flat.std().item():.6f}")
            print(f"  Min: {fp32_flat.min().item():.6f}, Max: {fp32_flat.max().item():.6f}")

            # === Scale Values ===
            def get_scale_val(s):
                return s.item() if hasattr(s, 'item') else float(s)
            print(f"\nSCALE VALUES:")
            print(f"  Conv1D: input={get_scale_val(self.conv1d.input_scale):.8f}, output={get_scale_val(self.conv1d.output_scale):.8f}")
            print(f"  Conv1D: weight={get_scale_val(self.conv1d.weight_scale):.8f}, bias={get_scale_val(self.conv1d.bias_scale):.8f}")
            print(f"  SSM: dt={get_scale_val(self.selective_scan.dt_scale):.8f}, A={get_scale_val(self.selective_scan.A_scale):.8f}")
            print(f"  SSM: B={get_scale_val(self.selective_scan.B_scale):.8f}, C={get_scale_val(self.selective_scan.C_scale):.8f}")
            print(f"  SSM: D={get_scale_val(self.selective_scan.D_scale):.8f}, z={get_scale_val(self.selective_scan.z_scale):.8f}")

            # === Quantization Comparison ===
            x_mode0_flat = x_mode0_int8.flatten().float()
            x_mode6_int8_flat = x_mode6_int8_for_xproj.flatten().float()
            quant_diff = (x_mode0_flat - x_mode6_int8_flat).abs()
            print(f"\nQUANTIZATION CHECK (x_mode0_int8 vs x_mode6_int8_for_xproj):")
            print(f"  Should be identical since both come from same FP32: {quant_diff.max().item() == 0}")
            print(f"  Max diff: {quant_diff.max().item():.6f}")

            # === Output Comparison ===
            print(f"\nOUTPUT COMPARISON:")
            print(f"Sample values (3 positions):")
            for idx in sample_indices:
                print(f"  [{idx}] Mode 0: {y_mode0_flat[idx].item():.6f}, Mode 6: {y_mode6_flat[idx].item():.6f}, Diff: {diff[idx].item():.6f}")
            print(f"Statistics:")
            print(f"  Mean: Mode 0={y_mode0_flat.float().mean().item():.6f}, Mode 6={y_mode6_flat.float().mean().item():.6f}")
            print(f"  Std:  Mode 0={y_mode0_flat.float().std().item():.6f}, Mode 6={y_mode6_flat.float().std().item():.6f}")
            print(f"  Min:  Mode 0={y_mode0_flat.min().item():.6f}, Mode 6={y_mode6_flat.min().item():.6f}")
            print(f"  Max:  Mode 0={y_mode0_flat.max().item():.6f}, Mode 6={y_mode6_flat.max().item():.6f}")
            print(f"Difference Statistics:")
            print(f"  Mean Abs Diff: {diff.mean().item():.6f}")
            print(f"  Max Abs Diff:  {diff.max().item():.6f}")
            print(f"{'='*80}\n")

        # === Step 6: Continue with Mode 6 output ===
        y_mode6_for_output = y_mode6.half() if y_mode6.dtype != torch.float16 else y_mode6
        y = self.had(y_mode6_for_output)
        out = self.out_proj(y)

        return out

# ===== DUAL MODE COMPARISON HELPER FUNCTION =====
# Global accumulator for all samples
_dual_mode_stats = {
    'sample_count': 0,
    'total_mean_diff': 0.0,
    'total_max_diff': 0.0,
    'all_diffs': []
}

def dual_mode_compare_ssm(layer_self, x, dt, B, C, z, output_scale):
    """
    Helper function to compare Mode 2-0 vs Mode 2-1 SSM outputs.
    Called when DUAL_MODE_DEBUG=true.
    Accumulates statistics across ALL samples.

    Args:
        layer_self: The MambaLayer instance
        x: Conv1D output (INT8)
        dt, B, C, z: SSM inputs
        output_scale: Conv1D output scale for dequantization
    """
    import torch
    import os
    global _dual_mode_stats

    # Only print details for first sample
    if _dual_mode_stats['sample_count'] == 0:
        print(f"\n{'='*80}")
        print(f"ðŸ”¬ DUAL MODE COMPARISON - Layer {layer_self.layer_idx}")
        print(f"{'='*80}")
        print(f"ðŸ“Š Conv1D Output (Sample 1, shared input for both modes):")
        print(f"    dtype: {x.dtype}")
        print(f"    first 5 values [0,0,:5]: {x[0, 0, :5].tolist()}")
        print(f"    output_scale: {output_scale:.10f}")
        print(f"")

    # Prepare inputs for BOTH modes
    x_mode20_fp32 = x.float() * output_scale  # Mode 2-0: dequantize to FP32
    x_mode21_int8 = x  # Mode 2-1: keep INT8

    if _dual_mode_stats['sample_count'] == 0:
        print(f"ðŸ”€ Mode 2-0 (CUDA INT8 with FP32 input):")
        print(f"    u dtype: torch.float32")
        print(f"    u first 5 values: {x_mode20_fp32[0, 0, :5].tolist()}")
        print(f"")

        print(f"ðŸ”€ Mode 2-1 (PyTorch INT8 direct):")
        print(f"    u dtype: torch.int8")
        print(f"    u first 5 values: {x_mode21_int8[0, 0, :5].tolist()}")
        print(f"    u first 5 (dequantized for ref): {(x_mode21_int8.float() * output_scale)[0, 0, :5].tolist()}")
        print(f"")

        # Run BOTH SSM kernels and compare outputs
        print(f"ðŸš€ Running BOTH SSM kernels for ALL 100 samples...")

    # Save original environment
    original_env = {
        'SSM_USE_PYTORCH_INT8': os.environ.get('SSM_USE_PYTORCH_INT8', 'false'),
        'SSM_USE_CUDA_FOR_FP32': os.environ.get('SSM_USE_CUDA_FOR_FP32', 'false'),
        'DUAL_MODE_DEBUG': 'true'
    }

    # Temporarily disable debug mode to avoid infinite recursion
    os.environ['DUAL_MODE_DEBUG'] = 'false'

    try:
        # Run Mode 2-0: CUDA INT8 SSM with FP32 input
        os.environ['SSM_USE_PYTORCH_INT8'] = 'false'
        os.environ['SSM_USE_CUDA_FOR_FP32'] = 'true'
        y_ssm_mode20 = layer_self.selective_scan.forward(x_mode20_fp32, dt, B, C, z=z, return_last_state=False)

        # Run Mode 2-1: PyTorch INT8 SSM with INT8 input
        os.environ['SSM_USE_PYTORCH_INT8'] = 'true'
        os.environ['SSM_USE_CUDA_FOR_FP32'] = 'false'
        y_ssm_mode21 = layer_self.selective_scan.forward(x_mode21_int8, dt, B, C, z=z, return_last_state=False)

        # Continue through had + out_proj to get final layer output
        y_had_mode20 = layer_self.had(y_ssm_mode20)
        y_had_mode21 = layer_self.had(y_ssm_mode21)

        out_mode20 = layer_self.out_proj(y_had_mode20)
        out_mode21 = layer_self.out_proj(y_had_mode21)

        # Compute SSM output difference
        diff_ssm = (y_ssm_mode20.float() - y_ssm_mode21.float()).abs()
        mean_diff_ssm = diff_ssm.mean().item()
        max_diff_ssm = diff_ssm.max().item()

        # Compute final layer output difference
        diff_out = (out_mode20.float() - out_mode21.float()).abs()
        mean_diff_out = diff_out.mean().item()
        max_diff_out = diff_out.max().item()

        # Accumulate statistics
        _dual_mode_stats['sample_count'] += 1
        _dual_mode_stats['total_mean_diff'] += mean_diff_ssm
        _dual_mode_stats['total_max_diff'] = max(max_diff_ssm, _dual_mode_stats['total_max_diff'])
        _dual_mode_stats['all_diffs'].append(mean_diff_ssm)

        # Also track layer output differences
        if 'total_mean_diff_out' not in _dual_mode_stats:
            _dual_mode_stats['total_mean_diff_out'] = 0.0
            _dual_mode_stats['total_max_diff_out'] = 0.0
            _dual_mode_stats['all_diffs_out'] = []

        _dual_mode_stats['total_mean_diff_out'] += mean_diff_out
        _dual_mode_stats['total_max_diff_out'] = max(max_diff_out, _dual_mode_stats['total_max_diff_out'])
        _dual_mode_stats['all_diffs_out'].append(mean_diff_out)

        # Print details for first sample only
        if _dual_mode_stats['sample_count'] == 1:
            print(f"")
            print(f"ðŸ“ˆ SSM Output Comparison (Sample 1):")
            print(f"    Mode 2-0 first 5 values [0,0,:5]: {y_ssm_mode20[0, 0, :5].tolist()}")
            print(f"    Mode 2-1 first 5 values [0,0,:5]: {y_ssm_mode21[0, 0, :5].tolist()}")
            print(f"    Mean absolute diff: {mean_diff_ssm:.6f}")
            print(f"    Max absolute diff: {max_diff_ssm:.6f}")
            print(f"")
            print(f"ðŸ“ˆ After Hadamard (Sample 1):")
            print(f"    Mode 2-0 had output [0,0,:5]: {y_had_mode20[0, 0, :5].tolist()}")
            print(f"    Mode 2-1 had output [0,0,:5]: {y_had_mode21[0, 0, :5].tolist()}")
            print(f"")
            print(f"ðŸ“ˆ Final Layer Output (Sample 1):")
            print(f"    Mode 2-0 first 5 values [0,0,:5]: {out_mode20[0, 0, :5].tolist()}")
            print(f"    Mode 2-1 first 5 values [0,0,:5]: {out_mode21[0, 0, :5].tolist()}")
            print(f"    Mean absolute diff: {mean_diff_out:.6f}")
            print(f"    Max absolute diff: {max_diff_out:.6f}")
            print(f"")
            print(f"â³ Continuing to compare remaining samples (progress shown by lm_eval)...")
            print(f"{'='*80}\n")

        # Print summary after all samples
        if _dual_mode_stats['sample_count'] == 100:
            avg_mean_diff_ssm = _dual_mode_stats['total_mean_diff'] / 100
            avg_mean_diff_out = _dual_mode_stats['total_mean_diff_out'] / 100
            print(f"\n{'='*80}")
            print(f"ðŸ“Š DUAL MODE COMPARISON - FINAL SUMMARY (100 samples)")
            print(f"{'='*80}")
            print(f"")
            print(f"ðŸ”¹ SSM Output Differences:")
            print(f"  Average mean absolute diff: {avg_mean_diff_ssm:.6f}")
            print(f"  Maximum absolute diff: {_dual_mode_stats['total_max_diff']:.6f}")
            import statistics
            print(f"  Min: {min(_dual_mode_stats['all_diffs']):.6f}")
            print(f"  Max: {max(_dual_mode_stats['all_diffs']):.6f}")
            print(f"  Median: {statistics.median(_dual_mode_stats['all_diffs']):.6f}")
            print(f"")
            print(f"ðŸ”¹ Final Layer Output Differences (after had + out_proj):")
            print(f"  Average mean absolute diff: {avg_mean_diff_out:.6f}")
            print(f"  Maximum absolute diff: {_dual_mode_stats['total_max_diff_out']:.6f}")
            print(f"  Min: {min(_dual_mode_stats['all_diffs_out']):.6f}")
            print(f"  Max: {max(_dual_mode_stats['all_diffs_out']):.6f}")
            print(f"  Median: {statistics.median(_dual_mode_stats['all_diffs_out']):.6f}")
            print(f"")
            if avg_mean_diff_out < 0.001:
                print(f"âœ… Mode 2-0 and Mode 2-1 produce nearly IDENTICAL layer outputs!")
                print(f"   Difference < 0.001 is within floating-point precision.")
            else:
                print(f"âš ï¸  Mode 2-0 and Mode 2-1 have measurable differences in layer outputs.")
                print(f"   This could lead to different final predictions.")
            print(f"{'='*80}\n")

    finally:
        # Restore original environment
        for key, value in original_env.items():
            os.environ[key] = value
