#!/bin/bash

# Quamba2 - Mamba2 8B ç³»åˆ—å®éªŒï¼ˆå®éªŒ15-20ï¼‰
# W4A8, W4A16, W8A8 å„åš default + pa=1.0
# æ€»å…± 6 ä¸ªå®éªŒ
# ä½œè€…ï¼šYZ
# æ—¥æœŸï¼š2025-11-04

set -e  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢

LOG_FILE="run_mamba2_8b_$(date +%Y%m%d_%H%M%S).log"
exec 2>&1 | tee -a "$LOG_FILE"

echo "========================================================================"
echo "ğŸš€ å¼€å§‹è¿è¡Œ Mamba2 8B å®éªŒï¼ˆå®éªŒ15-20ï¼‰"
echo "========================================================================"
echo "æ€»å®éªŒæ•°: 6 ä¸ª"
echo "é¢„è®¡æ€»æ—¶é—´: 3-3.5 å°æ—¶"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
echo ""

# ============================================================================
# Mamba2 8B W4A8
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W4A8 - é»˜è®¤ (15/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W4A8 - pa=1.0 (16/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# Mamba2 8B W4A16
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W4A16 - é»˜è®¤ (17/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W4A16 - pa=1.0 (18/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# Mamba2 8B W8A8
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W8A8 - é»˜è®¤ (19/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Quamba2: Mamba2 8B W8A8 - pa=1.0 (20/20)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs \
  --output_subdir quamba2
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# å®Œæˆ
# ============================================================================

echo "========================================================================"
echo "ğŸ‰ Mamba2 8B æ‰€æœ‰ 6 ä¸ªå®éªŒå®Œæˆï¼"
echo "========================================================================"
echo "ç»“æŸæ—¶é—´: $(date)"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
echo ""
echo "ğŸ“Š æŸ¥çœ‹ç»“æœï¼š"
echo "  - æ¨¡å‹: pretrained_models/quamba2/"
echo "  - æ—¥å¿—: logs/"
echo ""
echo "å®éªŒå®Œæˆç»Ÿè®¡ï¼š"
echo "  ğŸŸ¢ Mamba2 8B W4A8:  2 ä¸ªï¼ˆé»˜è®¤ + pa=1.0ï¼‰"
echo "  ğŸŸ¢ Mamba2 8B W4A16: 2 ä¸ªï¼ˆé»˜è®¤ + pa=1.0ï¼‰"
echo "  ğŸŸ¢ Mamba2 8B W8A8:  2 ä¸ªï¼ˆé»˜è®¤ + pa=1.0ï¼‰"
echo "  æ€»è®¡: 6 ä¸ªå®éªŒ"
echo ""
echo "æ–‡ä»¶å¤¹ç»“æ„ï¼š"
echo "  pretrained_models/quamba2/default/"
echo "    â”œâ”€â”€ quamba2-8b-converted-w4a8/"
echo "    â”œâ”€â”€ quamba2-8b-converted-w4a16/"
echo "    â””â”€â”€ quamba2-8b-converted-w8a8/"
echo "  pretrained_models/quamba2/pa-1/"
echo "    â”œâ”€â”€ quamba2-8b-converted-w4a8/"
echo "    â”œâ”€â”€ quamba2-8b-converted-w4a16/"
echo "    â””â”€â”€ quamba2-8b-converted-w8a8/"
echo "========================================================================"
