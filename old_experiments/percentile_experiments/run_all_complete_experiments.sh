#!/bin/bash

# Quamba å®Œæ•´å®éªŒè„šæœ¬ - æ–¹æ¡ˆB (é»˜è®¤ + percentile_alpha=1.0 å…¨å¯¹æ¯”)
# åŒ…å«æ‰€æœ‰æ¨¡å‹ï¼ˆMamba1 + Mamba2ï¼‰ï¼Œæ¯ä¸ªåšä¸¤æ¬¡ï¼ˆé»˜è®¤å’Œpa=1.0ï¼‰
# æ€»å…± 24 ä¸ªå®éªŒ
# ä½œè€…ï¼šYZ
# æ—¥æœŸï¼š2025-11-04

set -e  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢

LOG_FILE="run_complete_experiments_$(date +%Y%m%d_%H%M%S).log"
exec 2>&1 | tee -a "$LOG_FILE"

echo "========================================================================"
echo "ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰å®Œæ•´å®éªŒï¼ˆé»˜è®¤ + percentile_alpha=1.0ï¼‰"
echo "========================================================================"
echo "æ€»å®éªŒæ•°: 24 ä¸ª"
echo "é¢„è®¡æ€»æ—¶é—´: 8-10 å°æ—¶"
echo "å¼€å§‹æ—¶é—´: $(date)"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
echo ""

# ============================================================================
# Mamba1 ç³»åˆ—å®éªŒ (W8A8) - 8ä¸ªå®éªŒ
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Mamba1 130M W8A8 - é»˜è®¤ (1/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 130M W8A8 - pa=1.0 (2/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 370M W8A8 - é»˜è®¤ (3/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-370m \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 370M W8A8 - pa=1.0 (4/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-370m \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 1.4B W8A8 - é»˜è®¤ (5/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-1.4b \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 1.4B W8A8 - pa=1.0 (6/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-1.4b \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 2.8B W8A8 - é»˜è®¤ (7/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-2.8b \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba1 2.8B W8A8 - pa=1.0 (8/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-2.8b \
  --quantize \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# Mamba2 130M ç³»åˆ—å®éªŒ - 4ä¸ªå®éªŒ
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Mamba2 130M W4A8 - é»˜è®¤ (9/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/ut-enyac/pretrained_models/mamba2-130m \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 130M W4A8 - pa=1.0 (10/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/ut-enyac/pretrained_models/mamba2-130m \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 130M W8A8 - é»˜è®¤ (11/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/ut-enyac/pretrained_models/mamba2-130m \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 130M W8A8 - pa=1.0 (12/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/ut-enyac/pretrained_models/mamba2-130m \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# Mamba2 2.7B ç³»åˆ—å®éªŒ - 6ä¸ªå®éªŒ
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W4A8 - é»˜è®¤ (13/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W4A8 - pa=1.0 (14/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W8A8 - é»˜è®¤ (15/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W8A8 - pa=1.0 (16/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W4A16 - é»˜è®¤ (17/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 2.7B W4A16 - pa=1.0 (18/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py state-spaces/mamba2-2.7b \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# Mamba2 8B ç³»åˆ—å®éªŒ - 6ä¸ªå®éªŒ
# ============================================================================

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W4A8 - é»˜è®¤ (19/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W4A8 - pa=1.0 (20/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W8A8 - é»˜è®¤ (21/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W8A8 - pa=1.0 (22/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 8 \
  --a_bits 8 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W4A16 - é»˜è®¤ (23/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

echo "========================================================================"
echo "ğŸ“Š Mamba2 8B W4A16 - pa=1.0 (24/24)"
echo "========================================================================"
echo "å¼€å§‹æ—¶é—´: $(date)"
python3 main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba2-8b-converted \
  --quantize \
  --group_heads \
  --apply_gptq \
  --quantize_embedding \
  --quantize_lm_head \
  --w_bits 4 \
  --a_bits 16 \
  --percentile_alpha 1.0 \
  --batch_size 16 \
  --eval_zero_shot \
  --task_list lambada_openai \
  --pretrained_dir ./pretrained_models \
  --log_dir logs
echo "âœ… å®Œæˆæ—¶é—´: $(date)"
echo ""

# ============================================================================
# å®Œæˆ
# ============================================================================

echo "========================================================================"
echo "ğŸ‰ æ‰€æœ‰ 24 ä¸ªå®éªŒå®Œæˆï¼"
echo "========================================================================"
echo "ç»“æŸæ—¶é—´: $(date)"
echo "æ—¥å¿—æ–‡ä»¶: $LOG_FILE"
echo ""
echo "ğŸ“Š æŸ¥çœ‹ç»“æœï¼š"
echo "  - æ—¥å¿—ç›®å½•: logs/"
echo "  - æ¨¡å‹ç›®å½•: pretrained_models/yzReproduceauthors/"
echo ""
echo "å®éªŒå®Œæˆç»Ÿè®¡ï¼š"
echo "  Mamba1 ç³»åˆ—: 8 ä¸ªå®éªŒ (4ä¸ªæ¨¡å‹ Ã— 2é…ç½®)"
echo "  Mamba2 130M: 4 ä¸ªå®éªŒ (2ä¸ªé‡åŒ– Ã— 2é…ç½®)"
echo "  Mamba2 2.7B: 6 ä¸ªå®éªŒ (3ä¸ªé‡åŒ– Ã— 2é…ç½®)"
echo "  Mamba2 8B:   6 ä¸ªå®éªŒ (3ä¸ªé‡åŒ– Ã— 2é…ç½®)"
echo "  æ€»è®¡: 24 ä¸ªå®éªŒ"
echo "========================================================================"
