# Mode 2-1 vs Mode 2-0 è°ƒè¯•å¯¹æ¯”

**é—®é¢˜**: Mode 2-1 æ­£ç¡®ç‡ä¸º 36.0%ï¼Œä½äºé¢„æœŸçš„ 38.0% (Mode 2-0 å’Œ Mode 0 çš„æ°´å¹³)

**æ—¥æœŸ**: 2025-11-23
**ç›®æ ‡**: æ‰¾å‡º Mode 2-1 ç›¸å¯¹ Mode 2-0 çš„å…³é”®å·®å¼‚ï¼Œå®šä½æ€§èƒ½ä¸‹é™åŸå› 

---

## ğŸ“Š å®é™…ç»“æœå¯¹æ¯”

| Mode | æè¿° | Accuracy | æœŸæœ› | çŠ¶æ€ |
|------|------|----------|------|------|
| **Mode 0** | åŸºå‡† INT8 CUDA | **38.0%** âœ… | åŸºå‡† | âœ… ç¬¦åˆé¢„æœŸ |
| **Mode 2-0** | Dequant + CUDA INT8 SSM | **38.0%** âœ… | 38.0% | âœ… ç¬¦åˆé¢„æœŸ |
| **Mode 2-1** | INT8 + PyTorch INT8 SSM | **36.0%** âŒ | 38.0% | âŒ **ä½äºé¢„æœŸ 2%** |

**å…³é”®é—®é¢˜**: Mode 2-1 å’Œ Mode 2-0 çš„å”¯ä¸€å·®å¼‚æ˜¯ SSM å®ç°ï¼ˆPyTorch INT8 vs CUDA INT8ï¼‰ï¼Œä»¥åŠæ•°æ®åˆ†å‰å¤„çš„å¤„ç†æ–¹å¼ã€‚

---

## ğŸ” å®Œæ•´æ•°æ®æµå¯¹æ¯”ï¼ˆçªå‡ºå·®å¼‚ï¼‰

### æ•°æ®æµé˜¶æ®µå¯¹æ¯”è¡¨

| é˜¶æ®µ | Mode 2-0 | Mode 2-1 | å·®å¼‚æ ‡æ³¨ |
|------|----------|----------|----------|
| **in_proj è¾“å…¥** | `hidden_states` FP16/FP32 | `hidden_states` FP16/FP32 | âœ… ç›¸åŒ |
| **in_proj å‡½æ•°** | HadLinear W4A8B16O16 | HadLinear W4A8B16O16 | âœ… ç›¸åŒ |
| **in_proj è¾“å‡º** | `xz` INT8 BÃ—LÃ—2D | `xz` INT8 BÃ—LÃ—2D | âœ… ç›¸åŒ |
| **Conv1D è¾“å…¥** | `x` INT8 BÃ—DÃ—L | `x` INT8 BÃ—DÃ—L | âœ… ç›¸åŒ |
| **Conv1D å‡½æ•°** | CUDA INT8 `quant_causal_conv1d_cuda.fwd()` | CUDA INT8 `quant_causal_conv1d_cuda.fwd()` | âœ… ç›¸åŒ |
| **Conv1D è¾“å‡º** | `x` INT8 BÃ—DÃ—L | `x` INT8 BÃ—DÃ—L | âœ… ç›¸åŒ |
| **SiLU** | (èåˆåœ¨ Conv1D ä¸­) INT8 | (èåˆåœ¨ Conv1D ä¸­) INT8 | âœ… ç›¸åŒ |
| **ğŸ”´ æ•°æ®åˆ†å‰å¤„ç†** | **Dequant**: `x.float() * scale`<br>`x_for_ssm` = **FP32 (INT8 grid)** | **ä¿æŒINT8**: `x_for_ssm = x`<br>`x_for_ssm` = **INT8** | âŒ **å…³é”®å·®å¼‚1** |
| **x_proj è·¯å¾„** | `x_for_xproj` = INT8 (ä¿æŒ) | `x_for_xproj` = INT8 (ä¿æŒ) | âœ… ç›¸åŒ |
| **x_proj å‡½æ•°** | W8A8B8O8 | W8A8B8O8 | âœ… ç›¸åŒ |
| **x_proj è¾“å‡º** | `dt,B,C` INT8 | `dt,B,C` INT8 | âœ… ç›¸åŒ |
| **dt_proj å‡½æ•°** | W8A8B8O8 | W8A8B8O8 | âœ… ç›¸åŒ |
| **dt_proj è¾“å‡º** | `dt` INT8 | `dt` INT8 | âœ… ç›¸åŒ |
| **ğŸ”´ SSM è¾“å…¥ (u)** | `x_for_ssm` = **FP32 (INT8 grid)**<br>BÃ—DÃ—L | `x_for_ssm` = **INT8**<br>BÃ—DÃ—L | âŒ **å…³é”®å·®å¼‚2** |
| **SSM å…¶ä»–è¾“å…¥** | `dt,B,C,z` å…¨éƒ¨ INT8 | `dt,B,C,z` å…¨éƒ¨ INT8 | âœ… ç›¸åŒ |
| **ğŸ”´ SSM å®ç°** | **CUDA INT8 selective_scan**<br>(ç¡¬ä»¶ä¼˜åŒ–) | **PyTorch INT8 selective_scan**<br>(å†…éƒ¨ dequant + è½¯ä»¶å®ç°) | âŒ **å…³é”®å·®å¼‚3** |
| **SSM è¾“å‡º** | `y` FP16 BÃ—DÃ—L | `y` FP16 BÃ—DÃ—L | âœ… ç›¸åŒ |
| **Hadamard** | scale=1/âˆšd | scale=1/âˆšd | âœ… ç›¸åŒ |
| **out_proj** | HadLinear W4A8B16O16 | HadLinear W4A8B16O16 | âœ… ç›¸åŒ |
| **out_proj è¾“å‡º** | `output` FP16 | `output` FP16 | âœ… ç›¸åŒ |
| **ç¯å¢ƒå˜é‡** | `FLOAT_SIM_ASIC_INT8=true`<br>`SSM_USE_CUDA_FOR_FP32=true` | `FLOAT_SIM_ASIC_INT8=true`<br>`SSM_USE_PYTORCH_INT8=true` | âŒ **å·®å¼‚4** |

---

## ğŸ”´ å…³é”®å·®å¼‚è¯¦è§£

### å·®å¼‚ 1: æ•°æ®åˆ†å‰å¤„çš„å¤„ç†æ–¹å¼

**ä»£ç ä½ç½®**: `quamba/qMambaLayer.py`

#### Mode 2-0 (38.0% âœ…)
```python
# qMambaLayer:751
x_for_xproj = x  # ä¿æŒ INT8 ç”¨äº x_proj è·¯å¾„

# qMambaLayer:760 - å…³é”®ï¼Dequant æ“ä½œ
x_for_ssm = x.float() * self.conv1d.output_scale  # INT8 â†’ FP32 (INT8 grid)
```

#### Mode 2-1 (36.0% âŒ)
```python
# qMambaLayer:751
x_for_xproj = x  # ä¿æŒ INT8 ç”¨äº x_proj è·¯å¾„

# qMambaLayer:757 - å…³é”®ï¼ä¿æŒ INT8
x_for_ssm = x  # ä¿æŒ INT8
```

**å·®å¼‚è¯´æ˜**:
- Mode 2-0: åœ¨ä¼ å…¥ SSM å‰å…ˆ **Dequant** åˆ° FP32 (æ•°å€¼ä»åœ¨ INT8 grid èŒƒå›´å†…)
- Mode 2-1: ç›´æ¥ä¼ å…¥ **INT8** å¼ é‡ç»™ SSM

**å½±å“åˆ†æ**:
- Mode 2-0 çš„ SSM æ¥æ”¶ **FP32 dtype** æ•°æ®ï¼ˆå€¼åœ¨ INT8 gridï¼‰
- Mode 2-1 çš„ SSM æ¥æ”¶ **INT8 dtype** æ•°æ®
- PyTorch INT8 SSM å†…éƒ¨ä¼šè¿›è¡Œ dequantï¼Œä½†å¯èƒ½å¤„ç†æ–¹å¼ä¸åŒ

---

### å·®å¼‚ 2: SSM è¾“å…¥æ•°æ®ç±»å‹

#### Mode 2-0
```python
# SSM æ¥æ”¶çš„ u (è·¯å¾„B)
u: torch.float32  # dtype = FP32
# å€¼åŸŸ: [-127, 127] èŒƒå›´å†…çš„æ•´æ•°å€¼ (INT8 grid)
# ä¾‹å¦‚: tensor([45.0, -12.0, 127.0, -3.0])
```

#### Mode 2-1
```python
# SSM æ¥æ”¶çš„ u (è·¯å¾„B)
u: torch.int8  # dtype = INT8
# å€¼åŸŸ: [-128, 127]
# ä¾‹å¦‚: tensor([45, -12, 127, -3], dtype=torch.int8)
```

**dtype å·®å¼‚å¯èƒ½å¯¼è‡´çš„é—®é¢˜**:
1. **Scale åº”ç”¨æ—¶æœºä¸åŒ**:
   - Mode 2-0: SSM çŸ¥é“è¾“å…¥æ˜¯ FP32ï¼Œå¯èƒ½ç›´æ¥ä½¿ç”¨ scale è¿›è¡Œè®¡ç®—
   - Mode 2-1: SSM å†…éƒ¨éœ€è¦å…ˆ dequant (INT8 â†’ FP32)ï¼Œå¯èƒ½å¼•å…¥é¢å¤–çš„æ•°å€¼è¯¯å·®

2. **æ•°å€¼ç²¾åº¦å·®å¼‚**:
   - INT8 dtype å¯èƒ½åœ¨æŸäº›æ“ä½œä¸­è¢«å¼ºåˆ¶è½¬æ¢ï¼ŒæŸå¤±ç²¾åº¦
   - FP32 dtype å³ä½¿åœ¨ INT8 grid ä¸Šä¹Ÿèƒ½ä¿æŒæ›´é«˜çš„ä¸­é—´è®¡ç®—ç²¾åº¦

---

### å·®å¼‚ 3: SSM å®ç°æ–¹å¼

#### Mode 2-0: CUDA INT8 SSM
```python
# SSM å‡½æ•°: CUDA INT8 selective_scan
# ä½ç½®: csrc/selective_scan/
# ç‰¹ç‚¹:
# - ç¡¬ä»¶ä¼˜åŒ–çš„ CUDA kernel
# - ç›´æ¥å¤„ç† FP32 è¾“å…¥ (INT8 grid)
# - å†…éƒ¨é‡åŒ–/åé‡åŒ–ä¼˜åŒ–
# - ä½¿ç”¨ cuBLAS/cuDNN åŠ é€Ÿ
```

**ä»£ç è·¯å¾„** (æ¨æµ‹):
```cpp
// csrc/selective_scan/selective_scan_fwd_kernel.cu
// CUDA kernel ç›´æ¥å¤„ç† FP32 è¾“å…¥
__global__ void selective_scan_fwd_kernel(
    const float* u,     // FP32 è¾“å…¥ (INT8 grid)
    const float* delta,
    const float* A,
    const float* B,
    const float* C,
    float* out,
    const float* scales  // å„ç§ scale
) {
    // ç¡¬ä»¶ä¼˜åŒ–çš„è®¡ç®—
    // ç›´æ¥ä½¿ç”¨ FP32 è¿›è¡Œ SSM è®¡ç®—
}
```

#### Mode 2-1: PyTorch INT8 SSM
```python
# SSM å‡½æ•°: PyTorch INT8 selective_scan
# ä½ç½®: quamba/qSelectiveScan.py
# ç‰¹ç‚¹:
# - è½¯ä»¶å®ç° (Python/PyTorch)
# - æ¥æ”¶ INT8 è¾“å…¥ï¼Œå†…éƒ¨ dequant
# - å¯èƒ½å­˜åœ¨å¤šæ¬¡é‡åŒ–/åé‡åŒ–
# - CPU/GPU é€šç”¨å®ç°ï¼Œæ€§èƒ½å¯èƒ½ä¸å¦‚ CUDA
```

**ä»£ç è·¯å¾„**:
```python
# quamba/qSelectiveScan.py
class QSScan:
    def forward(self, u_int8, dt_int8, B_int8, C_int8, z_int8, ...):
        # ğŸ”´ å…³é”®ï¼å†…éƒ¨ dequant
        u_fp32 = u_int8.float() * self.u_scale  # INT8 â†’ FP32
        dt_fp32 = dt_int8.float() * self.dt_scale
        B_fp32 = B_int8.float() * self.B_scale
        C_fp32 = C_int8.float() * self.C_scale
        z_fp32 = z_int8.float() * self.z_scale

        # PyTorch è½¯ä»¶å®ç°çš„ selective scan
        y = self._selective_scan_pytorch(u_fp32, dt_fp32, B_fp32, C_fp32, z_fp32)
        return y
```

**æ€§èƒ½å·®å¼‚åŸå› **:
1. **å¤šæ¬¡ dequant å¼€é”€**: PyTorch å®ç°éœ€è¦å¯¹æ‰€æœ‰ 5 ä¸ªè¾“å…¥ (u, dt, B, C, z) åˆ†åˆ« dequant
2. **è½¯ä»¶ vs ç¡¬ä»¶**: PyTorch å®ç°æ— æ³•åˆ©ç”¨ CUDA kernel çš„ç¡¬ä»¶ä¼˜åŒ–
3. **æ•°å€¼ç²¾åº¦**: å¤šæ¬¡é‡åŒ–/åé‡åŒ–å¯èƒ½ç´¯ç§¯è¯¯å·®

---

### å·®å¼‚ 4: ç¯å¢ƒå˜é‡é…ç½®

#### Mode 2-0
```bash
FLOAT_SIM_ASIC_INT8=true         # å¯ç”¨ INT8 æµ®ç‚¹æ¨¡æ‹Ÿ
SSM_USE_CUDA_FOR_FP32=true       # å¼ºåˆ¶ä½¿ç”¨ CUDA INT8 SSM (å³ä½¿è¾“å…¥æ˜¯ FP32)
```

#### Mode 2-1
```bash
FLOAT_SIM_ASIC_INT8=true         # å¯ç”¨ INT8 æµ®ç‚¹æ¨¡æ‹Ÿ
SSM_USE_PYTORCH_INT8=true        # ä½¿ç”¨ PyTorch INT8 SSM
```

---

## ğŸ¯ é¢„æœŸ vs å®é™…å·®å¼‚åˆ†æ

### ç†è®ºé¢„æœŸ

Mode 2-1 å’Œ Mode 0 åº”è¯¥å®Œå…¨ç›¸åŒï¼Œå› ä¸ºï¼š

| æ¯”è¾ƒé¡¹ | Mode 0 (38.0%) | Mode 2-1 (36.0%) | ç†è®ºä¸Š |
|--------|----------------|------------------|--------|
| Conv1D è¾“å‡º | INT8 | INT8 | âœ… ç›¸åŒ |
| SSM è¾“å…¥ (u) | INT8 | INT8 | âœ… ç›¸åŒ |
| SSM å®ç° | CUDA INT8 | PyTorch INT8 | âš ï¸ **ä¸åŒ** |
| å…¶ä»–è¾“å…¥ (dt,B,C,z) | INT8 | INT8 | âœ… ç›¸åŒ |

**é—®é¢˜**: ä¸ºä»€ä¹ˆ Mode 0 ç”¨ CUDA INT8 SSM å¾—åˆ° 38%ï¼Œè€Œ Mode 2-1 ç”¨ PyTorch INT8 SSM åªæœ‰ 36%ï¼Ÿ

---

## ğŸ”¬ å¯èƒ½çš„æ€§èƒ½ä¸‹é™åŸå› 

### åŸå›  1: PyTorch INT8 SSM å®ç°é—®é¢˜ â­â­â­â­â­ (æœ€å¯èƒ½)

**å‡è®¾**: PyTorch INT8 SSM çš„è½¯ä»¶å®ç°åœ¨æ•°å€¼ç²¾åº¦ä¸Šä¸å¦‚ CUDA INT8 SSM

**è¯æ®**:
1. Mode 0 (CUDA INT8 SSM): **38.0%** âœ…
2. Mode 2-0 (CUDA INT8 SSM): **38.0%** âœ…
3. Mode 2-1 (PyTorch INT8 SSM): **36.0%** âŒ
4. Mode 2-2 (PyTorch FP32 SSM): **36.0%** âŒ

**ç»“è®º**: æ‰€æœ‰ä½¿ç”¨ PyTorch SSM (æ— è®º INT8 è¿˜æ˜¯ FP32) çš„æ¨¡å¼éƒ½æ˜¯ 36%ï¼Œè¯´æ˜ **PyTorch SSM å®ç°æœ¬èº«æœ‰é—®é¢˜**ï¼

**è°ƒè¯•å»ºè®®**:
```python
# åœ¨ quamba/qSelectiveScan.py ä¸­æ·»åŠ è°ƒè¯•è¾“å‡º
class QSScan:
    def forward(self, ...):
        # å¯¹æ¯” dequant åçš„å€¼
        u_fp32 = u_int8.float() * self.u_scale
        print(f"[DEBUG] u_int8 range: [{u_int8.min()}, {u_int8.max()}]")
        print(f"[DEBUG] u_scale: {self.u_scale}")
        print(f"[DEBUG] u_fp32 range: [{u_fp32.min():.4f}, {u_fp32.max():.4f}]")
        print(f"[DEBUG] u_fp32 mean: {u_fp32.mean():.4f}, std: {u_fp32.std():.4f}")
```

---

### åŸå›  2: Scale åº”ç”¨æ–¹å¼å·®å¼‚ â­â­â­â­

**å‡è®¾**: PyTorch INT8 SSM å†…éƒ¨çš„ dequant æ–¹å¼ä¸ CUDA INT8 SSM ä¸åŒ

#### CUDA INT8 SSM çš„ dequant (æ¨æµ‹)
```cpp
// å¯èƒ½åœ¨ SSM è®¡ç®—è¿‡ç¨‹ä¸­ç›´æ¥ä½¿ç”¨ INT8ï¼Œåªåœ¨å¿…è¦æ—¶ dequant
// ä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿçš„ INT8 ä¹˜æ³•å’Œç´¯åŠ 
__device__ float compute_ssm_element(
    int8_t u_int8,
    float u_scale,
    // ...
) {
    // å¯èƒ½ä¼˜åŒ–ï¼šå»¶è¿Ÿ dequant åˆ°æœ€å
    float result = (float)u_int8 * u_scale;  // ç¡¬ä»¶ä¼˜åŒ–çš„è½¬æ¢
    return result;
}
```

#### PyTorch INT8 SSM çš„ dequant (å®é™…)
```python
# ä¸€æ¬¡æ€§ dequant æ‰€æœ‰è¾“å…¥
u_fp32 = u_int8.float() * self.u_scale  # å¯èƒ½å¼•å…¥è¯¯å·®
# ç„¶åç”¨ FP32 è¿›è¡Œè®¡ç®—
y = self._selective_scan_pytorch(u_fp32, ...)
```

**é—®é¢˜**: PyTorch ä¸€æ¬¡æ€§ dequant å¯èƒ½åœ¨å¤§å¼ é‡ä¸Šå¼•å…¥ç´¯ç§¯è¯¯å·®

**è°ƒè¯•å»ºè®®**:
```python
# å¯¹æ¯” Mode 0 å’Œ Mode 2-1 çš„ SSM è¾“å…¥æ•°å€¼åˆ†å¸ƒ
# åœ¨ qMambaLayer.py ä¸­æ·»åŠ :
if self.ssm_mode == "0" or self.ssm_mode == "2-1":
    print(f"[{self.ssm_mode}] u before SSM: {u.shape}, dtype={u.dtype}")
    print(f"[{self.ssm_mode}] u range: [{u.min()}, {u.max()}]")
    print(f"[{self.ssm_mode}] u_scale: {self.mixer.selective_scan.u_scale}")
```

---

### åŸå›  3: SSM State é‡åŒ–å·®å¼‚ â­â­â­

**å‡è®¾**: CUDA å’Œ PyTorch å¯¹ SSM å†…éƒ¨ state çš„é‡åŒ–å¤„ç†ä¸åŒ

**`ssm_state_scale`** (Percentile) çš„ä½¿ç”¨æ–¹å¼å¯èƒ½ä¸åŒï¼š

#### CUDA INT8 SSM
```cpp
// SSM å†…éƒ¨ state é‡åŒ– (ç¡¬ä»¶ä¼˜åŒ–)
__device__ void update_ssm_state(
    float* state,
    int8_t* state_quantized,
    float state_scale
) {
    // ç›´æ¥åœ¨ INT8 ä¸Šè¿›è¡Œ state æ›´æ–°
    // ç¡¬ä»¶ä¼˜åŒ–çš„é‡åŒ–/åé‡åŒ–
}
```

#### PyTorch INT8 SSM
```python
# SSM å†…éƒ¨ state é‡åŒ– (è½¯ä»¶å®ç°)
def update_state(self, state_fp32, state_scale):
    # å¯èƒ½å¤šæ¬¡é‡åŒ–/åé‡åŒ–
    state_int8 = torch.round(state_fp32 / state_scale).to(torch.int8)
    state_fp32_dequant = state_int8.float() * state_scale
    # è¯¯å·®ç´¯ç§¯ï¼
    return state_fp32_dequant
```

---

### åŸå›  4: æµ®ç‚¹è¿ç®—é¡ºåºå·®å¼‚ â­â­

**å‡è®¾**: CUDA å’Œ PyTorch çš„æµ®ç‚¹è¿ç®—é¡ºåºä¸åŒï¼Œå¯¼è‡´æ•°å€¼è¯¯å·®

**IEEE 754 æµ®ç‚¹æ ‡å‡†**: `(a * b) * c â‰  a * (b * c)`

#### CUDA å®ç°
```cpp
// å¯èƒ½ä¼˜åŒ–çš„è¿ç®—é¡ºåº
float result = fma(u_int8, u_scale, bias);  // fused multiply-add
```

#### PyTorch å®ç°
```python
# æ ‡å‡†çš„è¿ç®—é¡ºåº
result = u_int8.float() * u_scale + bias  # åˆ†å¼€è®¡ç®—
```

---

## ğŸ› ï¸ è°ƒè¯•æ­¥éª¤å»ºè®®

### Step 1: éªŒè¯ PyTorch SSM æ˜¯é—®é¢˜æ ¹æº

**ç›®æ ‡**: ç¡®è®¤ PyTorch SSM (æ— è®º INT8/FP32) éƒ½æ¯” CUDA SSM å·®

**æ–¹æ³•**:
```bash
# è¿è¡Œå¯¹æ¯”å®éªŒ
python main.py --model quamba-130m-w8a8 --tasks lambada_openai --num_fewshot 0 \
  --limit 100 --ssm_mode 0    # CUDA INT8 SSM â†’ 38%

python main.py --model quamba-130m-w8a8 --tasks lambada_openai --num_fewshot 0 \
  --limit 100 --ssm_mode 2-1  # PyTorch INT8 SSM â†’ 36%

python main.py --model quamba-130m-w8a8 --tasks lambada_openai --num_fewshot 0 \
  --limit 100 --ssm_mode 2-2  # PyTorch FP32 SSM â†’ 36%
```

**é¢„æœŸç»“æœ**: å¦‚æœ Mode 2-2 ä¹Ÿæ˜¯ 36%ï¼Œåˆ™è¯æ˜ PyTorch SSM å®ç°æœ‰é—®é¢˜

---

### Step 2: å¯¹æ¯” SSM è¾“å…¥æ•°å€¼

**ç›®æ ‡**: æ£€æŸ¥ Mode 0 å’Œ Mode 2-1 ä¼ å…¥ SSM çš„æ•°æ®æ˜¯å¦ä¸€è‡´

**ä»£ç ä¿®æ”¹**: åœ¨ `quamba/qMambaLayer.py` æ·»åŠ æ—¥å¿—

```python
# åœ¨ forward() æ–¹æ³•ä¸­ï¼ŒSSM è°ƒç”¨å‰
if self.ssm_mode in ["0", "2-1"]:
    import torch
    print(f"\n{'='*80}")
    print(f"[Mode {self.ssm_mode}] SSM Input Debug")
    print(f"{'='*80}")
    print(f"u: shape={u.shape}, dtype={u.dtype}")
    print(f"   range=[{u.min().item():.6f}, {u.max().item():.6f}]")
    print(f"   mean={u.mean().item():.6f}, std={u.std().item():.6f}")
    print(f"   u_scale={self.mixer.selective_scan.u_scale:.6f}")

    # å¦‚æœæ˜¯ INT8ï¼Œæ˜¾ç¤º dequant åçš„å€¼
    if u.dtype == torch.int8:
        u_dequant = u.float() * self.mixer.selective_scan.u_scale
        print(f"   u_dequant range=[{u_dequant.min().item():.6f}, {u_dequant.max().item():.6f}]")
        print(f"   u_dequant mean={u_dequant.mean().item():.6f}, std={u_dequant.std().item():.6f}")
```

**é¢„æœŸç»“æœ**: Mode 0 å’Œ Mode 2-1 çš„ `u` åº”è¯¥å®Œå…¨ç›¸åŒï¼ˆéƒ½æ˜¯ INT8ï¼‰

---

### Step 3: å¯¹æ¯” SSM å†…éƒ¨ dequant å®ç°

**ç›®æ ‡**: æ£€æŸ¥ CUDA å’Œ PyTorch SSM çš„ dequant ä»£ç æ˜¯å¦ä¸€è‡´

**æ–‡ä»¶ä½ç½®**:
- CUDA: `csrc/selective_scan/selective_scan_fwd.cu`
- PyTorch: `quamba/qSelectiveScan.py`

**æ£€æŸ¥é¡¹**:
1. **Dequant å…¬å¼**: æ˜¯å¦éƒ½æ˜¯ `x_fp32 = x_int8.float() * scale`ï¼Ÿ
2. **Scale é¡ºåº**: æ˜¯å¦å…ˆä¹˜ `u_scale`ï¼Œè¿˜æ˜¯å…ˆè®¡ç®—å†ä¹˜ï¼Ÿ
3. **Clipping**: æ˜¯å¦æœ‰ `clamp(-127, 127)` æˆ–å…¶ä»–è£å‰ªï¼Ÿ
4. **Dtype è½¬æ¢**: `float()` çš„å®ç°æ˜¯å¦ä¸€è‡´ï¼Ÿ

---

### Step 4: å¯¹æ¯” SSM è¾“å‡º

**ç›®æ ‡**: æ£€æŸ¥ SSM è¾“å‡º `y` æ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚

**ä»£ç ä¿®æ”¹**: åœ¨ SSM è°ƒç”¨åæ·»åŠ æ—¥å¿—

```python
# åœ¨ SSM è°ƒç”¨å
y = self.mixer.selective_scan(u, dt, B, C, z, ...)

if self.ssm_mode in ["0", "2-1"]:
    print(f"\n[Mode {self.ssm_mode}] SSM Output Debug")
    print(f"y: shape={y.shape}, dtype={y.dtype}")
    print(f"   range=[{y.min().item():.6f}, {y.max().item():.6f}]")
    print(f"   mean={y.mean().item():.6f}, std={y.std().item():.6f}")

    # è®¡ç®—å·®å¼‚ (å¦‚æœæœ‰å‚è€ƒ)
    if hasattr(self, 'y_ref'):
        diff = (y - self.y_ref).abs()
        print(f"   diff from ref: max={diff.max().item():.6f}, mean={diff.mean().item():.6f}")
```

---

### Step 5: é€å±‚å¯¹æ¯” SSM è®¡ç®—

**ç›®æ ‡**: æ‰¾å‡º PyTorch SSM åœ¨å“ªä¸€æ­¥å¼•å…¥è¯¯å·®

**æ–¹æ³•**: åœ¨ PyTorch SSM å®ç°ä¸­æ·»åŠ è¯¦ç»†æ—¥å¿—

```python
# quamba/qSelectiveScan.py
class QSScan:
    def forward(self, u, dt, B, C, z, ...):
        # Step 1: Dequant
        u_fp32 = u.float() * self.u_scale
        dt_fp32 = dt.float() * self.dt_scale
        # ... (å…¶ä»– dequant)

        print(f"[PyTorch SSM] After dequant:")
        print(f"  u_fp32: range=[{u_fp32.min():.4f}, {u_fp32.max():.4f}]")

        # Step 2: SSM æ ¸å¿ƒè®¡ç®—
        # ... (selective scan ç®—æ³•)

        print(f"[PyTorch SSM] After SSM core:")
        print(f"  y: range=[{y.min():.4f}, {y.max():.4f}]")

        return y
```

---

## ğŸ“‹ è°ƒè¯•ä¼˜å…ˆçº§

### ğŸ”¥ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³æ‰§è¡Œï¼‰

1. **éªŒè¯ PyTorch SSM å‡è®¾**: è¿è¡Œ Mode 0 vs Mode 2-1 vs Mode 2-2ï¼Œç¡®è®¤ PyTorch SSM æ˜¯é—®é¢˜æ ¹æº
2. **å¯¹æ¯” SSM è¾“å…¥**: ç¡®ä¿ Mode 0 å’Œ Mode 2-1 ä¼ å…¥ SSM çš„æ•°æ®å®Œå…¨ä¸€è‡´
3. **æ£€æŸ¥ dequant å®ç°**: å¯¹æ¯” CUDA å’Œ PyTorch çš„ dequant ä»£ç 

### âš ï¸ ä¸­ä¼˜å…ˆçº§ï¼ˆé—®é¢˜æ˜ç¡®åï¼‰

4. **å¯¹æ¯” SSM State é‡åŒ–**: æ£€æŸ¥ `ssm_state_scale` çš„ä½¿ç”¨æ–¹å¼
5. **é€å±‚å¯¹æ¯” SSM è®¡ç®—**: æ‰¾å‡º PyTorch SSM çš„å…·ä½“è¯¯å·®æ¥æº

### ğŸ’¡ ä½ä¼˜å…ˆçº§ï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰

6. **æµ®ç‚¹è¿ç®—é¡ºåº**: æ£€æŸ¥ FMA ç­‰ä¼˜åŒ–æ˜¯å¦å½±å“ç»“æœ
7. **ç¡¬ä»¶å·®å¼‚**: æ£€æŸ¥ CUDA vs PyTorch çš„ç¡¬ä»¶åŠ é€Ÿå·®å¼‚

---

## ğŸ¯ é¢„æœŸè°ƒè¯•ç»“æœ

**æœ€å¯èƒ½çš„åŸå› **: PyTorch INT8 SSM çš„è½¯ä»¶å®ç°åœ¨æ•°å€¼ç²¾åº¦ä¸Šä¸å¦‚ CUDA INT8 SSM

**è¯æ®æ”¯æŒ**:
- Mode 0 (CUDA INT8): 38% âœ…
- Mode 2-0 (CUDA INT8): 38% âœ…
- Mode 2-1 (PyTorch INT8): 36% âŒ
- Mode 2-2 (PyTorch FP32): 36% âŒ

**ç»“è®º**: PyTorch SSM (æ— è®º INT8/FP32) éƒ½æ¯” CUDA SSM å·® **2%**

**å»ºè®®**:
1. ä¼˜åŒ– PyTorch SSM å®ç°ï¼Œä½¿å…¶æ•°å€¼ç²¾åº¦æ¥è¿‘ CUDA å®ç°
2. æˆ–è€…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ Mode 0 æˆ– Mode 2-0 (CUDA SSM)
3. å¦‚æœå¿…é¡»ä½¿ç”¨ PyTorch SSMï¼Œè€ƒè™‘æé«˜ SSM å†…éƒ¨çš„è®¡ç®—ç²¾åº¦ï¼ˆä¾‹å¦‚ä½¿ç”¨ FP64ï¼‰

---

## ğŸ“Œ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… **è¿è¡Œå¯¹æ¯”å®éªŒ**: ç¡®è®¤ Mode 0/2-1/2-2 çš„å‡†ç¡®ç‡
2. âœ… **æ·»åŠ è°ƒè¯•æ—¥å¿—**: åœ¨ qMambaLayer.py å’Œ qSelectiveScan.py ä¸­æ·»åŠ æ—¥å¿—
3. âœ… **å¯¹æ¯”æ•°å€¼åˆ†å¸ƒ**: æ£€æŸ¥ SSM è¾“å…¥/è¾“å‡ºçš„æ•°å€¼åˆ†å¸ƒå·®å¼‚
4. âœ… **æ£€æŸ¥ dequant å®ç°**: å¯¹æ¯” CUDA å’Œ PyTorch çš„ dequant ä»£ç 
5. âœ… **å®šä½è¯¯å·®æ¥æº**: æ‰¾å‡º PyTorch SSM çš„å…·ä½“é—®é¢˜æ‰€åœ¨
6. âœ… **ä¿®å¤æˆ–è§„é¿**: ä¿®å¤ PyTorch SSM å®ç°ï¼Œæˆ–åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ CUDA SSM

---

## ğŸ”‘ å…³é”®æ–‡ä»¶ä½ç½®

| æ–‡ä»¶ | ä½œç”¨ | å…³é”®ä»£ç ä½ç½® |
|------|------|-------------|
| `quamba/qMambaLayer.py` | Mode é€‰æ‹©å’Œæ•°æ®åˆ†å‰ | Line 751 (x_for_xproj)<br>Line 757 (Mode 2-1 ä¿æŒINT8)<br>Line 760 (Mode 2-0 Dequant) |
| `quamba/qSelectiveScan.py` | PyTorch INT8 SSM å®ç° | `forward()` æ–¹æ³•çš„ dequant é€»è¾‘ |
| `csrc/selective_scan/` | CUDA INT8 SSM å®ç° | CUDA kernel çš„ dequant å’Œè®¡ç®—é€»è¾‘ |
| `quamba/qConvLayer.py` | Conv1D å®ç° | Line 116-122 (CUDA INT8)<br>Line 157 (Mode 2-0/2-1 è°ƒç”¨) |

---

**æ€»ç»“**: Mode 2-1 çš„æ€§èƒ½ä¸‹é™ (36% vs é¢„æœŸ 38%) æœ€å¯èƒ½æ˜¯ç”±äº **PyTorch INT8 SSM çš„è½¯ä»¶å®ç°** åœ¨æ•°å€¼ç²¾åº¦ä¸Šä¸å¦‚ CUDA INT8 SSMã€‚å»ºè®®ä¼˜å…ˆè°ƒè¯• PyTorch SSM çš„ dequant å®ç°å’Œ SSM æ ¸å¿ƒè®¡ç®—é€»è¾‘ã€‚
