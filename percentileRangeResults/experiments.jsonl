{"timestamp": "2025-11-10 16:04:55", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --eval_zero_shot --task_list lambada_openai --testing --log_dir allmodeComparison/mode1", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.43, "perplexity": 22.888028791384134}, "activation_data_file": null}
{"timestamp": "2025-11-23 20:28:29", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3876261711120605, "range": 2.3876261711120605}, "after_percentile": {"min": 0.0, "max": 2.232022762298584, "range": 2.232022762298584}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06517075859534692}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6910884380340576, "range": 1.6910884380340576}, "after_percentile": {"min": 0.0, "max": 0.43851131200790405, "range": 0.43851131200790405}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7406928566564579}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.854201793670654, "range": 4.854201793670654}, "after_percentile": {"min": 0.0, "max": 1.3980681896209717, "range": 1.3980681896209717}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7119880365410645}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23891015350818634, "range": 0.23891015350818634}, "after_percentile": {"min": 0.0, "max": 0.1317008137702942, "range": 0.1317008137702942}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.44874333787667414}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.855637550354004, "range": 7.855637550354004}, "after_percentile": {"min": 0.0, "max": 2.569431781768799, "range": 2.569431781768799}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6729187458944041}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3465976417064667, "range": 0.3465976417064667}, "after_percentile": {"min": 0.0, "max": 0.1454925239086151, "range": 0.1454925239086151}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5802264458803426}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.39, "perplexity": 31.77814173201574}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_203056.npz"}
{"timestamp": "2025-11-23 20:33:25", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-1", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3876261711120605, "range": 2.3876261711120605}, "after_percentile": {"min": 0.0, "max": 2.232022762298584, "range": 2.232022762298584}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06517075859534692}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6910884380340576, "range": 1.6910884380340576}, "after_percentile": {"min": 0.0, "max": 0.4385119378566742, "range": 0.4385119378566742}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7406924865700946}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.85420036315918, "range": 4.85420036315918}, "after_percentile": {"min": 0.0, "max": 1.3981025218963623, "range": 1.3981025218963623}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7119808789708758}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23891201615333557, "range": 0.23891201615333557}, "after_percentile": {"min": 0.0, "max": 0.1317029744386673, "range": 0.1317029744386673}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.448738591891756}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.855668067932129, "range": 7.855668067932129}, "after_percentile": {"min": 0.0, "max": 2.56943941116333, "range": 2.56943941116333}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6729190453384709}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.34660395979881287, "range": 0.34660395979881287}, "after_percentile": {"min": 0.0, "max": 0.14549435675144196, "range": 0.14549435675144196}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5802288097461595}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.37, "perplexity": 30.154667536225265}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_203622.npz"}
{"timestamp": "2025-11-23 20:41:43", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3876261711120605, "range": 2.3876261711120605}, "after_percentile": {"min": 0.0, "max": 2.232022762298584, "range": 2.232022762298584}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06517075859534692}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6910914182662964, "range": 1.6910914182662964}, "after_percentile": {"min": 0.0, "max": 0.4385112524032593, "range": 0.4385112524032593}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7406933488830425}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.854089260101318, "range": 4.854089260101318}, "after_percentile": {"min": 0.0, "max": 1.3980739116668701, "range": 1.3980739116668701}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7119801806780767}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23891113698482513, "range": 0.23891113698482513}, "after_percentile": {"min": 0.0, "max": 0.13170401751995087, "range": 0.13170401751995087}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.44873219732608666}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.8553314208984375, "range": 7.8553314208984375}, "after_percentile": {"min": 0.0, "max": 2.5694222450256348, "range": 2.5694222450256348}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6729072132857556}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.34658920764923096, "range": 0.34658920764923096}, "after_percentile": {"min": 0.0, "max": 0.14549413323402405, "range": 0.14549413323402405}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5802115876000593}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.37, "perplexity": 30.65065749207311}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_204407.npz"}
{"timestamp": "2025-11-23 20:53:51", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3876261711120605, "range": 2.3876261711120605}, "after_percentile": {"min": 0.0, "max": 2.232022762298584, "range": 2.232022762298584}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06517075859534692}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6910914182662964, "range": 1.6910914182662964}, "after_percentile": {"min": 0.0, "max": 0.4385112524032593, "range": 0.4385112524032593}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7406933488830425}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.854089260101318, "range": 4.854089260101318}, "after_percentile": {"min": 0.0, "max": 1.3980739116668701, "range": 1.3980739116668701}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7119801806780767}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23891113698482513, "range": 0.23891113698482513}, "after_percentile": {"min": 0.0, "max": 0.13170401751995087, "range": 0.13170401751995087}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.44873219732608666}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.8553314208984375, "range": 7.8553314208984375}, "after_percentile": {"min": 0.0, "max": 2.5694222450256348, "range": 2.5694222450256348}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6729072132857556}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.34658920764923096, "range": 0.34658920764923096}, "after_percentile": {"min": 0.0, "max": 0.14549413323402405, "range": 0.14549413323402405}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5802115876000593}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.38, "perplexity": 30.657692385704973}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_205613.npz"}
{"timestamp": "2025-11-23 21:37:37", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6888459920883179, "range": 1.6888459920883179}, "after_percentile": {"min": 0.0, "max": 0.4402778148651123, "range": 0.4402778148651123}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393025670027537}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871548652648926, "range": 4.871548652648926}, "after_percentile": {"min": 0.0, "max": 1.4039891958236694, "range": 1.4039891958236694}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7117981783759372}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23117665946483612, "range": 0.23117665946483612}, "after_percentile": {"min": 0.0, "max": 0.13123326003551483, "range": 0.13123326003551483}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.43232478426103177}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700758457183838, "range": 7.700758457183838}, "after_percentile": {"min": 0.0, "max": 2.5652616024017334, "range": 2.5652616024017334}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668819549834514}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521742820739746, "range": 0.3521742820739746}, "after_percentile": {"min": 0.0, "max": 0.14704366028308868, "range": 0.14704366028308868}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824690564650544}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.4, "perplexity": 27.645396673368637}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_214008.npz"}
{"timestamp": "2025-11-23 21:54:24", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.688847541809082, "range": 1.688847541809082}, "after_percentile": {"min": 0.0, "max": 0.440277099609375, "range": 0.440277099609375}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393032297410617}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871530532836914, "range": 4.871530532836914}, "after_percentile": {"min": 0.0, "max": 1.4039586782455444, "range": 1.4039586782455444}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7118033708745011}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23118481040000916, "range": 0.23118481040000916}, "after_percentile": {"min": 0.0, "max": 0.1312333047389984, "range": 0.1312333047389984}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.43234460554769555}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.7005414962768555, "range": 7.7005414962768555}, "after_percentile": {"min": 0.0, "max": 2.565246343612671, "range": 2.565246343612671}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668745509841165}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521803021430969, "range": 0.3521803021430969}, "after_percentile": {"min": 0.0, "max": 0.1470448076725006, "range": 0.1470448076725006}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824729356590939}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.37, "perplexity": 26.155195502553426}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_215657.npz"}
{"timestamp": "2025-11-23 22:03:03", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 2-0", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.688847541809082, "range": 1.688847541809082}, "after_percentile": {"min": 0.0, "max": 0.440277099609375, "range": 0.440277099609375}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393032297410617}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871530532836914, "range": 4.871530532836914}, "after_percentile": {"min": 0.0, "max": 1.4039586782455444, "range": 1.4039586782455444}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7118033708745011}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23118573427200317, "range": 0.23118573427200317}, "after_percentile": {"min": 0.0, "max": 0.13123363256454468, "range": 0.13123363256454468}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.4323454560126931}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700627326965332, "range": 7.700627326965332}, "after_percentile": {"min": 0.0, "max": 2.565246105194092, "range": 2.565246105194092}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668782949395103}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521832227706909, "range": 0.3521832227706909}, "after_percentile": {"min": 0.0, "max": 0.14704671502113342, "range": 0.14704671502113342}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824709823929444}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.36, "perplexity": 28.118659936833605}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251123_220534.npz"}
{"timestamp": "2025-11-24 01:33:11", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6888459920883179, "range": 1.6888459920883179}, "after_percentile": {"min": 0.0, "max": 0.4402778148651123, "range": 0.4402778148651123}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393025670027537}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871548652648926, "range": 4.871548652648926}, "after_percentile": {"min": 0.0, "max": 1.4039891958236694, "range": 1.4039891958236694}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7117981783759372}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23117521405220032, "range": 0.23117521405220032}, "after_percentile": {"min": 0.0, "max": 0.1312336027622223, "range": 0.1312336027622223}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.4323197523563698}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700774192810059, "range": 7.700774192810059}, "after_percentile": {"min": 0.0, "max": 2.565261125564575, "range": 2.565261125564575}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668826975916695}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.35217714309692383, "range": 0.35217714309692383}, "after_percentile": {"min": 0.0, "max": 0.14704841375350952, "range": 0.14704841375350952}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824589510255643}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.39, "perplexity": 27.315447716471272}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251124_013538.npz"}
{"timestamp": "2025-11-24 02:06:58", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 4", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.688847541809082, "range": 1.688847541809082}, "after_percentile": {"min": 0.0, "max": 0.440277099609375, "range": 0.440277099609375}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393032297410617}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871530532836914, "range": 4.871530532836914}, "after_percentile": {"min": 0.0, "max": 1.4039586782455444, "range": 1.4039586782455444}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7118033708745011}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23118573427200317, "range": 0.23118573427200317}, "after_percentile": {"min": 0.0, "max": 0.13123363256454468, "range": 0.13123363256454468}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.4323454560126931}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700627326965332, "range": 7.700627326965332}, "after_percentile": {"min": 0.0, "max": 2.565246105194092, "range": 2.565246105194092}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668782949395103}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521832227706909, "range": 0.3521832227706909}, "after_percentile": {"min": 0.0, "max": 0.14704671502113342, "range": 0.14704671502113342}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824709823929444}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.37, "perplexity": 30.222492314033587}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251124_020955.npz"}
{"timestamp": "2025-11-24 02:14:54", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --testing --mode 4", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6888461112976074, "range": 1.6888461112976074}, "after_percentile": {"min": 0.0, "max": 0.440276563167572, "range": 0.440276563167572}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393033265598782}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871501922607422, "range": 4.871501922607422}, "after_percentile": {"min": 0.0, "max": 1.4039838314056396, "range": 1.4039838314056396}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7117965149741393}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.2311713844537735, "range": 0.2311713844537735}, "after_percentile": {"min": 0.0, "max": 0.13123352825641632, "range": 0.13123352825641632}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.4323106704296326}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700878143310547, "range": 7.700878143310547}, "after_percentile": {"min": 0.0, "max": 2.5652658939361572, "range": 2.5652658939361572}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668865749856717}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521730899810791, "range": 0.3521730899810791}, "after_percentile": {"min": 0.0, "max": 0.14704781770706177, "range": 0.14704781770706177}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824558380796157}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.36, "perplexity": 26.715350953932102}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251124_021755.npz"}
{"timestamp": "2025-11-24 02:19:22", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --mode 4", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": null, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2300710678100586, "range": 2.2300710678100586}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.06285795583199245}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.688847541809082, "range": 1.688847541809082}, "after_percentile": {"min": 0.0, "max": 0.440277099609375, "range": 0.440277099609375}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7393032297410617}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871530532836914, "range": 4.871530532836914}, "after_percentile": {"min": 0.0, "max": 1.4039586782455444, "range": 1.4039586782455444}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.7118033708745011}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23118573427200317, "range": 0.23118573427200317}, "after_percentile": {"min": 0.0, "max": 0.13123363256454468, "range": 0.13123363256454468}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.4323454560126931}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700627326965332, "range": 7.700627326965332}, "after_percentile": {"min": 0.0, "max": 2.565246105194092, "range": 2.565246105194092}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.6668782949395103}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.3521832227706909, "range": 0.3521832227706909}, "after_percentile": {"min": 0.0, "max": 0.14704671502113342, "range": 0.14704671502113342}, "percentile_alpha": 0.9995, "clipped_ratio": 0.0004999999999999449, "range_reduction": 0.5824709823929444}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.4020958664855424, "perplexity": 20.840628654960664}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_paNone_20251124_025315.npz"}
{"timestamp": "2025-11-24 08:56:07", "command": "main.py pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m --quantize --eval_zero_shot --task_list lambada_openai --mode 4 --percentile_alpha 0.9999 --log_dir logs", "config": {"model": "pretrained_models/mambaOriginalHuggingfaceDownload/mamba-130m", "w_bits": 8, "a_bits": 8, "percentile_alpha": 0.9999, "group_heads": false, "apply_gptq": false, "quantize_embedding": false, "quantize_lm_head": false, "calib_data_num": 512, "calib_seqlen": 512}, "activation_stats": {"layer_0.x_proj:input": {"before_percentile": {"min": 0.0, "max": 2.3796510696411133, "range": 2.3796510696411133}, "after_percentile": {"min": 0.0, "max": 2.2535266876220703, "range": 2.2535266876220703}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.053001208298183146}, "layer_0.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 1.6888461112976074, "range": 1.6888461112976074}, "after_percentile": {"min": 0.0, "max": 0.830359160900116, "range": 0.830359160900116}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.5083275170275177}, "layer_1.x_proj:input": {"before_percentile": {"min": 0.0, "max": 4.871501922607422, "range": 4.871501922607422}, "after_percentile": {"min": 0.0, "max": 2.5750675201416016, "range": 2.5750675201416016}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.4714017235236309}, "layer_1.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.23117223381996155, "range": 0.23117223381996155}, "after_percentile": {"min": 0.0, "max": 0.17500056326389313, "range": 0.17500056326389313}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.24298623423700308}, "layer_2.x_proj:input": {"before_percentile": {"min": 0.0, "max": 7.700843334197998, "range": 7.700843334197998}, "after_percentile": {"min": 0.0, "max": 3.0123424530029297, "range": 3.0123424530029297}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.6088295369384178}, "layer_2.ssm_state_act:input": {"before_percentile": {"min": 0.0, "max": 0.35217171907424927, "range": 0.35217171907424927}, "after_percentile": {"min": 0.0, "max": 0.22643154859542847, "range": 0.22643154859542847}, "percentile_alpha": 0.9999, "clipped_ratio": 9.999999999998899e-05, "range_reduction": 0.3570422145462245}}, "reorder_summary": {"enabled": false, "avg_range_reduction": null, "total_layers": 0}, "results": {"accuracy": 0.43178730836405976, "perplexity": 18.639914093086407}, "activation_data_file": "percentileRangeResults/activations_mamba-130m_pa0.9999_20251124_092900.npz"}
