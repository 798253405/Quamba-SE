# æ‰€æœ‰æ¨¡å¼æµ‹è¯•ç»“æœåˆ†æ

## ğŸ“Š æµ‹è¯•é…ç½®
- **æ¨¡å‹**: quamba-130m-w8a8
- **é¢„è®­ç»ƒæƒé‡**: pretrained_models/testPercentileRange/default
- **ä»»åŠ¡**: lambada_openai (zero-shot)
- **æµ‹è¯•æ¨¡å¼**: --testing (100 samples)

---

## ğŸ¯ ç»“æœæ€»è§ˆ

| æ’å | Mode | Accuracy (%) | Perplexity | Conv1Dè¾“å‡º | SSMå®ç° |
|------|------|--------------|------------|-----------|---------|
| ğŸ¥‡ 1 | **Mode 2-0** | **38.00%** | 29.9138 | FP32 (INT8 grid) | CUDA INT8 (requant) |
| ğŸ¥‡ 1 | **Mode 3** | **38.00%** | 29.0754 | FP32 (TRUE) | PyTorch FP32 |
| ğŸ¥ˆ 3 | Mode 2-1 | 36.00% | 29.0117 | INT8 | PyTorch INT8 |
| ğŸ¥ˆ 3 | Mode 2-2 | 36.00% | 30.5710 | FP32 (INT8 grid) | PyTorch FP32 |
| ğŸ¥ˆ 3 | Mode 2-3 | 36.00% | 29.0117 | FP32 (TRUE) | PyTorch INT8 (requant) |
| ğŸ¥‰ 6 | Mode 2-4 | 34.00% | 27.2117 | FP32 (TRUE) | PyTorch FP32 |
| 7 | Mode 1 | 33.00% | 29.0602 | FP32 (TRUE) | PyTorch FP32 |

---

## ğŸ” å…³é”®å‘ç°

### 1. **Mode 2-0 å’Œ Mode 3 è¡¨ç°æœ€ä½³ (38.00%)**

**Mode 2-0**: CUDA INT8 + Requantization
- Conv1D: FP32 (INT8 grid)
- SSM: CUDA INT8 kernel (with requantization)
- **ä¼˜åŠ¿**: CUDA INT8 kernel ä¼˜åŒ–å¥½ï¼Œrequantization å¼€é”€å¯æ¥å—

**Mode 3**: FP32/FP16 Input + FP32 Conv/SSM + INT8 Linear (Hybrid Precision)
- Conv1D: TRUE FP32 (accepts FP32/FP16 input, dynamic quantization)
- SSM: PyTorch FP32
- Linear: INT8 é‡åŒ–
- **ä¼˜åŠ¿**: æ··åˆç²¾åº¦ç­–ç•¥ - FP32 ç”¨äºå…³é”®éƒ¨åˆ†ï¼ŒINT8 ç”¨äºLinearå±‚
- **Perplexityæœ€ä½ä¹‹ä¸€**: 29.0754ï¼ˆè¯´æ˜é¢„æµ‹è´¨é‡å¥½ï¼‰

### 2. **Mode 2-3 çš„ TRUE FP32 Conv1D æ²¡æœ‰å¸¦æ¥é¢„æœŸæå‡**

**é¢„æœŸ**: Mode 2-3 åº”è¯¥æ¯” Mode 2-1 æ›´å¥½ï¼ˆå› ä¸º Conv1D ä½¿ç”¨ TRUE FP32ï¼‰
**å®é™…**: Mode 2-3 = Mode 2-1 = 36.00%ï¼ˆå®Œå…¨ç›¸åŒï¼ï¼‰
**Perplexity**: å®Œå…¨ç›¸åŒ (29.0117)

**åˆ†æ**:
```
Mode 2-1: INT8 Conv1D â†’ PyTorch INT8 SSM
Mode 2-3: TRUE FP32 Conv1D â†’ requantize to INT8 â†’ PyTorch INT8 SSM
```

**å¯èƒ½åŸå› **:
1. âœ… **Requantization æŠµæ¶ˆäº† FP32 çš„ç²¾åº¦ä¼˜åŠ¿**: TRUE FP32 â†’ INT8 æ—¶ï¼Œç²¾åº¦æŸå¤±ç­‰åŒäºç›´æ¥ç”¨ INT8
2. âœ… **PyTorch INT8 SSM æ˜¯ç“¶é¢ˆ**: SSM çš„é‡åŒ–è¯¯å·®ä¸»å¯¼äº†æ•´ä½“è¯¯å·®
3. âš ï¸ **Scale mismatch é£é™©**: å¦‚æœ TRUE FP32 range ä¸åŒ¹é… calibrated output_scaleï¼Œrequantization ä¼šå¼•å…¥é¢å¤–è¯¯å·®

**ç»“è®º**: Mode 2-3 çš„è®¾è®¡å­˜åœ¨é—®é¢˜ - TRUE FP32 çš„ä¼˜åŠ¿åœ¨ requantization æ­¥éª¤è¢«å®Œå…¨æŠµæ¶ˆ

### 3. **Mode 2-4 è¡¨ç°æ„å¤–è¾ƒå·® (34.00%)**

**é¢„æœŸ**: Mode 2-4 åº”è¯¥æ˜¯ Mode 2-x ç³»åˆ—ä¸­æœ€å¥½çš„ï¼ˆå®Œå…¨ FP32 pipelineï¼‰
**å®é™…**: Mode 2-4 = 34.00%ï¼ˆä»…ä¼˜äº Mode 1ï¼‰

**åˆ†æ**:
```
Mode 2-4: TRUE FP32 Conv1D â†’ FP32 SSM (no requantization)
```

**å¯èƒ½åŸå› **:
1. âš ï¸ **FP32 SSM å®ç°é—®é¢˜**: PyTorch FP32 SSM (selective_scan_SE_float) å¯èƒ½å­˜åœ¨æ•°å€¼é—®é¢˜
2. âš ï¸ **Scale mismatch**: FP32 è¾“å‡ºå¯èƒ½ä¸åç»­å±‚æœŸæœ›çš„ scale ä¸åŒ¹é…
3. âš ï¸ **è¿‡æ‹Ÿåˆäº INT8 calibration**: æ¨¡å‹æƒé‡æ˜¯åŸºäº INT8 calibration çš„ï¼Œå®Œå…¨ FP32 åè€Œåç¦»äº†æ ¡å‡†ç‚¹

**Perplexity**: 27.2117ï¼ˆæœ€ä½ï¼ï¼‰ä½† accuracy ä¸é«˜
- è¯´æ˜ Mode 2-4 é¢„æµ‹æ›´"è‡ªä¿¡"ï¼Œä½†ä¸ä¸€å®šæ›´å‡†ç¡®

### 4. **Mode 1 (Pure FP32) è¡¨ç°æœ€å·® (33.00%)**

**åˆ†æ**:
- Mode 1 æ˜¯ç†è®ºä¸Šç•Œï¼Œä½†å®é™…è¡¨ç°æœ€å·®
- **åŸå› **: æ¨¡å‹æƒé‡æ˜¯ä¸º INT8 é‡åŒ–æ ¡å‡†çš„ï¼Œå®Œå…¨ FP32 åè€Œåç¦»äº†æœ€ä½³å·¥ä½œç‚¹
- **ç»“è®º**: è¿™ä¸ªæ¨¡å‹çš„æœ€ä½³æ€§èƒ½ç‚¹åœ¨é‡åŒ–é…ç½®ä¸‹ï¼Œè€Œéå®Œå…¨ FP32

### 5. **Mode 2-2 vs Mode 2-4: INT8 Grid vs TRUE FP32**

**Mode 2-2**: 36.00% (FP32 on INT8 grid â†’ PyTorch FP32 SSM)
**Mode 2-4**: 34.00% (TRUE FP32 â†’ PyTorch FP32 SSM)

**ç»“è®º**: INT8 grid çš„ç¦»æ•£åŒ–åè€Œæ›´å¥½ï¼
- **å¯èƒ½åŸå› **: INT8 grid çš„ç¦»æ•£åŒ–èµ·åˆ°äº†ç±»ä¼¼æ­£åˆ™åŒ–çš„ä½œç”¨
- **æˆ–è€…**: PyTorch FP32 SSM å¯¹ INT8 grid è¾“å…¥ä¼˜åŒ–æ›´å¥½

---

## ğŸ’¡ æ¨¡å¼å¯¹æ¯”æ·±å…¥åˆ†æ

### Conv1D è¾“å‡ºç²¾åº¦å½±å“

| Conv1Dè¾“å‡ºç±»å‹ | æ¨¡å¼ | å¹³å‡ Accuracy |
|---------------|------|---------------|
| **INT8** | Mode 2-1 | 36.00% |
| **FP32 (INT8 grid)** | Mode 2-0, Mode 2-2 | 37.00% |
| **FP32 (TRUE)** | Mode 2-3, Mode 2-4, Mode 3, Mode 1 | 35.25% |

**ç»“è®º**: FP32 (INT8 grid) è¡¨ç°æœ€å¥½ï¼ŒTRUE FP32 åè€Œä¸å¦‚é¢„æœŸ

### SSM å®ç°å½±å“

| SSMç±»å‹ | æ¨¡å¼ | å¹³å‡ Accuracy |
|---------|------|---------------|
| **CUDA INT8** | Mode 2-0 | 38.00% |
| **PyTorch INT8** | Mode 2-1, Mode 2-3 | 36.00% |
| **PyTorch FP32** | Mode 2-2, Mode 2-4, Mode 3, Mode 1 | 35.25% |

**ç»“è®º**: CUDA INT8 kernel è¡¨ç°æœ€å¥½ï¼ˆé«˜åº¦ä¼˜åŒ–ï¼‰ï¼ŒPyTorch å®ç°åè€Œä¸å¦‚

### Requantization å¼€é”€

| æ˜¯å¦ Requantization | æ¨¡å¼ | Accuracy |
|---------------------|------|----------|
| âœ… æœ‰ requant | Mode 2-0 | 38.00% |
| âœ… æœ‰ requant | Mode 2-3 | 36.00% |
| âŒ æ—  requant | Mode 2-1 | 36.00% |
| âŒ æ—  requant | Mode 2-2 | 36.00% |
| âŒ æ—  requant | Mode 2-4 | 34.00% |

**ç»“è®º**: Requantization ä¸æ˜¯ä¸»è¦ç“¶é¢ˆï¼ˆMode 2-0 æœ€å¥½ï¼ŒMode 2-3 ä¸æ—  requant ç›¸åŒï¼‰

---

## ğŸ¯ æ¨èç­–ç•¥

### 1. **ç”Ÿäº§ç¯å¢ƒæ¨è: Mode 2-0 æˆ– Mode 3**

**Mode 2-0** (38.00%):
```bash
FLOAT_SIM_ASIC_INT8=true SSM_USE_CUDA_FOR_FP32=true \
python3 main.py quamba-130m-w8a8 --quantize --float-sim-asic-int8 ...
```
- âœ… æœ€é«˜ accuracy (38.00%)
- âœ… CUDA INT8 kernel é«˜åº¦ä¼˜åŒ–
- âœ… Requantization å¼€é”€å¯æ¥å—

**Mode 3** (38.00%):
```bash
CONV1D_MODE3_FP32=true \
python3 main.py quamba-130m-w8a8 --quantize ...
```
- âœ… æœ€é«˜ accuracy (38.00%)
- âœ… æœ€ä½ perplexity (29.0754)
- âœ… Hybrid precision (FP32 Conv/SSM + INT8 Linear)
- âœ… æ¥å— FP32/FP16 è¾“å…¥ï¼ˆæ— éœ€é¢„é‡åŒ–ï¼‰
- âœ… çµæ´»æ€§æœ€é«˜

### 2. **Mode 2-3 çš„é—®é¢˜**

**ä¸æ¨èä½¿ç”¨ Mode 2-3**:
- âŒ TRUE FP32 ä¼˜åŠ¿è¢« requantization å®Œå…¨æŠµæ¶ˆ
- âŒ ä¸ Mode 2-1 (INT8 Conv1D) æ€§èƒ½å®Œå…¨ç›¸åŒ
- âŒ å¢åŠ äº†è®¡ç®—å¤æ‚åº¦ï¼Œä½†æ— æ€§èƒ½æå‡
- âš ï¸ Scale mismatch é£é™©

**å»ºè®®**:
- å¦‚æœéœ€è¦ PyTorch INT8 SSM: ç›´æ¥ç”¨ **Mode 2-1**ï¼ˆæ›´ç®€å•ï¼Œæ€§èƒ½ç›¸åŒï¼‰
- å¦‚æœéœ€è¦ TRUE FP32 Conv1D: ç”¨ **Mode 2-4** æˆ– **Mode 3**ï¼ˆé¿å… requantizationï¼‰

### 3. **Mode 2-4 çš„æ„å¤–ç»“æœ**

**Mode 2-4 (34.00%) è¡¨ç°ä¸å¦‚é¢„æœŸ**:
- âŒ å®Œå…¨ FP32 pipelineï¼Œä½† accuracy ä»… 34%
- âš ï¸ å¯èƒ½çš„åŸå› : PyTorch FP32 SSM æ•°å€¼é—®é¢˜ï¼Œæˆ–ä¸ INT8 calibration ä¸åŒ¹é…

**è°ƒè¯•å»ºè®®**:
1. æ£€æŸ¥ Mode 2-4 çš„ Layer 24 è¾“å‡º
2. å¯¹æ¯” Mode 2-4 vs Mode 3 çš„æ•°å€¼å·®å¼‚ï¼ˆä¸¤è€…éƒ½ç”¨ FP32 SSMï¼‰
3. åˆ†æä¸ºä»€ä¹ˆ Mode 3 (38%) æ¯” Mode 2-4 (34%) å¥½å¾ˆå¤š

---

## ğŸ”¬ éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥

### 1. **Mode 3 vs Mode 2-4 å·®å¼‚åˆ†æ**

ä¸¤è€…éƒ½ä½¿ç”¨ TRUE FP32 Conv1D + FP32 SSMï¼Œä½†ç»“æœç›¸å·® 4%ï¼š
```
Mode 3:   38.00% (FP32/FP16 input, dynamic quantization, INT8 Linear)
Mode 2-4: 34.00% (INT8 input, static calibration, INT8 Linear)
```

**å…³é”®åŒºåˆ«**:
- Mode 3 æ¥å— FP32/FP16 è¾“å…¥ + åŠ¨æ€é‡åŒ–
- Mode 2-4 æ¥å— INT8 è¾“å…¥ + é™æ€ calibration

**å¯èƒ½åŸå› **:
1. Mode 3 çš„åŠ¨æ€é‡åŒ–æ›´é€‚åº”è¾“å…¥åˆ†å¸ƒ
2. Mode 2-4 çš„é™æ€ scale ä¸ TRUE FP32 è¾“å‡ºä¸åŒ¹é…
3. è¾“å…¥ç²¾åº¦å¯¹æœ€ç»ˆç»“æœå½±å“å¾ˆå¤§

### 2. **Mode 2-3 Scale Validation æ£€æŸ¥**

æŸ¥çœ‹ Mode 2-3 çš„æ—¥å¿—ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ scale mismatch warning:
```bash
grep -i "scale" logs_all_modes/mode23/*.log
grep -i "mismatch" logs_all_modes/mode23/*.log
```

å¦‚æœæœ‰å¤§é‡ scale mismatchï¼Œè¯´æ˜ TRUE FP32 range ä¸åŒ¹é… calibrated output_scale

### 3. **Layer 24 è¾“å‡ºåˆ†æ**

æŸ¥çœ‹ Layer 24 çš„è¾“å‡ºï¼š
```bash
grep "Layer 24" logs_all_modes/mode*/quamba-130m-w8a8.log
```

å¯¹æ¯”ä¸åŒæ¨¡å¼çš„ Layer 24 output range, absmax, scales

---

## ğŸ“ æ€»ç»“

### âœ… æˆåŠŸå‘ç°

1. **Mode 2-0 å’Œ Mode 3 æ˜¯æœ€ä½³é€‰æ‹©** (38.00%)
2. **Mode 2-3 çš„ TRUE FP32 Conv1D æ²¡æœ‰ä»·å€¼** (requantization æŠµæ¶ˆäº†ä¼˜åŠ¿)
3. **Mode 1 (Pure FP32) ä¸æ˜¯æœ€ä¼˜** (æ¨¡å‹ä¸º INT8 æ ¡å‡†)
4. **CUDA INT8 kernel ä¼˜åŒ–éå¸¸å¥½** (Mode 2-0 æœ€ä½³)
5. **Hybrid precision (Mode 3) æ•ˆæœæœ€å¥½** (ç²¾åº¦ + æ•ˆç‡å¹³è¡¡)

### âš ï¸ æ„å¤–å‘ç°

1. **Mode 2-4 è¡¨ç°ä¸å¦‚é¢„æœŸ** (34% vs é¢„æœŸæ¥è¿‘ Mode 1)
2. **INT8 grid æ¯” TRUE FP32 æ›´å¥½** (Mode 2-2 > Mode 2-4)
3. **PyTorch FP32 SSM è¡¨ç°ä¸€èˆ¬** (ä¸å¦‚ CUDA INT8)

### ğŸ¯ æ¨èè¡ŒåŠ¨

1. âœ… **ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ Mode 3** (38%, æœ€çµæ´»ï¼Œhybrid precision)
2. âœ… **æˆ–ä½¿ç”¨ Mode 2-0** (38%, CUDA ä¼˜åŒ–æœ€å¥½)
3. âŒ **å¼ƒç”¨ Mode 2-3** (æ— ä¼˜åŠ¿ï¼Œå¢åŠ å¤æ‚åº¦)
4. ğŸ” **è°ƒæŸ¥ Mode 2-4 vs Mode 3 å·®å¼‚** (ä¸ºä»€ä¹ˆ Mode 3 å¥½ 4%ï¼Ÿ)
5. ğŸ” **æ£€æŸ¥ Mode 2-3 scale mismatch** (æ˜¯å¦æœ‰å¤§é‡ warningï¼Ÿ)

---

## ğŸš€ åç»­æµ‹è¯•å»ºè®®

### 1. å®Œæ•´è¯„ä¼°ï¼ˆé testing æ¨¡å¼ï¼‰

å½“å‰ç»“æœåŸºäº `--testing` (100 samples)ï¼Œéœ€è¦å®Œæ•´è¯„ä¼°ï¼š
```bash
# Mode 3 å®Œæ•´è¯„ä¼°
CONV1D_MODE3_FP32=true python3 main.py quamba-130m-w8a8 \
    --pretrained_dir pretrained_models/testPercentileRange/default \
    --quantize --eval_zero_shot --task_list lambada_openai \
    --log_dir logs_mode3_full

# Mode 2-0 å®Œæ•´è¯„ä¼°
FLOAT_SIM_ASIC_INT8=true SSM_USE_CUDA_FOR_FP32=true \
python3 main.py quamba-130m-w8a8 \
    --pretrained_dir pretrained_models/testPercentileRange/default \
    --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai \
    --log_dir logs_mode20_full
```

### 2. Layer 24 æ•°å€¼å¯¹æ¯”

å¯¹æ¯” Mode 2-3 vs Mode 2-4 vs Mode 3 çš„ Layer 24 è¾“å‡º

### 3. Scale Validation åˆ†æ

æ£€æŸ¥ Mode 2-3 çš„ scale validation æ—¥å¿—

---

**æµ‹è¯•æ—¶é—´**: 2025-11-10
**é…ç½®**: pretrained_models/testPercentileRange/default
**æ ·æœ¬æ•°**: 100 (testing mode)
