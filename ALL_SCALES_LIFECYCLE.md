# æ‰€æœ‰ Scale çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸåˆ†æ

## æ¦‚è§ˆï¼š7 ä¸ªä¸»è¦ Scale

| Scale åç§° | Observer ç±»å‹ | ç”¨é€” | SSM ä½¿ç”¨ |
|-----------|--------------|------|----------|
| `x_proj:input` | âœ… Percentile | Conv1Dè¾“å‡ºâ†’x_projè¾“å…¥ | âœ… u_scale |
| `ssm_state_act:input` | âœ… Percentile | SSMå†…éƒ¨stateé‡åŒ– | âœ… ssm_state_scale |
| `in_proj:input` | âŒ MinMax | in_projè¾“å…¥ | âŒ ä¸ç›´æ¥ç”¨äºSSM |
| `in_proj:output` | âŒ MinMax | in_projè¾“å‡ºâ†’Conv1Dè¾“å…¥ | âœ… z_scale |
| `x_proj:output` | âŒ MinMax | x_projè¾“å‡ºâ†’dt_projè¾“å…¥ | âœ… B_scale, C_scale |
| `dt_proj:output` | âŒ MinMax | dt_projè¾“å‡º | âœ… dt_scale |
| `out_proj:input` | âŒ MinMax | SSMè¾“å‡ºâ†’out_projè¾“å…¥ | âŒ ä¸ç›´æ¥ç”¨äºSSM |

---

## 1ï¸âƒ£ `x_proj:input` (Conv1D output_scale / u_scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:163-169):
```python
if is_x(op) or is_ssm_state(op):  # is_x = lambda op: op == "x_proj"
    observers[i]["x_proj:input"] = PerTensorPercentileObserver(
        n_bits=8,
        percentile_alpha=0.9995  # è£å‰ª0.05% outliers
    )
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
# Hook åœ¨ x_proj å±‚çš„ forward æ—¶è§¦å‘
def stat_hook(m, inputs, outputs, op="x_proj", block_idx=i):
    observers[block_idx]["x_proj:input"].update(inputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ Conv1D+SiLU è¾“å‡ºï¼ˆINT8ï¼‰ï¼Œå³å°†è¾“å…¥ x_proj
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
# å†…éƒ¨è°ƒç”¨ observer.py:92-110:
#   cur_max = torch.quantile(w.abs().reshape(-1), 0.9995)
#   scale = cur_max / 127
act_scales[i]["x_proj:input"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° Conv1D** (qMambaLayer.py:603-606):
```python
qmixer.conv1d = QCausalConv1D.from_fp16(
    output_scale=act_scales["x_proj:input"].item(),  # â† å­˜å‚¨ä¸º self.output_scale
)
```

**èµ‹å€¼åˆ° x_proj** (qMambaLayer.py:610-614):
```python
qmixer.x_proj = W4A8B8O8Linear.from_fp16(
    input_scale=act_scales["x_proj:input"],  # â† å­˜å‚¨ä¸º self.input_scale
)
```

**èµ‹å€¼åˆ° SSM** (qMambaLayer.py:628-633):
```python
qmixer.selective_scan = QSScan.from_fp16(
    u_scale=act_scales["x_proj:input"],  # â† å­˜å‚¨ä¸º self.u_scale
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨1: Conv1D forward - Mode 0, 2-1** (qConvLayer.py:116-122 / 157):
```python
# INT8 Conv1D kernel ç›´æ¥è¾“å‡º INT8ï¼Œä¸ä½¿ç”¨ output_scale
y = quant_causal_conv1d_cuda.fwd(
    x, self.input_scale,
    self.weight, self.weight_scale,
    self.output_scale,  # â† ä¼ å…¥ä½† INT8 æ¨¡å¼ä¸‹ä¸ç”¨äº dequant
    self.bias_scale, self.bias,
    None, None, None, True
)
```

**ä½¿ç”¨2: Dequant INT8â†’FP32 - Mode 2-0, 2-2** (qMambaLayer.py:760):
```python
x_for_ssm = x.float() * self.conv1d.output_scale  # â† Dequant ä½¿ç”¨
```

**ä½¿ç”¨3: Requant FP32â†’INT8 - Mode 2-3, 2-4** (qMambaLayer.py:764):
```python
x_for_xproj = torch.round(x / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
# â† Requant ä½¿ç”¨
```

**ä½¿ç”¨4: Requant FP32â†’INT8 - Mode 3 âš ï¸ Scale Mismatch** (qMambaLayer.py:764):
```python
# Conv1D forward æ—¶ç”¨åŠ¨æ€ scale (qConvLayer.py:426-430):
#   x_dynamic_scale = x.abs().max().item() / 127.0
#   y_fp32 = quant_causal_conv1d_cuda.fwd_fp32(x_int8, x_dynamic_scale, ...)
# ä½† Requant æ—¶ç”¨çš„æ˜¯ calibration çš„ Percentile scale:
x_for_xproj = torch.round(x / self.conv1d.output_scale).clamp(-128, 127).to(torch.int8)
# âš ï¸ ä¸¤ä¸ª scale ä¸åŒ¹é…ï¼
```

**ä½¿ç”¨5: x_proj forward** (W4A8B8O8Linear):
```python
# x_proj.input_scale ç”¨äºå°†è¾“å…¥ dequantï¼ˆå¦‚æœéœ€è¦ï¼‰
# å…·ä½“ä½¿ç”¨åœ¨ linear å±‚å†…éƒ¨
```

**ä½¿ç”¨6: SSM forward - u è¾“å…¥** (qSelectiveScan.py / CUDA):
```python
# self.u_scale ç”¨äºé‡åŒ–/åé‡åŒ– u è¾“å…¥
# å…·ä½“ä½¿ç”¨åœ¨ SSM kernel å†…éƒ¨
```

---

## 2ï¸âƒ£ `ssm_state_act:input` (SSM state scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:163-169):
```python
if is_x(op) or is_ssm_state(op):  # is_ssm_state = lambda op: op == "ssm_state_act"
    observers[i]["ssm_state_act:input"] = PerTensorPercentileObserver(
        n_bits=8,
        percentile_alpha=0.9995
    )
```

**æ•°æ®æ”¶é›†** (é€šè¿‡ SSM å†…éƒ¨ hook):
```python
# Hook åœ¨ selective_scan å†…éƒ¨æ”¶é›† SSM state æ¿€æ´»å€¼
def stat_hook(m, inputs, outputs, op="ssm_state_act", block_idx=i):
    observers[block_idx]["ssm_state_act:input"].update(inputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ SSM å†…éƒ¨è®¡ç®—çš„ state æ¿€æ´»å€¼
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
act_scales[i]["ssm_state_act:input"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° SSM** (qMambaLayer.py:628-633):
```python
qmixer.selective_scan = QSScan.from_fp16(
    ssm_state_scale=act_scales["ssm_state_act:input"],  # â† å­˜å‚¨ä¸º self.ssm_state_scale
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨: SSM forward - state é‡åŒ–** (qSelectiveScan.py / CUDA):
```python
# self.ssm_state_scale ç”¨äº SSM å†…éƒ¨ state çš„é‡åŒ–
# å…·ä½“ä½¿ç”¨åœ¨ selective_scan kernel å†…éƒ¨
# å¯¹ SSM çŠ¶æ€è¿›è¡Œ INT8 é‡åŒ–ä»¥èŠ‚çœå†…å­˜å’Œè®¡ç®—
```

---

## 3ï¸âƒ£ `in_proj:input` (in_proj è¾“å…¥ scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:171-175):
```python
else:  # ä¸æ˜¯ x_proj æˆ– ssm_state_act
    observers[i]["in_proj:input"] = PerTensorMinmaxObserver(
        n_bits=8,
        clip_ratio=1.0,
        sym=True
    )
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
def stat_hook(m, inputs, outputs, op="in_proj", block_idx=i):
    observers[block_idx]["in_proj:input"].update(inputs.clone().detach())
    # æ”¶é›†çš„æ˜¯å‰ä¸€å±‚è¾“å‡ºï¼ˆhidden_statesï¼‰ï¼Œå³å°†è¾“å…¥ in_proj
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
# MinmaxObserver è®¡ç®—æ–¹æ³• (observer.py):
#   cur_max = w.abs().max()
#   scale = cur_max / 127
act_scales[i]["in_proj:input"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° in_proj** (qMambaLayer.py:593-597):
```python
qmixer.in_proj = W4A8B8O8Linear.from_fp16(
    input_scale=act_scales["in_proj:input"],  # â† å­˜å‚¨ä¸º self.input_scale
    output_scale=act_scales["in_proj:output"],
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨: in_proj forward** (W4A8B8O8Linear):
```python
# self.input_scale ç”¨äºå°† FP16 hidden_states é‡åŒ–ä¸º INT8
# æˆ–åœ¨å·²ç»æ˜¯ INT8 æ—¶ç”¨äºè®°å½• scale ä¿¡æ¯
```

---

## 4ï¸âƒ£ `in_proj:output` (z_scale / Conv1D è¾“å…¥ scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:176-180):
```python
observers[i]["in_proj:output"] = PerTensorMinmaxObserver(
    n_bits=8,
    clip_ratio=1.0,
    sym=True
)
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
def stat_hook(m, inputs, outputs, op="in_proj", block_idx=i):
    observers[block_idx]["in_proj:output"].update(outputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ in_proj çš„è¾“å‡ºï¼ˆxzæ‹¼æ¥ï¼‰ï¼Œå³å°† split å¹¶é€å…¥ Conv1D å’Œä½œä¸º z
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
act_scales[i]["in_proj:output"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° in_proj** (qMambaLayer.py:593-597):
```python
qmixer.in_proj = W4A8B8O8Linear.from_fp16(
    input_scale=act_scales["in_proj:input"],
    output_scale=act_scales["in_proj:output"],  # â† å­˜å‚¨ä¸º self.output_scale
)
```

**èµ‹å€¼åˆ° Conv1D** (qMambaLayer.py:603-606):
```python
qmixer.conv1d = QCausalConv1D.from_fp16(
    input_scale=act_scales["in_proj:output"].item(),  # â† å­˜å‚¨ä¸º self.input_scale
    output_scale=act_scales["x_proj:input"].item(),
)
```

**èµ‹å€¼åˆ° SSM (ä½œä¸º z_scale)** (qMambaLayer.py:628-633):
```python
qmixer.selective_scan = QSScan.from_fp16(
    z_scale=act_scales["in_proj:output"],  # â† å­˜å‚¨ä¸º self.z_scale
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨1: in_proj forward** (W4A8B8O8Linear):
```python
# self.output_scale ç”¨äºè®°å½•è¾“å‡ºçš„é‡åŒ– scale
```

**ä½¿ç”¨2: Conv1D forward** (qConvLayer.py):
```python
# self.input_scale ç”¨äºé‡åŒ–è¾“å…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
# æˆ–åœ¨ kernel ä¸­ç”¨äºè®¡ç®—
```

**ä½¿ç”¨3: SSM forward - z è¾“å…¥** (qSelectiveScan.py):
```python
# self.z_scale ç”¨äºé‡åŒ–/åé‡åŒ– z è¾“å…¥
```

---

## 5ï¸âƒ£ `x_proj:output` (B_scale, C_scale / dt_proj è¾“å…¥ scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:176-180):
```python
observers[i]["x_proj:output"] = PerTensorMinmaxObserver(
    n_bits=8,
    clip_ratio=1.0,
    sym=True
)
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
def stat_hook(m, inputs, outputs, op="x_proj", block_idx=i):
    observers[block_idx]["x_proj:output"].update(outputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ x_proj è¾“å‡ºï¼ˆdt, B, C æ‹¼æ¥ï¼‰ï¼Œå³å°† split ååˆ†åˆ«ä½¿ç”¨
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
act_scales[i]["x_proj:output"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° x_proj** (qMambaLayer.py:610-614):
```python
qmixer.x_proj = W4A8B8O8Linear.from_fp16(
    input_scale=act_scales["x_proj:input"],
    output_scale=act_scales["x_proj:output"],  # â† å­˜å‚¨ä¸º self.output_scale
)
```

**èµ‹å€¼åˆ° dt_proj** (qMambaLayer.py:617-621):
```python
qmixer.dt_proj = W8A8B8O8Linear.from_fp16(
    input_scale=act_scales["x_proj:output"].item(),  # â† å­˜å‚¨ä¸º self.input_scale
    output_scale=act_scales["dt_proj:output"].item(),
)
```

**èµ‹å€¼åˆ° SSM (ä½œä¸º B_scale, C_scale)** (qMambaLayer.py:628-633):
```python
qmixer.selective_scan = QSScan.from_fp16(
    B_scale=act_scales["x_proj:output"],  # â† å­˜å‚¨ä¸º self.B_scale
    C_scale=act_scales["x_proj:output"],  # â† å­˜å‚¨ä¸º self.C_scaleï¼ˆåŒä¸€ä¸ªå€¼ï¼‰
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨1: x_proj forward** (W4A8B8O8Linear):
```python
# self.output_scale ç”¨äºè®°å½•è¾“å‡ºçš„é‡åŒ– scale
```

**ä½¿ç”¨2: dt_proj forward** (W8A8B8O8Linear):
```python
# self.input_scale ç”¨äºé‡åŒ–è¾“å…¥ï¼ˆå·²ç»æ˜¯ INT8ï¼Œæ‰€ä»¥ä¸»è¦ç”¨äºè®°å½•ï¼‰
```

**ä½¿ç”¨3: SSM forward - B, C è¾“å…¥** (qSelectiveScan.py):
```python
# self.B_scale å’Œ self.C_scale ç”¨äºé‡åŒ–/åé‡åŒ– B, C è¾“å…¥
```

---

## 6ï¸âƒ£ `dt_proj:output` (dt_scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:176-180):
```python
observers[i]["dt_proj:output"] = PerTensorMinmaxObserver(
    n_bits=8,
    clip_ratio=1.0,
    sym=True
)
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
def stat_hook(m, inputs, outputs, op="dt_proj", block_idx=i):
    observers[block_idx]["dt_proj:output"].update(outputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ dt_proj è¾“å‡ºï¼Œå³å°†è¾“å…¥ SSM ä½œä¸º dt
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
act_scales[i]["dt_proj:output"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° dt_proj** (qMambaLayer.py:617-621):
```python
qmixer.dt_proj = W8A8B8O8Linear.from_fp16(
    input_scale=act_scales["x_proj:output"].item(),
    output_scale=act_scales["dt_proj:output"].item(),  # â† å­˜å‚¨ä¸º self.output_scale
)
```

**èµ‹å€¼åˆ° SSM (ä½œä¸º dt_scale)** (qMambaLayer.py:628-633):
```python
qmixer.selective_scan = QSScan.from_fp16(
    dt_scale=act_scales["dt_proj:output"],  # â† å­˜å‚¨ä¸º self.dt_scale
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨1: dt_proj forward** (W8A8B8O8Linear):
```python
# self.output_scale ç”¨äºè®°å½•è¾“å‡ºçš„é‡åŒ– scale
```

**ä½¿ç”¨2: SSM forward - dt è¾“å…¥** (qSelectiveScan.py):
```python
# self.dt_scale ç”¨äºé‡åŒ–/åé‡åŒ– dt è¾“å…¥
```

---

## 7ï¸âƒ£ `out_proj:input` (out_proj è¾“å…¥ scale)

### ğŸ“¥ Calibration é˜¶æ®µ

**Observer æ³¨å†Œ** (modelutils_mamba.py:171-175):
```python
observers[i]["out_proj:input"] = PerTensorMinmaxObserver(
    n_bits=8,
    clip_ratio=1.0,
    sym=True
)
```

**æ•°æ®æ”¶é›†** (modelutils_mamba.py:141-149):
```python
def stat_hook(m, inputs, outputs, op="out_proj", block_idx=i):
    observers[block_idx]["out_proj:input"].update(inputs.clone().detach())
    # æ”¶é›†çš„æ˜¯ SSM è¾“å‡ºï¼ˆç»è¿‡ Hadamardï¼‰ï¼Œå³å°†è¾“å…¥ out_proj
```

**Scale è®¡ç®—** (modelutils_mamba.py:247-251):
```python
scale, base = observer.get_quantization_parameters()
act_scales[i]["out_proj:input"] = scale.to(torch.float32)
```

### ğŸ”„ Model æ„å»ºé˜¶æ®µ

**èµ‹å€¼åˆ° Hadamard** (qMambaLayer.py:636-640):
```python
if use_had_transform:
    qmixer.had.x_H_scale = act_scales["out_proj:input"].item()  # â† HadLinear å†…éƒ¨
else:
    qmixer.had.scale = act_scales["out_proj:input"].item()  # â† QAct
```

**èµ‹å€¼åˆ° out_proj** (qMambaLayer.py:641-644):
```python
qmixer.out_proj = W4A8B16O16Linear.from_fp16(
    input_scale=act_scales["out_proj:input"],  # â† å­˜å‚¨ä¸º self.input_scale
)
```

### ğŸš€ Inference é˜¶æ®µ

**ä½¿ç”¨1: Hadamard forward** (qMambaLayer.py:141):
```python
# scale ç”¨äºé‡åŒ– SSM è¾“å‡ºä¸º INT8ï¼ˆå¦‚æœéœ€è¦ï¼‰
```

**ä½¿ç”¨2: out_proj forward** (W4A8B16O16Linear):
```python
# self.input_scale ç”¨äºé‡åŒ–è¾“å…¥ï¼ˆä» FP16 æˆ–å·²æœ‰ INT8ï¼‰
```

---

## ğŸ”‘ æ€»ç»“ï¼šScale ä½¿ç”¨æ¨¡å¼

### Percentile Scale (2ä¸ª)
- `x_proj:input`: Conv1Dè¾“å‡º â†’ x_proj/SSM
- `ssm_state_act:input`: SSMå†…éƒ¨state

### MinMax Scale (5ä¸ª)
- `in_proj:input`: å‰ä¸€å±‚è¾“å‡º â†’ in_proj
- `in_proj:output`: in_projè¾“å‡º â†’ Conv1D/z
- `x_proj:output`: x_projè¾“å‡º â†’ dt_proj/B/C
- `dt_proj:output`: dt_projè¾“å‡º â†’ SSM dt
- `out_proj:input`: SSMè¾“å‡º â†’ out_proj

### SSM 6-scale è¾“å…¥
1. `u_scale` = `x_proj:input` âœ… Percentile
2. `dt_scale` = `dt_proj:output` âŒ MinMax
3. `B_scale` = `x_proj:output` âŒ MinMax
4. `C_scale` = `x_proj:output` âŒ MinMax
5. `z_scale` = `in_proj:output` âŒ MinMax
6. `ssm_state_scale` = `ssm_state_act:input` âœ… Percentile
