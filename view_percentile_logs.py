#!/usr/bin/env python3
"""
Percentileæ—¥å¿—æŸ¥çœ‹å·¥å…·

ç”¨æ³•:
    python view_percentile_logs.py                    # æŸ¥çœ‹æ‰€æœ‰å®éªŒ
    python view_percentile_logs.py --last 5           # æŸ¥çœ‹æœ€è¿‘5æ¬¡å®éªŒ
    python view_percentile_logs.py --compare pa1.0,default  # å¯¹æ¯”ä¸¤ä¸ªå®éªŒ
    python view_percentile_logs.py --filter "mamba-370m"    # ç­›é€‰ç‰¹å®šæ¨¡å‹
"""

import json
import argparse
from pathlib import Path
from datetime import datetime


def load_experiments(log_file):
    """åŠ è½½æ‰€æœ‰å®éªŒè®°å½•"""
    experiments = []
    if not Path(log_file).exists():
        print(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return experiments

    with open(log_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line:
                try:
                    experiments.append(json.loads(line))
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  è§£æJSONå¤±è´¥: {e}")
                    continue

    return experiments


def print_experiment_summary(exp, index=None):
    """æ‰“å°å•ä¸ªå®éªŒçš„æ‘˜è¦"""
    header = f"å®éªŒ #{index}" if index is not None else "å®éªŒ"
    print(f"\n{'='*80}")
    print(f"{header} - {exp['timestamp']}")
    print(f"{'='*80}")

    # é…ç½®ä¿¡æ¯
    config = exp['config']
    print(f"\nğŸ“‹ é…ç½®:")
    print(f"  æ¨¡å‹: {config['model']}")
    print(f"  é‡åŒ–: W{config['w_bits']}A{config['a_bits']}")
    print(f"  Percentile Alpha: {config.get('percentile_alpha', 'default')}")
    print(f"  Group Heads: {config['group_heads']}")
    print(f"  GPTQ: {config['apply_gptq']}")

    # æ¿€æ´»ç»Ÿè®¡ï¼ˆåªæ˜¾ç¤ºå‰3å±‚ï¼‰
    if exp['activation_stats']:
        print(f"\nğŸ“Š æ¿€æ´»ç»Ÿè®¡ (å‰3å±‚):")
        count = 0
        for layer_name, stats in exp['activation_stats'].items():
            if count >= 3:
                break
            print(f"\n  {layer_name}:")

            if 'before_percentile' in stats:
                before = stats['before_percentile']
                after = stats['after_percentile']
                print(f"    è£å‰ªå‰: [{before['min']:.2f}, {before['max']:.2f}] èŒƒå›´={before['range']:.2f}")
                print(f"    è£å‰ªå: [{after['min']:.2f}, {after['max']:.2f}] èŒƒå›´={after['range']:.2f}")

                if 'range_reduction' in stats:
                    print(f"    èŒƒå›´ç¼©å°: {stats['range_reduction']*100:.2f}%")
                if 'clipped_ratio' in stats:
                    print(f"    è£å‰ªæ¯”ä¾‹: {stats['clipped_ratio']*100:.4f}%")

            count += 1

        if len(exp['activation_stats']) > 3:
            print(f"\n  ... å…±{len(exp['activation_stats'])}å±‚")

    # Reorderæ•ˆæœ
    reorder = exp.get('reorder_summary', {})
    if reorder.get('enabled'):
        print(f"\nğŸ”„ Reorderæ•ˆæœ:")
        print(f"  å½±å“å±‚æ•°: {reorder.get('total_layers', 0)}")
        if reorder.get('avg_range_reduction') is not None:
            print(f"  å¹³å‡èŒƒå›´ç¼©å°: {reorder['avg_range_reduction']:.2f}%")

    # æœ€ç»ˆç»“æœ
    if 'results' in exp and exp['results']:
        results = exp['results']
        print(f"\nğŸ¯ æœ€ç»ˆç»“æœ:")
        print(f"  Accuracy: {results.get('accuracy', 0)*100:.2f}%")
        print(f"  Perplexity: {results.get('perplexity', 0):.3f}")

    # å‘½ä»¤
    print(f"\nğŸ’» å‘½ä»¤:")
    print(f"  {exp['command']}")


def compare_experiments(exp1, exp2, label1="å®éªŒ1", label2="å®éªŒ2"):
    """å¯¹æ¯”ä¸¤ä¸ªå®éªŒ"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å¯¹æ¯”: {label1} vs {label2}")
    print(f"{'='*80}")

    # é…ç½®å¯¹æ¯”
    print(f"\né…ç½®å¯¹æ¯”:")
    print(f"  {'é¡¹ç›®':<25} {label1:<25} {label2:<25}")
    print(f"  {'-'*75}")

    config1 = exp1['config']
    config2 = exp2['config']

    fields = [
        ('æ¨¡å‹', 'model'),
        ('é‡åŒ–', lambda c: f"W{c['w_bits']}A{c['a_bits']}"),
        ('Percentile Alpha', lambda c: c.get('percentile_alpha', 'default')),
        ('Group Heads', 'group_heads'),
        ('GPTQ', 'apply_gptq'),
    ]

    for label, key in fields:
        if callable(key):
            val1 = key(config1)
            val2 = key(config2)
        else:
            val1 = config1.get(key, 'N/A')
            val2 = config2.get(key, 'N/A')

        diff_marker = "" if val1 == val2 else " âš ï¸"
        print(f"  {label:<25} {str(val1):<25} {str(val2):<25}{diff_marker}")

    # ç»“æœå¯¹æ¯”
    if 'results' in exp1 and 'results' in exp2:
        r1 = exp1['results']
        r2 = exp2['results']

        print(f"\nğŸ¯ ç»“æœå¯¹æ¯”:")
        acc1 = r1.get('accuracy', 0) * 100
        acc2 = r2.get('accuracy', 0) * 100
        acc_diff = acc2 - acc1

        ppl1 = r1.get('perplexity', 0)
        ppl2 = r2.get('perplexity', 0)
        ppl_diff = ppl2 - ppl1

        print(f"  Accuracy: {acc1:.2f}% vs {acc2:.2f}% (å·®å¼‚: {acc_diff:+.2f}%)")
        print(f"  Perplexity: {ppl1:.3f} vs {ppl2:.3f} (å·®å¼‚: {ppl_diff:+.3f})")

    # æ¿€æ´»èŒƒå›´å¯¹æ¯”ï¼ˆç¬¬ä¸€å±‚ï¼‰
    if exp1['activation_stats'] and exp2['activation_stats']:
        print(f"\nğŸ“Š æ¿€æ´»èŒƒå›´å¯¹æ¯”ï¼ˆç¬¬ä¸€å±‚ï¼‰:")

        # è·å–ç¬¬ä¸€å±‚çš„åç§°
        layer1 = list(exp1['activation_stats'].keys())[0]
        layer2 = list(exp2['activation_stats'].keys())[0]

        stats1 = exp1['activation_stats'][layer1]
        stats2 = exp2['activation_stats'][layer2]

        if 'before_percentile' in stats1 and 'before_percentile' in stats2:
            print(f"\n  è£å‰ªå‰èŒƒå›´:")
            r1 = stats1['before_percentile']['range']
            r2 = stats2['before_percentile']['range']
            print(f"    {label1}: {r1:.2f}")
            print(f"    {label2}: {r2:.2f}")

            print(f"\n  è£å‰ªåèŒƒå›´:")
            r1 = stats1['after_percentile']['range']
            r2 = stats2['after_percentile']['range']
            print(f"    {label1}: {r1:.2f}")
            print(f"    {label2}: {r2:.2f}")


def main():
    parser = argparse.ArgumentParser(description='Percentileå®éªŒæ—¥å¿—æŸ¥çœ‹å·¥å…·')
    parser.add_argument('--log_file', default='logs/percentile_experiments.jsonl',
                        help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--last', type=int, help='æ˜¾ç¤ºæœ€è¿‘Næ¬¡å®éªŒ')
    parser.add_argument('--filter', help='ç­›é€‰åŒ…å«å…³é”®è¯çš„å®éªŒ')
    parser.add_argument('--compare', help='å¯¹æ¯”ä¸¤ä¸ªå®éªŒçš„ç´¢å¼•ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚: 1,2ï¼‰')

    args = parser.parse_args()

    # åŠ è½½å®éªŒ
    experiments = load_experiments(args.log_file)
    if not experiments:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å®éªŒè®°å½•")
        return

    print(f"\nâœ… åŠ è½½äº† {len(experiments)} ä¸ªå®éªŒè®°å½•")

    # ç­›é€‰
    if args.filter:
        experiments = [
            exp for exp in experiments
            if args.filter.lower() in exp['config']['model'].lower() or
               args.filter.lower() in exp['command'].lower()
        ]
        print(f"âœ… ç­›é€‰åå‰©ä½™ {len(experiments)} ä¸ªå®éªŒ")

    # é™åˆ¶æ•°é‡
    if args.last:
        experiments = experiments[-args.last:]
        print(f"âœ… æ˜¾ç¤ºæœ€è¿‘ {len(experiments)} ä¸ªå®éªŒ")

    # å¯¹æ¯”æ¨¡å¼
    if args.compare:
        indices = [int(i.strip()) for i in args.compare.split(',')]
        if len(indices) != 2:
            print("âŒ --compareå‚æ•°éœ€è¦ä¸¤ä¸ªç´¢å¼•ï¼Œç”¨é€—å·åˆ†éš”")
            return

        idx1, idx2 = indices
        if idx1 >= len(experiments) or idx2 >= len(experiments):
            print(f"âŒ ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼ˆå…±{len(experiments)}ä¸ªå®éªŒï¼‰")
            return

        compare_experiments(
            experiments[idx1], experiments[idx2],
            label1=f"å®éªŒ#{idx1}", label2=f"å®éªŒ#{idx2}"
        )
        return

    # æ˜¾ç¤ºæ‰€æœ‰å®éªŒ
    for i, exp in enumerate(experiments):
        print_experiment_summary(exp, index=i)


if __name__ == '__main__':
    main()
