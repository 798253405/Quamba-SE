# æ‰€æœ‰æ¨¡å¼å®Œæ•´è·¯å¾„å¯¹æ¯”

## æ€»è§ˆè¡¨

| Mode | Conv1D è¾“å‡º | SSM è¾“å…¥ | SSM å®ç° | ç¯å¢ƒå˜é‡ |
|------|------------|----------|---------|---------|
| **Mode 0** | INT8 | INT8 | CUDA INT8 | (é»˜è®¤) |
| **Mode 2-0** | FP32 (INT8 grid) | INT8 (requantize) | CUDA INT8 | `FLOAT_SIM_ASIC_INT8=true SSM_USE_CUDA_FOR_FP32=true` |
| **Mode 2-1** | INT8 | INT8 (direct) | PyTorch INT8 | `FLOAT_SIM_ASIC_INT8=true SSM_USE_PYTORCH_INT8=true` |
| **Mode 2-2** | FP32 (INT8 grid) | FP32 (INT8 grid) | PyTorch FP32 | `FLOAT_SIM_ASIC_INT8=true` |
| **Mode 2-3** âœ… | FP32 (TRUE) | INT8 (requantize) | PyTorch INT8 | `FLOAT_SIM_ASIC_INT8=true CONV1D_MODE23_FP32=true` |
| **Mode 2-4** âœ¨ | FP32 (TRUE) | FP32 (TRUE) | PyTorch FP32 | `FLOAT_SIM_ASIC_INT8=true CONV1D_MODE24_FP32=true` |
| **Mode 3** ğŸŒŸ | FP32 (TRUE) | FP32 (TRUE) | PyTorch FP32 + INT8 Linear | `CONV1D_MODE3_FP32=true` |
| **Mode 1** | FP32 (TRUE) | FP32 (TRUE) | PyTorch FP32 | `FP32_SSM_INPUT=true` |

---

## è¯¦ç»†è·¯å¾„

### **Mode 0: Baseline INT8 CUDA**

```
ç¯å¢ƒå˜é‡: (æ— )

Conv1D:
  ğŸ“ quamba/qConvLayer.py:112-148
  ğŸ”§ quant_causal_conv1d_cuda.fwd() â†’ CUDA INT8 kernel
  ğŸ“Š è¾“å…¥: INT8 â†’ è¾“å‡º: INT8

SSM:
  ğŸ“ quamba/qSelectiveScan.py:325-373
  ğŸ”§ quant_selective_scan_fn() â†’ CUDA INT8 kernel
  ğŸ“Š è¾“å…¥: INT8 â†’ è¾“å‡º: INT8 â†’ half

ç²¾åº¦: INT8 computation (256 discrete values)
```

---

### **Mode 2-0: CUDA INT8 + Requantization**

```
ç¯å¢ƒå˜é‡: FLOAT_SIM_ASIC_INT8=true SSM_USE_CUDA_FOR_FP32=true

Conv1D:
  ğŸ“ quamba/qConvLayer.py:150-199
  ğŸ”§ quant_causal_conv1d_cuda.fwd() â†’ INT8 kernel
       â†’ y_int8.float() * output_scale
  ğŸ“Š è¾“å…¥: INT8 â†’ CUDAè®¡ç®—: FP32 â†’ é‡åŒ–åˆ°INT8 â†’ åé‡åŒ–åˆ°FP32
  âš ï¸ è¾“å‡º: FP32 (on INT8 grid - 256 discrete values)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:285-291
  ğŸ“ quamba/SoftEdgeSSM.py:28-99
  ğŸ”§ execute_mode_20_cuda_int8_requant()
       â†’ FP32 requantize to INT8
       â†’ quant_selective_scan_fn() (CUDA INT8 kernel)
  ğŸ“Š è¾“å…¥: FP32 (INT8 grid) â†’ Requantize to INT8 â†’ CUDA INT8 â†’ FP32 â†’ half

æµ‹è¯•: Requantization æ˜¯å¦å½±å“ç²¾åº¦
```

---

### **Mode 2-1: PyTorch INT8 Direct**

```
ç¯å¢ƒå˜é‡: FLOAT_SIM_ASIC_INT8=true SSM_USE_PYTORCH_INT8=true

Conv1D:
  ğŸ“ quamba/qConvLayer.py:112-148 (åŒ Mode 0)
  ğŸ”§ quant_causal_conv1d_cuda.fwd() â†’ CUDA INT8 kernel
  ğŸ“Š è¾“å…¥: INT8 â†’ è¾“å‡º: INT8 (no dequantization)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:293-299
  ğŸ“ quamba/SoftEdgeSSM.py:102-213
  ğŸ”§ execute_mode_21_pytorch_int8_direct()
       â†’ selective_scan_SE_int8Torch() (PyTorch INT8)
  ğŸ“Š è¾“å…¥: INT8 (direct pass, no requantization) â†’ PyTorch INT8 â†’ FP32 â†’ half

æµ‹è¯•: PyTorch INT8 vs CUDA INT8 å®ç°å·®å¼‚
```

---

### **Mode 2-2: FP32 PyTorch (INT8 Grid)**

```
ç¯å¢ƒå˜é‡: FLOAT_SIM_ASIC_INT8=true

Conv1D:
  ğŸ“ quamba/qConvLayer.py:150-199
  ğŸ”§ quant_causal_conv1d_cuda.fwd() â†’ INT8 kernel
       â†’ y_int8.float() * output_scale
  ğŸ“Š è¾“å…¥: INT8 â†’ CUDAè®¡ç®—: FP32 â†’ é‡åŒ–åˆ°INT8 â†’ åé‡åŒ–åˆ°FP32
  âš ï¸ è¾“å‡º: FP32 (on INT8 grid - 256 discrete values)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:318-332
  ğŸ“ quamba/SoftEdgeSSM.py:344-419 (line 387-396)
  ğŸ”§ execute_fp32_modes('mode22_fp32_replicates_mode21')
       â†’ selective_scan_SE_mode22_fp32_replicates_mode21()
  ğŸ“Š è¾“å…¥: FP32 (on INT8 grid) â†’ å®Œå…¨FP32è®¡ç®— â†’ FP32 â†’ half

ç‰¹ç‚¹: SSM ç”¨ FP32 å¤åˆ¶ Mode 2-1 çš„é€»è¾‘
å½“å‰æœ€ä½³æ€§èƒ½: âœ… (å¯¹äº INT8 grid è¾“å…¥)
```

---

### **Mode 2-3: TRUE FP32 Conv1D + PyTorch INT8 SSM** â­ (ä¿®æ­£å)

```
ç¯å¢ƒå˜é‡: FLOAT_SIM_ASIC_INT8=true CONV1D_MODE23_FP32=true

Conv1D:
  ğŸ“ quamba/qConvLayer.py:201-230
  ğŸ”§ quant_causal_conv1d_cuda.fwd_fp32() â†’ NEW FP32 CUDA kernel
  ğŸ“ csrc/causal_conv1d/quant_causal_conv1d_fwd_fp32_kernel.cuh

  å…³é”®ä»£ç  (line 155-157):
    float out_vals_store[kNElts];
    for (int i = 0; i < kNElts; ++i) {
        out_vals_store[i] = out_vals[i];  // ä¸é‡åŒ–ï¼
    }

  ğŸ“Š è¾“å…¥: INT8 â†’ CUDAè®¡ç®—: FP32 (å®Œæ•´ç²¾åº¦) â†’ è¾“å‡º: FP32 (TRUE continuous)
  âœ… è·³è¿‡é‡åŒ–æ­¥éª¤ (ä¿ç•™ CUDA å†…éƒ¨ FP32 ç²¾åº¦)

SSM: (âœ… ä¿®æ­£åçš„è·¯ç”±)
  ğŸ“ quamba/qSelectiveScan.py:274-280
  ğŸ”§ execute_mode_21_legacy_pytorch_int8_requant()
  ğŸ“ quamba/SoftEdgeSSM.py:216-342

  æ­¥éª¤:
    1. æ¥æ”¶: FP32 (TRUE continuous values)
    2. Requantize: torch.round(u / u_scale).clamp(-128, 127).to(torch.int8)
    3. è®¡ç®—: selective_scan_SE_int8Torch() (PyTorch INT8)
    4. è¾“å‡º: FP32 â†’ half

  ğŸ“Š è¾“å…¥: FP32 (TRUE) â†’ Requantize to INT8 â†’ PyTorch INT8 â†’ FP32 â†’ half

æµ‹è¯•ç›®çš„: Conv1D çš„é«˜ç²¾åº¦ FP32 è¾“å‡ºæ˜¯å¦èƒ½æ”¹å–„æœ€ç»ˆç»“æœ
é¢„æœŸæ€§èƒ½: ä¸ Mode 2-1 legacy ç›¸å½“æˆ–æ›´å¥½
```

---

### **Mode 2-4: TRUE FP32 Conv1D + PyTorch FP32 SSM** âœ¨ (å®Œå…¨FP32)

```
ç¯å¢ƒå˜é‡: FLOAT_SIM_ASIC_INT8=true CONV1D_MODE24_FP32=true

Conv1D:
  ğŸ“ quamba/qConvLayer.py:301-329
  ğŸ”§ quant_causal_conv1d_cuda.fwd_fp32() â†’ FP32 CUDA kernel
  ğŸ“ csrc/causal_conv1d/quant_causal_conv1d_fwd_fp32_kernel.cuh

  å…³é”®ä»£ç  (line 155-157):
    float out_vals_store[kNElts];
    for (int i = 0; i < kNElts; ++i) {
        out_vals_store[i] = out_vals[i];  // ä¸é‡åŒ–ï¼
    }

  ğŸ“Š è¾“å…¥: INT8 â†’ CUDAè®¡ç®—: FP32 (å®Œæ•´ç²¾åº¦) â†’ è¾“å‡º: FP32 (TRUE continuous)
  âœ… è·³è¿‡é‡åŒ–æ­¥éª¤ (ä¿ç•™ CUDA å†…éƒ¨ FP32 ç²¾åº¦)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:277-284
  ğŸ”§ execute_fp32_modes('fp32_upper_bound')
  ğŸ“ quamba/SoftEdgeSSM.py:344-419 (line 378-386)

  æ­¥éª¤:
    1. æ¥æ”¶: FP32 (TRUE continuous values)
    2. ç›´æ¥ä½¿ç”¨: ä¸éœ€è¦ requantizationï¼
    3. è®¡ç®—: selective_scan_SE_float() (PyTorch FP32)
    4. è¾“å‡º: FP32 â†’ half

  ğŸ“Š è¾“å…¥: FP32 (TRUE) â†’ ç›´æ¥ä½¿ç”¨ â†’ PyTorch FP32 â†’ FP32 â†’ half

æµ‹è¯•ç›®çš„: å®Œå…¨ FP32 æµç¨‹ï¼Œæµ‹è¯• Conv1D FP32 çš„çœŸæ­£ä¸Šç•Œ
é¢„æœŸæ€§èƒ½: åº”è¯¥æ˜¯æ‰€æœ‰ Mode 2-x ä¸­æœ€å¥½çš„ï¼Œæ¥è¿‘ Mode 1

å…³é”®ç‰¹å¾:
  âœ… No scale mismatch issues (ä¸éœ€è¦ requantization)
  âœ… No quantization error in Conv1D
  âœ… No quantization error in SSM
  âœ… Complete FP32 pipeline: Conv1D â†’ SSM
```

---

### **Mode 3: FP32/FP16 Input + FP32 Conv/SSM + INT8 Linear** ğŸŒŸ (Hybrid Precision)

```
ç¯å¢ƒå˜é‡: CONV1D_MODE3_FP32=true

è¾“å…¥ç‰¹å¾:
  ğŸ“Š æ¨¡å‹è¾“å…¥: FP32 æˆ– FP16 (å®Œæ•´ç²¾åº¦)
  âš¡ åŠ¨æ€é‡åŒ–: è¿è¡Œæ—¶å°† FP32/FP16 è¾“å…¥é‡åŒ–ä¸º INT8

Conv1D:
  ğŸ“ quamba/qConvLayer.py:341-399

  æ­¥éª¤:
    1. æ¥æ”¶ FP32/FP16 è¾“å…¥
    2. è®¡ç®—åŠ¨æ€ scale: x_dynamic_scale = x.abs().max() / 127.0
    3. é‡åŒ–: x_int8 = round(x / x_dynamic_scale).clamp(-128, 127)
    4. CUDA è®¡ç®—: quant_causal_conv1d_cuda.fwd_fp32() â†’ FP32 kernel
    5. è¾“å‡º: FP32 (TRUE continuous values)

  ğŸ“ csrc/causal_conv1d/quant_causal_conv1d_fwd_fp32_kernel.cuh

  å…³é”®ä»£ç  (line 155-157):
    float out_vals_store[kNElts];
    for (int i = 0; i < kNElts; ++i) {
        out_vals_store[i] = out_vals[i];  // ä¸é‡åŒ–ï¼
    }

  ğŸ“Š è¾“å…¥: FP32/FP16 â†’ åŠ¨æ€é‡åŒ–åˆ° INT8 â†’ CUDAè®¡ç®—: FP32 â†’ è¾“å‡º: FP32 (TRUE)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:274-289
  ğŸ”§ execute_fp32_modes('fp32_upper_bound')
  ğŸ“ quamba/SoftEdgeSSM.py:344-419 (line 378-386)

  æ­¥éª¤:
    1. æ¥æ”¶: FP32 (TRUE continuous values)
    2. ç›´æ¥ä½¿ç”¨: ä¸éœ€è¦ requantizationï¼
    3. è®¡ç®—: selective_scan_SE_float() (PyTorch FP32)
    4. è¾“å‡º: FP32 â†’ half

  ğŸ“Š è¾“å…¥: FP32 (TRUE) â†’ ç›´æ¥ä½¿ç”¨ â†’ PyTorch FP32 â†’ FP32 â†’ half

Linearå±‚:
  ğŸ“Š ä¿æŒ INT8 é‡åŒ– (baseline é…ç½®)
  âš¡ è¿™æ˜¯ä¸ Mode 2-4 å’Œ Mode 1 çš„ä¸»è¦åŒºåˆ«

æµ‹è¯•ç›®çš„:
  - Hybrid precision: æµ‹è¯• FP32 Conv/SSM + INT8 Linear çš„ç»„åˆ
  - å¯¹æ¯” Mode 2-4: æµ‹è¯• FP32 è¾“å…¥æ˜¯å¦æ¯” INT8 è¾“å…¥æ›´å¥½
  - å®ç”¨æ€§: æ¯”å®Œå…¨ FP32 æ›´èŠ‚çœå†…å­˜å’Œè®¡ç®—

é¢„æœŸæ€§èƒ½:
  - Conv/SSM ä¸ Mode 2-4 ç›¸åŒï¼ˆFP32ï¼‰
  - Linear ä½¿ç”¨ INT8ï¼ˆå‡å°‘å†…å­˜/è®¡ç®—ï¼‰
  - æ•´ä½“åº”è¯¥æ¥è¿‘ Mode 2-4 æˆ– Mode 1

å…³é”®ç‰¹å¾:
  âœ… Accepts FP32/FP16 input (no pre-quantization needed)
  âœ… Dynamic quantization at runtime
  âœ… Complete FP32 pipeline for Conv1D â†’ SSM
  âœ… INT8 Linear (memory/compute efficient)
  ğŸ¯ Best of both worlds: FP32 precision + INT8 efficiency
```

---

### **Mode 1: Pure FP32 Upper Bound**

```
ç¯å¢ƒå˜é‡: FP32_SSM_INPUT=true

Conv1D:
  ğŸ“ (é€šå¸¸ä½¿ç”¨ PyTorch FP32 fallbackï¼Œå¦‚æœæ²¡æœ‰é‡åŒ–æƒé‡)
  ğŸ“Š è¾“å…¥: FP32 â†’ è¾“å‡º: FP32 (full precision)

SSM:
  ğŸ“ quamba/qSelectiveScan.py:318-332
  ğŸ“ quamba/SoftEdgeSSM.py:344-419 (line 378-386)
  ğŸ”§ execute_fp32_modes('fp32_upper_bound')
       â†’ selective_scan_SE_float()
  ğŸ“Š è¾“å…¥: FP32 â†’ å®Œå…¨FP32è®¡ç®— â†’ FP32 â†’ half

ç²¾åº¦: å®Œå…¨ FP32 (ç†è®ºä¸Šç•Œ)
```

---

## å…³é”®å¯¹æ¯”

### Conv1D è¾“å‡ºç²¾åº¦

```
Mode 0:      INT8 (256 values)
Mode 2-0:    FP32 on INT8 grid (256 discrete FP32 values)
Mode 2-1:    INT8 (256 values)
Mode 2-2:    FP32 on INT8 grid (256 discrete FP32 values)
Mode 2-3: âœ… FP32 TRUE continuous (unlimited precision)
Mode 2-4: âœ¨ FP32 TRUE continuous (unlimited precision)
Mode 3:   ğŸŒŸ FP32 TRUE continuous (unlimited precision, accepts FP32/FP16 input)
Mode 1:      FP32 TRUE continuous (unlimited precision)
```

### SSM è®¡ç®—ç²¾åº¦

```
Mode 0:      CUDA INT8 kernel
Mode 2-0:    CUDA INT8 kernel (with requantization overhead)
Mode 2-1:    PyTorch INT8
Mode 2-2:    PyTorch FP32 (designed for INT8 grid input)
Mode 2-3: âœ… PyTorch INT8 (with requantization from TRUE FP32)
Mode 2-4: âœ¨ PyTorch FP32 (full precision, no requantization)
Mode 3:   ğŸŒŸ PyTorch FP32 (full precision, same as Mode 2-4)
Mode 1:      PyTorch FP32 (full precision)
```

### æ•°å€¼æµå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚                    Conv1D Output â†’ SSM                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mode 0       â”‚ INT8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ INT8 SSM                               â”‚
â”‚ Mode 2-0     â”‚ INT8 grid (FP32) â”€â”€â†’ INT8 SSM (requant)                     â”‚
â”‚ Mode 2-1     â”‚ INT8 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ INT8 SSM (direct)                      â”‚
â”‚ Mode 2-2     â”‚ INT8 grid (FP32) â”€â”€â†’ FP32 SSM (INT8 grid logic)            â”‚
â”‚ Mode 2-3 âœ…  â”‚ TRUE FP32 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ INT8 SSM (requant from FP32)          â”‚
â”‚ Mode 2-4 âœ¨  â”‚ TRUE FP32 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ FP32 SSM (full precision)             â”‚
â”‚ Mode 3   ğŸŒŸ  â”‚ FP32/FP16 input â†’ TRUE FP32 â†’ FP32 SSM + INT8 Linear      â”‚
â”‚ Mode 1       â”‚ TRUE FP32 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ FP32 SSM (full precision)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¿®æ­£å†å²

### ä¿®æ­£å‰çš„ Mode 2-3 (é”™è¯¯):

```
Conv1D: TRUE FP32 âœ…
SSM:    execute_fp32_modes('mode22_fp32_replicates_mode21') âŒ
        â†’ selective_scan_SE_mode22_fp32_replicates_mode21()
        (ä¸º INT8 grid çš„ FP32 è®¾è®¡ï¼Œä¸é€‚åˆ TRUE continuous FP32)

ç»“æœ: æ¯” Mode 2-2 æ›´å·® âŒ
```

### ä¿®æ­£åçš„ Mode 2-3 (æ­£ç¡®):

```
Conv1D: TRUE FP32 âœ…
SSM:    execute_mode_21_legacy_pytorch_int8_requant() âœ…
        â†’ requantize FP32 to INT8
        â†’ selective_scan_SE_int8Torch()

ç»“æœ: é¢„æœŸä¸ Mode 2-1 legacy ç›¸å½“æˆ–æ›´å¥½ âœ…
```

---

## è¿è¡Œå‘½ä»¤æ€»ç»“

```bash
# Mode 0: Baseline
python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode0

# Mode 2-0: CUDA INT8 + Requantization
FLOAT_SIM_ASIC_INT8=true SSM_USE_CUDA_FOR_FP32=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode20

# Mode 2-1: PyTorch INT8 Direct
FLOAT_SIM_ASIC_INT8=true SSM_USE_PYTORCH_INT8=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode21

# Mode 2-2: FP32 PyTorch (INT8 Grid)
FLOAT_SIM_ASIC_INT8=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode22

# Mode 2-3: TRUE FP32 Conv1D + PyTorch INT8 SSM (CORRECTED)
FLOAT_SIM_ASIC_INT8=true CONV1D_MODE23_FP32=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode23

# Mode 2-4: TRUE FP32 Conv1D + PyTorch FP32 SSM (å®Œå…¨FP32)
FLOAT_SIM_ASIC_INT8=true CONV1D_MODE24_FP32=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode24

# Mode 3: FP32/FP16 Input + FP32 Conv/SSM + INT8 Linear (Hybrid Precision)
CONV1D_MODE3_FP32=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode3

# Mode 1: Pure FP32 Upper Bound
FP32_SSM_INPUT=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --fp32-ssm-input --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode1
```

---

## è°ƒè¯•å‘½ä»¤

```bash
# Mode 2-3 with debug
FLOAT_SIM_ASIC_INT8=true CONV1D_MODE23_FP32=true SSM_DEBUG_MODE23=true python3 main.py quamba-130m-w8a8 --pretrained_dir pretrained_models/quamba1/default --quantize --float-sim-asic-int8 --eval_zero_shot --task_list lambada_openai --testing --log_dir logs_mode23_debug

# æ£€æŸ¥ debug_mode_comparison/ ç›®å½•
ls -lh debug_mode_comparison/
```
