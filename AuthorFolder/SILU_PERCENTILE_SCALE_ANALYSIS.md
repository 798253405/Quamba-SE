# SiLU ä¸ Percentile Scale çš„å®Œæ•´åˆ†æ

## æ ¸å¿ƒé—®é¢˜

**ä¸ºä»€ä¹ˆ Conv1d è¾“å‡ºéœ€è¦ç”¨ Percentile Scale é‡æ–°é‡åŒ–ï¼Ÿ**

## èƒŒæ™¯ï¼šConv1d çš„ç²¾åº¦æµç¨‹

### Online Inference ä¸­çš„å®é™…æµç¨‹

```
CUDA Kernel: quant_causal_conv1d_fwd_kernel
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

è¾“å…¥:  INT8 x, INT8 weight, INT8 bias
      FP32 scale_x, scale_w, scale_b, scale_out

Step 1: è¯»å–å¹¶è½¬æ¢ä¸º FP32
  x_vals[i] = float(x_vals_load[i])        // INT8 â†’ FP32 (ç±»å‹è½¬æ¢)
  weight_vals[i] = float(weight[i])        // INT8 â†’ FP32 (ç±»å‹è½¬æ¢)
  bias_val = float(bias) * scale_b         // INT8 â†’ FP32 å¹¶åé‡åŒ–

Step 2: Conv1d è®¡ç®— (FP32)
  out_tmp = Î£(weight_vals[w] Ã— x_vals[...])  // INT8Ã—INT8 ä»¥ FP32 è®¡ç®—
  out_vals[i] = scale_wx Ã— out_tmp + bias_val // åé‡åŒ–åˆ°çœŸå®å€¼åŸŸ

Step 3: SiLU Activation (FP32 â†’ FP32) ğŸ”¥ å…³é”®!
  out_vals[i] = out_vals[i] / (1 + expf(-out_vals[i]))

Step 4: é‡åŒ–ä¸º INT8 (ä½¿ç”¨ percentile scale)
  q = clamp(round(out_vals[i] / scale_out), -128, 127)

è¾“å‡º:  INT8 tensor (ç›´æ¥å†™å› global memory)
```

**å…³é”®å‘ç°ï¼šConv1d å†…éƒ¨æ˜¯ FP32 è®¡ç®—ï¼Œä½†ç›´æ¥è¾“å‡º INT8ï¼**

## æ ¸å¿ƒï¼šSiLU å‡½æ•°ä¸ºä»€ä¹ˆæ˜¯å…³é”®

### SiLU çš„æ•°å­¦å®šä¹‰

```
SiLU(x) = x / (1 + e^(-x))

ç‰¹æ€§:
  â€¢ x â†’ -âˆ: SiLU(x) â†’ 0    (è´Ÿæ•°è¢«å‹ç¼©åˆ°æ¥è¿‘0)
  â€¢ x = 0:  SiLU(0) = 0    (åŸç‚¹)
  â€¢ x â†’ +âˆ: SiLU(x) â†’ x    (å¤§æ­£æ•°å‡ ä¹ä¸å˜)
  â€¢ éçº¿æ€§ã€éå¯¹ç§°
```

### SiLU å¦‚ä½•æ”¹å˜å€¼çš„åˆ†å¸ƒ

å‡è®¾ Conv1d è¾“å‡ºèŒƒå›´ `[-5.0, 5.0]`, é—´è· = 0.1 (ç”± scale_wx å†³å®š)

```
Conv1d è¾“å‡º (FP32)  â†’  SiLU è¾“å‡º (FP32)  â†’  è¯´æ˜
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  -5.00           â†’     -0.033          â†’  è´Ÿæ•°è¢«ä¸¥é‡å‹ç¼©
  -4.00           â†’     -0.072          â†’  å‹ç¼©åˆ° [-0.27, 0]
  -3.00           â†’     -0.142          â†’  èŒƒå›´ä»… 0.27
  -2.00           â†’     -0.238          â†’
  -1.00           â†’     -0.269          â†’  æœ€å°å€¼
   0.00           â†’      0.000          â†’  ä¸­å¿ƒç‚¹
   1.00           â†’      0.731          â†’
   2.00           â†’      1.762          â†’  æ­£æ•°ç›¸å¯¹ä¿æŒ
   3.00           â†’      2.858          â†’
   4.00           â†’      3.928          â†’  æ¥è¿‘çº¿æ€§
   5.00           â†’      4.967          â†’  èŒƒå›´çº¦ 5.0

è¾“å…¥èŒƒå›´: 10.0  (ä» -5 åˆ° 5)
è¾“å‡ºèŒƒå›´: 5.24  (ä» -0.27 åˆ° 4.97)  â† å‹ç¼©äº† 47.6%!
åˆ†å¸ƒ:     ä¸å¯¹ç§°ï¼Œå¤§éƒ¨åˆ†å€¼é›†ä¸­åœ¨ [0, 3] åŒºé—´
```

### ä¸ºä»€ä¹ˆä¸èƒ½ç”¨ Conv1d çš„ scaleï¼Ÿ

#### åœºæ™¯1: ç”¨ scale_wx = 0.1 (Conv1d çš„ scale)

```
SiLU è¾“å‡º (FP32)  â†’  é‡åŒ– (INT8)  â†’  åé‡åŒ– (FP32)  â†’  è¯¯å·®
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  -0.269          â†’       -3       â†’      -0.300       â†’  0.031
   0.000          â†’        0       â†’       0.000       â†’  0.000
   0.731          â†’        7       â†’       0.700       â†’  0.031
   1.762          â†’       18       â†’       1.800       â†’  0.038
   2.858          â†’       29       â†’       2.900       â†’  0.042
   4.967          â†’       50       â†’       5.000       â†’  0.033

INT8 ä½¿ç”¨èŒƒå›´: [-3, 50]
INT8 åˆ©ç”¨ç‡:   50/127 = 39.4%  â† æµªè´¹ 60% çš„è¡¨ç¤ºèƒ½åŠ›!
å¹³å‡è¯¯å·®:      0.027
```

**é—®é¢˜ï¼š**
- SiLU è¾“å‡ºèŒƒå›´æ˜¯ `[~0, 5]`ï¼Œä½† scale_wx æ˜¯ä¸º Conv1d çš„ `[-5, 5]` è®¾è®¡çš„
- Scale å¤ªå¤§ â†’ INT8 çš„ 256 ä¸ªç¦»æ•£çº§åˆ«è¢«æµªè´¹
- é‡åŒ–ç²¾åº¦ä½

#### åœºæ™¯2: ç”¨ Percentile scale = 0.0387

```
SiLU è¾“å‡º (FP32)  â†’  é‡åŒ– (INT8)  â†’  åé‡åŒ– (FP32)  â†’  è¯¯å·®
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  -0.269          â†’       -7       â†’      -0.271       â†’  0.002
   0.000          â†’        0       â†’       0.000       â†’  0.000
   0.731          â†’       19       â†’       0.736       â†’  0.005
   1.762          â†’       46       â†’       1.781       â†’  0.019
   2.858          â†’       74       â†’       2.865       â†’  0.007
   4.967          â†’      127       â†’       4.917       â†’  0.050 (é¥±å’Œ)

INT8 ä½¿ç”¨èŒƒå›´: [-7, 127]
INT8 åˆ©ç”¨ç‡:   127/127 = 100%  â† å……åˆ†åˆ©ç”¨!
å¹³å‡è¯¯å·®:      0.011
è¯¯å·®æ”¹å–„:      2.51x
```

**ä¼˜åŠ¿ï¼š**
- Scale æ ¹æ® SiLU è¾“å‡ºçš„å®é™…åˆ†å¸ƒè®¡ç®—
- Scale æ›´å° (0.0387 vs 0.1) â†’ é‡åŒ–é—´è·æ›´ç»†
- INT8 çš„ 256 ä¸ªçº§åˆ«å……åˆ†åˆ©ç”¨
- é‡åŒ–ç²¾åº¦æé«˜ 2.5 å€

### ä¸ºä»€ä¹ˆéœ€è¦ Percentile è€Œä¸æ˜¯ MinMaxï¼Ÿ

å‡è®¾ SiLU è¾“å‡ºæœ‰ outliers:
- 99.95% çš„å€¼åœ¨ `[0, 3.0]`
- 0.05% çš„ outliers åˆ°è¾¾ `10.0`

```
MinMax scale      = 10.0 / 127 = 0.0787
Percentile scale  = 3.0 / 127 = 0.0236  â† å°äº† 3.3 å€!

å¯¹äºæ­£å¸¸å€¼ 1.0:
  MinMax:      q = round(1.0/0.0787) = 13  â†’ ç²¾åº¦ä½
  Percentile:  q = round(1.0/0.0236) = 42  â†’ ç²¾åº¦é«˜ 3.3x!

å¯¹äº outlier 10.0:
  MinMax:      q = 127  â†’ æ­£å¸¸è¡¨ç¤º
  Percentile:  q = 127 (é¥±å’Œ) â†’ æœ‰æŸå¤±ï¼Œä½†åªå½±å“ 0.05%
```

**Trade-offï¼šç‰ºç‰² 0.05% çš„ outliersï¼Œæ¢å– 99.95% æ­£å¸¸å€¼çš„é«˜ç²¾åº¦ï¼**

## å®Œæ•´çš„ Percentile Scale å·¥ä½œæµç¨‹

### Offline Calibration (ç”Ÿæˆ scale)

```python
# ä½ç½®: modelutils_mamba.py:161-165
if is_x(op) or is_ssm_state(op):
    observers[i][op + ":input"] = PerTensorPercentileObserver(
        n_bits=8, clip_ratio=1.0, sym=True,
        percentile_alpha=0.9995  # å¿½ç•¥ top 0.05%
    )

# Hook æ•è·: x_proj çš„è¾“å…¥ (å³ conv1d+silu çš„è¾“å‡º)
# ä½ç½®: qMambaLayer.py:105-109 (FP16 ç‰ˆæœ¬)
x = self.conv1d(x)           # FP16
x = self.act(x[...,:seqlen]) # FP16 SiLU
x_reshape = rearrange(x, "b d l -> b l d")  # Hook åœ¨è¿™é‡Œæ•è· FP16
x_dbl = self.x_proj(x_reshape)

# Observer è®¡ç®— percentile (observer.py:90-92)
w = w.clone().to(torch.float32)  # FP16 â†’ FP32
cur_max = torch.quantile(w.abs().reshape(-1), self.percentile_alpha)
# cur_max: 99.95% åˆ†ä½æ•° (FP32)

# EMA æ›´æ–° (observer.py:98-101)
if self.w_max is None:
    self.w_max = cur_max
else:
    self.w_max = self.w_max + 0.01 * (cur_max - self.w_max)

# è®¡ç®— scale (observer.py:112-118)
scales = w_max / 127  # FP32 scalar
return scales.to(torch.float32).clamp(min=1e-6)

# ä¿å­˜åˆ° state_dict (qMambaLayer.py:852)
qconv.output_scale = act_scales["x_proj:input"].item()  # FP32 scalar
```

### Online Inference (ä½¿ç”¨ scale)

```cpp
// ä½ç½®: quant_causal_conv1d_fwd_kernel.cuh:57-62
float scale_x = params.scale_x;      // Conv1d è¾“å…¥ scale
float scale_w = params.scale_w;      // Conv1d æƒé‡ scale
float scale_b = params.scale_b;      // Conv1d bias scale
float scale_out = params.scale_out;  // Conv1d è¾“å‡º scale (æ¥è‡ª percentile!)
float scale_wx = scale_w * scale_x;  // è”åˆ scale

// Conv1d è®¡ç®— (Line 126-137)
float out_vals[kNElts];
for (int i = 0; i < kNElts; ++i) {
    float out_tmp = 0;
    for (int w = 0; w < kWidth; ++w) {
        out_tmp += weight_vals[w] * x_vals[kNElts + i - (kWidth - w - 1)];
    }
    out_vals[i] = scale_wx * out_tmp + bias_val;  // FP32
}

// SiLU activation (Line 139-144)
if (params.silu_activation) {
    for (int i = 0; i < kNElts; ++i) {
        out_vals[i] = out_vals[i] / (1 + expf(-out_vals[i]));  // FP32
    }
}

// é‡åŒ–ä¸º INT8 (Line 146-151) - ä½¿ç”¨ percentile scale!
input_t out_vals_store[kNElts];
for (int i = 0; i < kNElts; ++i) {
    int tmp = int(roundf(out_vals[i] / scale_out));  // FP32 / FP32
    out_vals_store[i] = tmp > 127 ? 127 : tmp < -128 ? -128 : static_cast<input_t>(tmp);
}
// è¾“å‡º: INT8 tensor
```

## å®é™…æ¨¡å‹çš„ Scale æ•°æ®

### Quamba2-130m-w8a8 (default é…ç½®)

è¿è¡Œ `python3 analyze_scales.py` çš„ç»“æœï¼š

```
Layer |     Config |         x_scale |        wx_scale |     x_out_scale |      ratio |     shape
     0 |    default |      0.03795522 |      0.00918891 |      0.01578744 |     1.7181 | (1, 4, 4)
     1 |    default |      0.03491019 |      0.00804318 |      0.06717040 |     8.3512 | (1, 4, 4)
     2 |    default |      0.05035064 |      0.00715890 |      0.07035671 |     9.8279 | (1, 4, 4)
     3 |    default |      0.03946235 |      0.00817391 |      0.07583546 |     9.2778 | (1, 4, 4)
     4 |    default |      0.05570251 |      0.00752799 |      0.06240292 |     8.2895 | (1, 4, 4)
```

### ğŸ”¥ å…³é”®å‘ç°

1. **ratio > 1**: SiLU **æ‰©å¤§äº†å€¼åŸŸ**ï¼Œè€Œä¸æ˜¯å‹ç¼©ï¼
   - ç†è®ºåˆ†æåŸºäºç®€åŒ–å‡è®¾ï¼ˆConv1d è¾“å‡º `[-5, 5]`ï¼‰
   - å®é™…æ¨¡å‹ä¸­ï¼ŒConv1d è¾“å‡ºå¯èƒ½æœ¬èº«å°±å¾ˆå°
   - SiLU å¯¹å°è´Ÿæ•°çš„å‹ç¼© + å¯¹æ­£æ•°çš„ä¿æŒ = æ€»ä½“æ‰©å¤§

2. **x_out_scales æ˜¯ tensor**: Shape `(1, 4, 4)`
   - ä¸æ˜¯ per-tensor é‡åŒ–ï¼ˆå•ä¸ª scalarï¼‰
   - å¯èƒ½æ˜¯ per-channel æˆ– per-group é‡åŒ–
   - Dim 1 å’Œ Dim 2 å¯èƒ½å¯¹åº” head groups å’Œ dim groups

3. **ratio å·®å¼‚å¾ˆå¤§**: ä» 1.7 åˆ° 9.8
   - ä¸åŒå±‚çš„ SiLU å½±å“ä¸åŒ
   - æ·±å±‚ç½‘ç»œ (Layer 1-4) çš„ ratio æ›´å¤§ (8-10x)
   - æµ…å±‚ç½‘ç»œ (Layer 0) çš„ ratio è¾ƒå° (1.7x)

### ä¿®æ­£çš„ç†è§£

**åŸå§‹å‡è®¾**: SiLU å‹ç¼©å€¼åŸŸ â†’ percentile scale æ›´å° â†’ ratio < 1

**å®é™…æƒ…å†µ**:
- Conv1d è¾“å‡ºç»è¿‡é‡åŒ–åï¼Œ`wx_scale` å·²ç»å¾ˆå° (0.007-0.009)
- SiLU æ¿€æ´»åï¼Œè¾“å‡ºå€¼åŸŸå®é™…ä¸Š**æ‰©å¤§**äº†
- `x_out_scale` (0.015-0.076) > `wx_scale` â†’ ratio > 1
- Percentile çš„ä½œç”¨ï¼š**é˜²æ­¢ SiLU è¾“å‡ºçš„ outliers è®© scale æ›´å¤§**

### ä¸ºä»€ä¹ˆä»ç„¶éœ€è¦ Percentileï¼Ÿ

å³ä½¿ ratio > 1ï¼ŒPercentile ä»ç„¶é‡è¦ï¼š

1. **SiLU æ”¹å˜äº†å€¼çš„åˆ†å¸ƒ** - éœ€è¦é‡æ–°è§‚å¯Ÿå®é™…è¾“å‡º
2. **Outliers é—®é¢˜ä¾ç„¶å­˜åœ¨** - å¦‚æœç”¨ MinMaxï¼Œscale ä¼šæ›´å¤§
3. **ä¸åŒå±‚å·®å¼‚å·¨å¤§** - ratio ä» 1.7 åˆ° 9.8ï¼Œè¯´æ˜æ¯å±‚éƒ½éœ€è¦ç‹¬ç«‹ calibration

## æ€»ç»“

### æ ¸å¿ƒç­”æ¡ˆ

**Q: ä¸ºä»€ä¹ˆéœ€è¦ Percentile Scaleï¼Ÿ**

**A: å› ä¸º SiLU æ˜¯éçº¿æ€§å‡½æ•°ï¼Œå®ƒæ”¹å˜äº†å€¼çš„èŒƒå›´å’Œåˆ†å¸ƒï¼š**

1. **Conv1d è¾“å‡º**: é‡åŒ–åçš„ `wx_scale` å¾ˆå° (0.007-0.009)
2. **SiLU è¾“å‡º**: æ‰©å¤§äº†å€¼åŸŸï¼Œéœ€è¦æ›´å¤§çš„ scale (0.015-0.076)
3. **å¦‚æœç”¨ Conv1d çš„ scale**:
   - Scale å¤ªå°ï¼Œæ— æ³•è¡¨ç¤º SiLU è¾“å‡º
   - ä¼šå¯¼è‡´ä¸¥é‡çš„é¥±å’Œï¼ˆclippingï¼‰
   - é‡åŒ–è¯¯å·®å·¨å¤§
4. **ç”¨ Percentile scale**:
   - è§‚å¯Ÿ SiLU è¾“å‡ºçš„å®é™…åˆ†å¸ƒ
   - è®¡ç®—é€‚åˆ SiLU è¾“å‡ºçš„ scale
   - å¿½ç•¥ top 0.05% outliersï¼Œé˜²æ­¢ scale è¿‡å¤§
   - å……åˆ†åˆ©ç”¨ INT8 èŒƒå›´

### å…³é”®å…¬å¼

```
é‡åŒ–å…¬å¼: q = clamp(round(x / scale), -128, 127)

Conv1d scale:    scale_wx = (w_max / 127) * (x_max / 127)
                 ä¸º Conv1d è¾“å‡ºèŒƒå›´è®¾è®¡

Percentile scale: scale_out = percentile(SiLU_output, 99.95%) / 127
                  ä¸º SiLU è¾“å‡ºåˆ†å¸ƒä¼˜åŒ–
                  å¿½ç•¥ top 0.05% outliers
```

### ç²¾åº¦æå‡æ•°æ®

| æŒ‡æ ‡ | ç”¨ scale_wx | ç”¨ Percentile scale | æå‡ |
|-----|------------|-------------------|------|
| INT8 åˆ©ç”¨ç‡ | 39.4% | 100% | 2.5x |
| å¹³å‡é‡åŒ–è¯¯å·® | 0.027 | 0.011 | 2.5x |
| å— outliers å½±å“ | å¤§ | å° (åªå½±å“ 0.05%) | - |

### æœ¬è´¨

**SiLU æŠŠ FP32 å€¼"é‡æ–°æ’åˆ—"äº†ï¼Œéœ€è¦é‡æ–°é€‰æ‹©æœ€ä¼˜çš„é‡åŒ–é—´è·æ¥å……åˆ†åˆ©ç”¨ INT8 çš„ 256 ä¸ªç¦»æ•£çº§åˆ«ï¼**

è¿™ä¸æ˜¯"å¢åŠ ä¿¡æ¯é‡"ï¼Œè€Œæ˜¯"å‡å°‘è¡¨ç¤ºè¯¯å·®" - ç”¨æœ‰é™çš„ INT8 èŒƒå›´å»æ›´å¥½åœ°æ‹Ÿåˆå®é™…å€¼åˆ†å¸ƒã€‚

## ä»£ç ä½ç½®ç´¢å¼•

| åŠŸèƒ½ | æ–‡ä»¶ | è¡Œå· |
|-----|------|-----|
| Percentile Observer å®šä¹‰ | observer.py | 75-118 |
| Percentile è®¡ç®— (torch.quantile) | observer.py | 92 |
| Calibration æ³¨å†Œ observer | modelutils_mamba.py | 161-165 |
| Conv1d output_scale è®¾ç½® | qMambaLayer.py | 848-852 |
| CUDA kernel SiLU è®¡ç®— | quant_causal_conv1d_fwd_kernel.cuh | 139-144 |
| CUDA kernel é‡åŒ– | quant_causal_conv1d_fwd_kernel.cuh | 146-151 |
| Conv1d forward (Python) | qMambaLayer.py | 920 |
| SSM æ¥æ”¶ INT8 | qMambaLayer.py | 933 |
