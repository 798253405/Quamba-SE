# Percentile Scale ä½¿ç”¨ä½ç½®å®Œæ•´è¿½è¸ª

## æ ¸å¿ƒé—®é¢˜å›ç­”

### Q1: æ¯ä¸€å±‚çš„ conv1d éƒ½å» SSM å—ï¼Ÿ

**ç­”æ¡ˆï¼šæ˜¯çš„ï¼** æ¯ä¸ª Mamba block çš„æ•°æ®æµï¼š

```
è¾“å…¥ â†’ RMSNorm â†’ in_proj â†’ conv1d â†’ x_proj â†’ SSM (selective_scan)
                                 â†“
                            è¿™é‡Œå» SSM!
```

**24 å±‚ç»“æ„ (Quamba2-130m)**:
```
Layer 0: conv1d â†’ SSM
Layer 1: conv1d â†’ SSM
Layer 2: conv1d â†’ SSM
...
Layer 23: conv1d â†’ SSM
```

æ¯ä¸€å±‚çš„ conv1d è¾“å‡ºéƒ½æ˜¯å¯¹åº”å±‚ SSM çš„è¾“å…¥ï¼

---

## Q2: Percentile ç”¨åœ¨å“ªäº› Scaleï¼Ÿ

### Quamba1 (Mamba1 æ¨¡å‹)

**Percentile ä½¿ç”¨ä½ç½®** (modelutils_mamba.py:163-169):

```python
if is_x(op) or is_ssm_state(op):
    observers[i][op + ":input"] = PerTensorPercentileObserver(
        percentile_alpha=percentile_alpha  # 0.9995
    )
```

**åˆ¤æ–­æ¡ä»¶** (modelutils_mamba.py:122-123):
```python
is_x = lambda op: op == "x_proj"
is_ssm_state = lambda op: op == "ssm_state_act"
```

#### âœ… ä½¿ç”¨ Percentile çš„ 2 ä¸ª Scale:

1. **`x_proj:input`** â† Conv1d+SiLU çš„è¾“å‡º
   - æ¥æº: `conv1d` è¾“å‡º (fused with SiLU)
   - å»å‘: `x_proj` è¾“å…¥
   - ä½ç½®: qMambaLayer.py:851
   ```python
   qmixer.conv1d = QCausalConv1D.from_fp16(
       output_scale=act_scales["x_proj:input"].item(),  # â† Percentile!
   )
   ```

2. **`ssm_state_act:input`** â† SSM å†…éƒ¨çŠ¶æ€æ¿€æ´»
   - æ¥æº: SSM å†…éƒ¨ state è®¡ç®—
   - å»å‘: SSM state quantization
   - ä½ç½®: qMambaLayer.py:876
   ```python
   qmixer.selective_scan = QSScan.from_fp16(
       ssm_state_scale=act_scales["ssm_state_act:input"],  # â† Percentile!
   )
   ```

#### âŒ ä¸ä½¿ç”¨ Percentile çš„å…¶ä»– Scale (ç”¨ MinMax):

- `in_proj:input` (MinMax)
- `in_proj:output` (MinMax)
- `x_proj:output` (MinMax)
- `dt_proj:output` (MinMax)
- `out_proj:input` (MinMax)

---

### Quamba2 (Mamba2 æ¨¡å‹) - ä¸ç”¨ Percentile!

**Quamba2 ä½¿ç”¨ä¸åŒçš„ Observer** (modelutils_mamba.py:256-273):

```python
def run_quamba2_calibration(...):
    # Quamba2 ä¸ç”¨ PerTensorPercentileObserver
    # è€Œæ˜¯ç”¨ CrossHeadMinmaxObserver (Group Quantization)
```

**å…³é”®åŒºåˆ«**:
```
Quamba1: PerTensorPercentileObserver  â†’ 1 ä¸ª scalar scale (percentile)
Quamba2: CrossHeadMinmaxObserver      â†’ (1,4,4) æˆ– (8,4,4) scales (minmax per group)
```

---

## Q3: å¦‚ä½•ç›‘æµ‹å’Œä¿®æ”¹ç‰¹å®šçš„ Percentile Scaleï¼Ÿ

### æ–¹æ³• 1: ä¿®æ”¹ Observer (Calibration é˜¶æ®µ)

**ä½ç½®**: `quamba/observer.py:92`

```python
class PerTensorPercentileObserver:
    def get_quantization_parameters(self):
        cur_max = torch.quantile(
            w.abs().reshape(-1),
            self.percentile_alpha  # â† è¿™é‡Œè®¡ç®— percentile
        )

        # ğŸ”¥ ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹ scale!
        # ä¾‹å¦‚: cur_max = cur_max + 2025  (ä½ ä¹‹å‰æåˆ°çš„ +2025)
        scale = cur_max / (2 ** (self.n_bits - 1) - 1)
        return scale, zero
```

**å½±å“èŒƒå›´**:
- ä¼šå½±å“æ‰€æœ‰ä½¿ç”¨ `PerTensorPercentileObserver` çš„å±‚
- å³: æ‰€æœ‰ 24 å±‚çš„ `x_proj:input` å’Œ `ssm_state_act:input`

---

### æ–¹æ³• 2: ä¿®æ”¹ act_scales (Model æ„å»ºé˜¶æ®µ)

**ä½ç½®**: `quamba/modelutils_mamba.py:247-251`

```python
for i in range(len(layers) + 1):
    for name, observer in observers[i].items():
        scale, base = observer.get_quantization_parameters()
        act_scales[i][name] = scale.to(torch.float32)

        # ğŸ”¥ ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹ç‰¹å®šå±‚çš„ scale!
        # ä¾‹å¦‚:
        if name == "x_proj:input" and i == 0:  # åªä¿®æ”¹ Layer 0
            act_scales[i][name] = scale * 1.5  # ä¹˜ä»¥ 1.5
```

**ä¼˜ç‚¹**: å¯ä»¥ç²¾ç¡®æ§åˆ¶æ¯ä¸€å±‚

---

### æ–¹æ³• 3: ä¿®æ”¹å·²ä¿å­˜çš„æ¨¡å‹ (åŠ è½½å)

**ä½ç½®**: åŠ è½½æ¨¡å‹åç›´æ¥ä¿®æ”¹

```python
model = load_quamba_model(...)

# éå†æ‰€æœ‰å±‚
for layer_idx, layer in enumerate(model.backbone.layers):
    mixer = layer.mixer

    # ä¿®æ”¹ conv1d çš„ output_scale (è¿™å°±æ˜¯ x_proj:input)
    if hasattr(mixer.conv1d, 'output_scale'):
        old_scale = mixer.conv1d.output_scale
        new_scale = old_scale * 1.5  # ä½ çš„ä¿®æ”¹
        mixer.conv1d.output_scale = new_scale
        print(f"Layer {layer_idx}: {old_scale:.4f} â†’ {new_scale:.4f}")

    # ä¿®æ”¹ SSM çš„ ssm_state_scale
    if hasattr(mixer.selective_scan, 'ssm_state_scale'):
        old_scale = mixer.selective_scan.ssm_state_scale
        new_scale = old_scale * 1.5
        mixer.selective_scan.ssm_state_scale = new_scale
```

**ä¼˜ç‚¹**: ä¸éœ€è¦é‡æ–° calibrate

---

## Q4: å¦‚ä½•æ ‡è®°å’Œç›‘æµ‹ Percentile Scale çš„ä½¿ç”¨ï¼Ÿ

### ç›‘æµ‹è„šæœ¬

æˆ‘ç»™ä½ å†™ä¸€ä¸ªè„šæœ¬æ¥è¿½è¸ªæ¯ä¸€å±‚çš„ percentile scale ä½¿ç”¨æƒ…å†µï¼š

```python
import torch
from safetensors import safe_open

def trace_percentile_scales(model_path):
    """
    è¿½è¸ªæ¨¡å‹ä¸­æ‰€æœ‰ä½¿ç”¨ percentile scale çš„ä½ç½®
    """

    with safe_open(model_path, framework="pt", device="cpu") as f:
        print("=" * 80)
        print("Percentile Scale ä½¿ç”¨ä½ç½®è¿½è¸ª")
        print("=" * 80)

        # ç»Ÿè®¡ä¿¡æ¯
        total_layers = 0
        x_proj_scales = []
        ssm_state_scales = []

        for key in f.keys():
            # è¿½è¸ª conv1d çš„ output_scale (å¯¹åº” x_proj:input)
            if "mixer.conv1d.output_scale" in key:
                total_layers += 1
                layer_idx = int(key.split(".")[2])  # backbone.layers.0.mixer...
                value = f.get_tensor(key)

                print(f"\nğŸ¯ Layer {layer_idx} Conv1d Output (å» SSM)")
                print(f"   Key: {key}")
                print(f"   Shape: {value.shape}")
                print(f"   Value: {value}")
                print(f"   âœ… ä½¿ç”¨ Percentile (x_proj:input)")

                x_proj_scales.append({
                    'layer': layer_idx,
                    'scale': float(value.mean())
                })

            # è¿½è¸ª SSM çš„ ssm_state_scale
            if "selective_scan.ssm_state_scale" in key:
                layer_idx = int(key.split(".")[2])
                value = f.get_tensor(key)

                print(f"\nğŸ¯ Layer {layer_idx} SSM State")
                print(f"   Key: {key}")
                print(f"   Value: {value}")
                print(f"   âœ… ä½¿ç”¨ Percentile (ssm_state_act:input)")

                ssm_state_scales.append({
                    'layer': layer_idx,
                    'scale': float(value)
                })

        print("\n" + "=" * 80)
        print("ç»Ÿè®¡æ€»ç»“")
        print("=" * 80)
        print(f"æ€»å±‚æ•°: {total_layers}")
        print(f"ä½¿ç”¨ Percentile çš„ Scale:")
        print(f"  â€¢ x_proj:input (Conv1d â†’ SSM): {len(x_proj_scales)} å±‚")
        print(f"  â€¢ ssm_state_act:input (SSM å†…éƒ¨): {len(ssm_state_scales)} å±‚")
        print(f"\næ¯ä¸€å±‚çš„ Conv1d éƒ½ä½¿ç”¨ Percentile Scale å» SSM!")

        # æ˜¾ç¤º scale åˆ†å¸ƒ
        print("\n" + "=" * 80)
        print("Conv1d â†’ SSM Scale åˆ†å¸ƒ (Percentile-computed)")
        print("=" * 80)
        for item in x_proj_scales[:5]:  # æ˜¾ç¤ºå‰ 5 å±‚
            print(f"Layer {item['layer']:2d}: {item['scale']:.6f}")
        print("...")

# ä½¿ç”¨
trace_percentile_scales("./pretrained_models/quamba1-130m-w8a8/model.safetensors")
```

---

## æ€»ç»“

### âœ… Percentile ç”¨åœ¨è¿™ 2 ä¸ªåœ°æ–¹:

| Scale åç§° | æ¥æº | å»å‘ | æ¯å±‚éƒ½ç”¨? | å» SSM? |
|-----------|------|------|----------|---------|
| **x_proj:input** | Conv1d+SiLU è¾“å‡º | x_proj è¾“å…¥ â†’ SSM | âœ… 24 å±‚å…¨éƒ¨ | âœ… æ˜¯ |
| **ssm_state_act:input** | SSM å†…éƒ¨ state | SSM é‡åŒ– | âœ… 24 å±‚å…¨éƒ¨ | âœ… æ˜¯ |

### ğŸ”¥ å…³é”®ç‚¹:

1. **æ¯ä¸€å±‚çš„ conv1d éƒ½å» SSM** (24 å±‚å…¨éƒ¨)
2. **Percentile åªç”¨åœ¨ 2 ä¸ªä½ç½®**:
   - Conv1d è¾“å‡º (x_proj:input)
   - SSM å†…éƒ¨ state (ssm_state_act:input)
3. **Quamba2 ä¸ç”¨ Percentile** (æ”¹ç”¨ Group Quantization)

### ğŸ“ ä¿®æ”¹ Percentile Scale çš„ 3 ä¸ªä½ç½®:

1. **Observer** (observer.py:92) - å½±å“æ‰€æœ‰å±‚
2. **act_scales** (modelutils_mamba.py:251) - å¯æ§åˆ¶å•å±‚
3. **åŠ è½½åä¿®æ”¹** - æœ€çµæ´»

### ğŸ¯ ç›‘æµ‹æ–¹æ³•:

ä½¿ç”¨ä¸Šé¢çš„ `trace_percentile_scales()` è„šæœ¬è¿½è¸ªæ¯ä¸€å±‚çš„ scale ä½¿ç”¨æƒ…å†µã€‚
