# Percentile Scale 实际数据分析总结

## 实验配置

- **模型**: Quamba2-130m-w4a8
- **对比**: default, pa-0.5 (α=0.9995), pa-1.0 (α=0.99999)
- **运行**: `python3 analyze_scales.py`

## 关键发现

### 1. Percentile Alpha 的影响微乎其微

```
Layer | pa-0.5 x_out | pa-1.0 x_out | 相对差异
------+-------------+-------------+----------
  0   |  0.01578744 |  0.01578744 |   0.00%
  1   |  0.06717040 |  0.06717424 |   0.06%
  2   |  0.07035671 |  0.07035863 |   0.03%
  3   |  0.07583546 |  0.07583161 |  -0.05%
  4   |  0.06240292 |  0.06240004 |  -0.05%
```

**结论**: percentile_alpha 从 0.9995 (忽略 top 0.05%) 到 0.99999 (忽略 top 0.001%) 对 scale 的影响 < 0.1%

### 2. 这说明什么？

#### ✅ 好消息: SiLU 输出分布很集中

- 99.5% 分位数 ≈ 99.999% 分位数
- 说明 **0.5% - 0.001% 之间没有极端 outliers**
- 分布的"尾巴"很短，quantization-friendly

#### ✅ Percentile 仍然重要

虽然 pa-0.5 和 pa-1.0 差异小，但这不代表 percentile 没用：
- 如果用 MinMax (α=1.0，保留所有值)，可能有极端 outlier
- Percentile 已经成功过滤了潜在的 outliers
- 这是 **预防性措施**，而不是 **修复性措施**

### 3. 模型大小的影响

对比 130m 和 2.7b 模型 (Layer 0):

```
Model   | Config      | x_out_scale | ratio
--------+-------------+-------------+-------
130m    | pa-0.5      |   0.01579   |  1.72
2.7b    | quamba2/pa-1|   0.01849   |  4.89
```

**观察**:
- 大模型的 ratio 更大 (4.89 vs 1.72)
- 大模型中 SiLU 对值域的扩大效果更明显
- **不同模型必须独立 calibrate**

### 4. SiLU 扩大值域的证据

所有 Layer 的 ratio > 1:

```
Layer | ratio (130m) | ratio (2.7b)
------+-------------+-------------
  0   |    1.72     |    4.89
  1   |    8.35     |   10.50
  2   |    9.83     |    9.22
  3   |    9.28     |   10.30
  4   |    8.29     |   12.68
```

**修正理解**:
- 早期理论: SiLU 压缩值域 → ratio < 1
- **实际情况**: SiLU 扩大值域 → ratio > 1
- 原因: Conv1d 量化后 wx_scale 很小，SiLU 输出需要更大的 scale

## 为什么需要 Percentile Scale？

### 原因 1: SiLU 改变分布

即使 ratio > 1（扩大值域），仍需重新 calibrate：

```
Conv1d 输出 (理论 scale = wx_scale)
    ↓
SiLU 非线性变换
    ↓
实际需要的 scale = x_out_scale (不能直接用 wx_scale!)
```

### 原因 2: 防止 Outliers

虽然这个模型的 pa-0.5 和 pa-1.0 差异小，但：
- 不同模型、不同层的情况可能不同
- Percentile 是 **保险措施**
- 宁可多过滤，不可漏掉极端值

### 原因 3: 不同层差异巨大

```
Layer 0: ratio = 1.7  (SiLU 影响小)
Layer 1: ratio = 8.4  (SiLU 影响大)
Layer 2: ratio = 9.8  (SiLU 影响大)
```

每层必须独立 calibrate，不能用统一的 scale。

## 理论 vs 实际

### 理论预期 (简化假设)

```
假设: Conv1d 输出范围 [-5, 5]
SiLU: 压缩负数到 [-0.27, 0]，保持正数
结果: 输出范围 [~0, 5]
结论: ratio < 1 (压缩)
```

### 实际情况

```
Conv1d 输出: 量化后 wx_scale ≈ 0.007-0.009
SiLU 输出: 需要 x_out_scale ≈ 0.015-0.076
结果: x_out_scale > wx_scale
结论: ratio = 1.7-12.7 (扩大!)
```

### 为什么不符？

1. **Conv1d 输出已经很小**: 量化后的 wx_scale 本身就小
2. **SiLU 的非线性**: 对小值的处理不是简单的"压缩"
3. **实际分布复杂**: 不能用简化假设推广到真实模型

## 最终结论

### ✅ Percentile Scale 是必要的

1. **SiLU 改变分布**: 必须重新 calibrate，不能用 wx_scale
2. **防止 outliers**: 即使这个模型影响小，但是通用的保护措施
3. **每层独立**: ratio 从 1.7 到 12.7，差异巨大

### 📊 Alpha 选择建议

基于实验数据:
- **pa-0.5 (α=0.9995)** 已经足够
- pa-1.0 (α=0.99999) 提升 < 0.1%
- 建议: **默认用 0.9995**，除非发现明显的 outliers

### 🎯 关键理解

**Percentile 不是为了"压缩值域"，而是为了"适配 SiLU 输出的实际分布"！**

- 理论: 基于简化假设 → 可能不准确
- 实践: 基于实际 calibration 数据 → 始终正确
- **数据驱动 > 理论推导**

## 进一步实验建议

1. **对比 MinMax vs Percentile**:
   - 看看如果不用 percentile (α=1.0, 保留所有值)，scale 会不会更大

2. **大模型实验**:
   - 在 2.7b, 8b 模型上重复实验
   - 看大模型是否有更多 outliers

3. **分析 x_out_scales 的 tensor 结构**:
   - Shape (1, 4, 4) 代表什么？
   - 是 per-channel 还是 per-group 量化？

4. **可视化分布**:
   - 画出 SiLU 输出的直方图
   - 直观看 99.5% vs 99.999% 分位数的差异
